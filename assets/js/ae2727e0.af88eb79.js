"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5828],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>d});var a=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var p=a.createContext({}),s=function(e){var t=a.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},u=function(e){var t=s(e.components);return a.createElement(p.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},k=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,p=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),k=s(n),d=i,c=k["".concat(p,".").concat(d)]||k[d]||m[d]||r;return n?a.createElement(c,l(l({ref:t},u),{},{components:n})):a.createElement(c,l({ref:t},u))}));function d(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,l=new Array(r);l[0]=k;var o={};for(var p in t)hasOwnProperty.call(t,p)&&(o[p]=t[p]);o.originalType=e,o.mdxType="string"==typeof e?e:i,l[1]=o;for(var s=2;s<r;s++)l[s]=n[s];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}k.displayName="MDXCreateElement"},85162:(e,t,n)=>{n.d(t,{Z:()=>l});var a=n(67294),i=n(86010);const r="tabItem_Ymn6";function l(e){let{children:t,hidden:n,className:l}=e;return a.createElement("div",{role:"tabpanel",className:(0,i.Z)(r,l),hidden:n},t)}},74866:(e,t,n)=>{n.d(t,{Z:()=>C});var a=n(87462),i=n(67294),r=n(86010),l=n(76775),o=n(91980),p=n(67392),s=n(50012);function u(e){return function(e){return i.Children.map(e,(e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:n,attributes:a,default:i}}=e;return{value:t,label:n,attributes:a,default:i}}))}function m(e){const{values:t,children:n}=e;return(0,i.useMemo)((()=>{const e=t??u(n);return function(e){const t=(0,p.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function k(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function d(e){let{queryString:t=!1,groupId:n}=e;const a=(0,l.k6)(),r=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,o._X)(r),(0,i.useCallback)((e=>{if(!r)return;const t=new URLSearchParams(a.location.search);t.set(r,e),a.replace({...a.location,search:t.toString()})}),[r,a])]}function c(e){const{defaultValue:t,queryString:n=!1,groupId:a}=e,r=m(e),[l,o]=(0,i.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!k({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const a=n.find((e=>e.default))??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:r}))),[p,u]=d({queryString:n,groupId:a}),[c,g]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[a,r]=(0,s.Nk)(n);return[a,(0,i.useCallback)((e=>{n&&r.set(e)}),[n,r])]}({groupId:a}),h=(()=>{const e=p??c;return k({value:e,tabValues:r})?e:null})();(0,i.useLayoutEffect)((()=>{h&&o(h)}),[h]);return{selectedValue:l,selectValue:(0,i.useCallback)((e=>{if(!k({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);o(e),u(e),g(e)}),[u,g,r]),tabValues:r}}var g=n(12466),h=n(72389);const f="tabList__CuJ",b="tabItem_LNqP";function N(e){let{className:t,block:n,selectedValue:l,selectValue:o,tabValues:p}=e;const s=[],{blockElementScrollPositionUntilNextRender:u}=(0,g.o5)(),m=e=>{const t=e.currentTarget,n=s.indexOf(t),a=p[n].value;a!==l&&(u(t),o(a))},k=e=>{let t=null;switch(e.key){case"Enter":m(e);break;case"ArrowRight":{const n=s.indexOf(e.currentTarget)+1;t=s[n]??s[0];break}case"ArrowLeft":{const n=s.indexOf(e.currentTarget)-1;t=s[n]??s[s.length-1];break}}t?.focus()};return i.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.Z)("tabs",{"tabs--block":n},t)},p.map((e=>{let{value:t,label:n,attributes:o}=e;return i.createElement("li",(0,a.Z)({role:"tab",tabIndex:l===t?0:-1,"aria-selected":l===t,key:t,ref:e=>s.push(e),onKeyDown:k,onClick:m},o,{className:(0,r.Z)("tabs__item",b,o?.className,{"tabs__item--active":l===t})}),n??t)})))}function y(e){let{lazy:t,children:n,selectedValue:a}=e;const r=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=r.find((e=>e.props.value===a));return e?(0,i.cloneElement)(e,{className:"margin-top--md"}):null}return i.createElement("div",{className:"margin-top--md"},r.map(((e,t)=>(0,i.cloneElement)(e,{key:t,hidden:e.props.value!==a}))))}function v(e){const t=c(e);return i.createElement("div",{className:(0,r.Z)("tabs-container",f)},i.createElement(N,(0,a.Z)({},e,t)),i.createElement(y,(0,a.Z)({},e,t)))}function C(e){const t=(0,h.Z)();return i.createElement(v,(0,a.Z)({key:String(t)},e))}},81742:(e,t,n)=>{n.d(t,{ZP:()=>p});var a=n(87462),i=(n(67294),n(3905)),r=n(74866),l=n(85162);const o={toc:[{value:"Simple Memory Circuit Breaker",id:"simple-memory-circuit-breaker",level:3},{value:"Java Runtime Circuit Breaker",id:"java-runtime-circuit-breaker",level:3},{value:"Custom Circuit Breaker",id:"custom-circuit-breaker",level:3}]};function p(e){let{components:t,...n}=e;return(0,i.kt)("wrapper",(0,a.Z)({},o,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("admonition",{type:"info"},(0,i.kt)("p",{parentName:"admonition"},"This feature is available in OpenLineage versions >= 1.9.0.")),(0,i.kt)("p",null,"To prevent from over-instrumentation OpenLineage integration provides a circuit breaker mechanism\nthat stops OpenLineage from creating, serializing and sending OpenLineage events."),(0,i.kt)("h3",{id:"simple-memory-circuit-breaker"},"Simple Memory Circuit Breaker"),(0,i.kt)("p",null,"Simple circuit breaker which is working based only on free memory within JVM. Configuration should\ncontain free memory threshold limit (percentage). Default value is ",(0,i.kt)("inlineCode",{parentName:"p"},"20%"),". The circuit breaker\nwill close within first call if free memory is low. ",(0,i.kt)("inlineCode",{parentName:"p"},"circuitCheckIntervalInMillis")," parameter is used\nto configure a frequency circuit breaker is called. Default value is ",(0,i.kt)("inlineCode",{parentName:"p"},"1000ms"),", when no entry in config.\n",(0,i.kt)("inlineCode",{parentName:"p"},"timeoutInSeconds")," is optional. If set, OpenLineage code execution is terminated when a timeout\nis reached (added in version 1.13). "),(0,i.kt)(r.Z,{groupId:"integrations",mdxType:"Tabs"},(0,i.kt)(l.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"circuitBreaker:\n  type: simpleMemory\n  memoryThreshold: 20\n  circuitCheckIntervalInMillis: 1000\n  timeoutInSeconds: 90\n"))),(0,i.kt)(l.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,i.kt)("th",{parentName:"tr",align:null},"Definition"),(0,i.kt)("th",{parentName:"tr",align:null},"Example"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.type"),(0,i.kt)("td",{parentName:"tr",align:null},"Circuit breaker type selected"),(0,i.kt)("td",{parentName:"tr",align:null},"simpleMemory")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.memoryThreshold"),(0,i.kt)("td",{parentName:"tr",align:null},"Memory threshold"),(0,i.kt)("td",{parentName:"tr",align:null},"20")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.circuitCheckIntervalInMillis"),(0,i.kt)("td",{parentName:"tr",align:null},"Frequency of checking circuit breaker"),(0,i.kt)("td",{parentName:"tr",align:null},"1000")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.timeoutInSeconds"),(0,i.kt)("td",{parentName:"tr",align:null},"Optional timeout for OpenLineage execution (Since version 1.13)"),(0,i.kt)("td",{parentName:"tr",align:null},"90"))))),(0,i.kt)(l.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,i.kt)("th",{parentName:"tr",align:null},"Definition"),(0,i.kt)("th",{parentName:"tr",align:null},"Example"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.type"),(0,i.kt)("td",{parentName:"tr",align:null},"Circuit breaker type selected"),(0,i.kt)("td",{parentName:"tr",align:null},"simpleMemory")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.memoryThreshold"),(0,i.kt)("td",{parentName:"tr",align:null},"Memory threshold"),(0,i.kt)("td",{parentName:"tr",align:null},"20")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.circuitCheckIntervalInMillis"),(0,i.kt)("td",{parentName:"tr",align:null},"Frequency of checking circuit breaker"),(0,i.kt)("td",{parentName:"tr",align:null},"1000")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.timeoutInSeconds"),(0,i.kt)("td",{parentName:"tr",align:null},"Optional timeout for OpenLineage execution (Since version 1.13)"),(0,i.kt)("td",{parentName:"tr",align:null},"90")))))),(0,i.kt)("h3",{id:"java-runtime-circuit-breaker"},"Java Runtime Circuit Breaker"),(0,i.kt)("p",null,"More complex version of circuit breaker. The amount of free memory can be low as long as\namount of time spent on Garbage Collection is acceptable. ",(0,i.kt)("inlineCode",{parentName:"p"},"JavaRuntimeCircuitBreaker")," closes\nwhen free memory drops below threshold and amount of time spent on garbage collection exceeds\ngiven threshold (",(0,i.kt)("inlineCode",{parentName:"p"},"10%")," by default). The circuit breaker is always open when checked for the first time\nas GC threshold is computed since the previous circuit breaker call.\n",(0,i.kt)("inlineCode",{parentName:"p"},"circuitCheckIntervalInMillis")," parameter is used\nto configure a frequency circuit breaker is called.\nDefault value is ",(0,i.kt)("inlineCode",{parentName:"p"},"1000ms"),", when no entry in config.\n",(0,i.kt)("inlineCode",{parentName:"p"},"timeoutInSeconds")," is optional. If set, OpenLineage code execution is terminated when a timeout\nis reached (added in version 1.13)."),(0,i.kt)(r.Z,{groupId:"integrations",mdxType:"Tabs"},(0,i.kt)(l.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"circuitBreaker:\n  type: javaRuntime\n  memoryThreshold: 20\n  gcCpuThreshold: 10\n  circuitCheckIntervalInMillis: 1000\n  timeoutInSeconds: 90\n"))),(0,i.kt)(l.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,i.kt)("th",{parentName:"tr",align:null},"Definition"),(0,i.kt)("th",{parentName:"tr",align:null},"Example"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.type"),(0,i.kt)("td",{parentName:"tr",align:null},"Circuit breaker type selected"),(0,i.kt)("td",{parentName:"tr",align:null},"javaRuntime")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.memoryThreshold"),(0,i.kt)("td",{parentName:"tr",align:null},"Memory threshold"),(0,i.kt)("td",{parentName:"tr",align:null},"20")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.gcCpuThreshold"),(0,i.kt)("td",{parentName:"tr",align:null},"Garbage Collection CPU threshold"),(0,i.kt)("td",{parentName:"tr",align:null},"10")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.circuitCheckIntervalInMillis"),(0,i.kt)("td",{parentName:"tr",align:null},"Frequency of checking circuit breaker"),(0,i.kt)("td",{parentName:"tr",align:null},"1000")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.timeoutInSeconds"),(0,i.kt)("td",{parentName:"tr",align:null},"Optional timeout for OpenLineage execution (Since version 1.13)"),(0,i.kt)("td",{parentName:"tr",align:null},"90"))))),(0,i.kt)(l.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,i.kt)("th",{parentName:"tr",align:null},"Definition"),(0,i.kt)("th",{parentName:"tr",align:null},"Example"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.type"),(0,i.kt)("td",{parentName:"tr",align:null},"Circuit breaker type selected"),(0,i.kt)("td",{parentName:"tr",align:null},"javaRuntime")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.memoryThreshold"),(0,i.kt)("td",{parentName:"tr",align:null},"Memory threshold"),(0,i.kt)("td",{parentName:"tr",align:null},"20")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.gcCpuThreshold"),(0,i.kt)("td",{parentName:"tr",align:null},"Garbage Collection CPU threshold"),(0,i.kt)("td",{parentName:"tr",align:null},"10")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.circuitCheckIntervalInMillis"),(0,i.kt)("td",{parentName:"tr",align:null},"Frequency of checking circuit breaker"),(0,i.kt)("td",{parentName:"tr",align:null},"1000")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.timeoutInSeconds"),(0,i.kt)("td",{parentName:"tr",align:null},"Optional timeout for OpenLineage execution (Since version 1.13)"),(0,i.kt)("td",{parentName:"tr",align:null},"90")))))),(0,i.kt)("h3",{id:"custom-circuit-breaker"},"Custom Circuit Breaker"),(0,i.kt)("p",null,"List of available circuit breakers can be extended with custom one loaded via ServiceLoader\nwith own implementation of ",(0,i.kt)("inlineCode",{parentName:"p"},"io.openlineage.client.circuitBreaker.CircuitBreakerBuilder"),"."))}p.isMDXComponent=!0},55154:(e,t,n)=>{n.d(t,{ZP:()=>p});var a=n(87462),i=(n(67294),n(3905)),r=n(74866),l=n(85162);const o={toc:[{value:"HTTP",id:"http",level:3},{value:"Configuration",id:"configuration",level:4},{value:"Behavior",id:"behavior",level:4},{value:"Examples",id:"examples",level:4},{value:"Kafka",id:"kafka",level:3},{value:"Configuration",id:"configuration-1",level:4},{value:"Behavior",id:"behavior-1",level:4},{value:"Notes",id:"notes",level:4},{value:"Examples",id:"examples-1",level:4},{value:"Kinesis",id:"kinesis",level:3},{value:"Configuration",id:"configuration-2",level:4},{value:"Behavior",id:"behavior-2",level:4},{value:"Examples",id:"examples-2",level:4},{value:"Console",id:"console",level:3},{value:"Behavior",id:"behavior-3",level:4},{value:"Notes",id:"notes-1",level:4},{value:"Configuration",id:"configuration-3",level:4},{value:"Examples",id:"examples-3",level:4},{value:"File",id:"file",level:3},{value:"Configuration",id:"configuration-4",level:4},{value:"Behavior",id:"behavior-4",level:4},{value:"Notes for Yarn/Kubernetes",id:"notes-for-yarnkubernetes",level:4},{value:"Examples",id:"examples-4",level:4}]};function p(e){let{components:t,...n}=e;return(0,i.kt)("wrapper",(0,a.Z)({},o,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Tip:")," See current list of ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java/src/main/java/io/openlineage/client/transports"},"all supported transports"),"."),(0,i.kt)("h3",{id:"http"},(0,i.kt)("a",{parentName:"h3",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java/src/main/java/io/openlineage/client/transports/HttpTransport.java"},"HTTP")),(0,i.kt)("p",null,"Allows sending events to HTTP endpoint, using ",(0,i.kt)("a",{parentName:"p",href:"https://hc.apache.org/index.html"},"ApacheHTTPClient"),"."),(0,i.kt)("h4",{id:"configuration"},"Configuration"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"type")," - string, must be ",(0,i.kt)("inlineCode",{parentName:"li"},'"http"'),". Required."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"url")," - string, base url for HTTP requests. Required."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"endpoint")," - string specifying the endpoint to which events are sent, appended to ",(0,i.kt)("inlineCode",{parentName:"li"},"url"),". Optional, default: ",(0,i.kt)("inlineCode",{parentName:"li"},"/api/v1/lineage"),"."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"urlParams")," - dictionary specifying query parameters send in HTTP requests. Optional."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"timeoutInMillis")," - integer specifying timeout (in milliseconds) value used while connecting to server. Optional, default: ",(0,i.kt)("inlineCode",{parentName:"li"},"5000"),"."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"auth")," - dictionary specifying authentication options. Optional, by default no authorization is used. If set, requires the ",(0,i.kt)("inlineCode",{parentName:"li"},"type")," property.",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"type"),' - string specifying the "api_key" or the fully qualified class name of your TokenProvider. Required if ',(0,i.kt)("inlineCode",{parentName:"li"},"auth")," is provided."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"apiKey")," - string setting the Authentication HTTP header as the Bearer. Required if ",(0,i.kt)("inlineCode",{parentName:"li"},"type")," is ",(0,i.kt)("inlineCode",{parentName:"li"},"api_key"),"."))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"headers")," - dictionary specifying HTTP request headers. Optional."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"compression")," - string, name of algorithm used by HTTP client to compress request body. Optional, default value ",(0,i.kt)("inlineCode",{parentName:"li"},"null"),", allowed values: ",(0,i.kt)("inlineCode",{parentName:"li"},"gzip"),". Added in v1.13.0.")),(0,i.kt)("h4",{id:"behavior"},"Behavior"),(0,i.kt)("p",null,"Events are serialized to JSON, and then are send as HTTP POST request with ",(0,i.kt)("inlineCode",{parentName:"p"},"Content-Type: application/json"),"."),(0,i.kt)("h4",{id:"examples"},"Examples"),(0,i.kt)(r.Z,{groupId:"integrations",mdxType:"Tabs"},(0,i.kt)(l.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,i.kt)("p",null,"Anonymous connection:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: http\n  url: http://localhost:5000\n")),(0,i.kt)("p",null,"With authorization:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: http\n  url: http://localhost:5000\n  auth:\n    type: api_key\n    api_key: f38d2189-c603-4b46-bdea-e573a3b5a7d5\n")),(0,i.kt)("p",null,"Full example:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: http\n  url: http://localhost:5000\n  endpoint: /api/v1/lineage\n  urlParams:\n    param0: value0\n    param1: value1\n  timeoutInMillis: 5000\n  auth:\n    type: api_key\n    api_key: f38d2189-c603-4b46-bdea-e573a3b5a7d5\n  headers:\n    X-Some-Extra-Header: abc\n  compression: gzip\n"))),(0,i.kt)(l.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,i.kt)("p",null,"Anonymous connection:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-ini"},"spark.openlineage.transport.type=http\nspark.openlineage.transport.url=http://localhost:5000\n")),(0,i.kt)("p",null,"With authorization:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-ini"},"spark.openlineage.transport.type=http\nspark.openlineage.transport.url=http://localhost:5000\nspark.openlineage.transport.auth.type=api_key\nspark.openlineage.transport.auth.apiKey=f38d2189-c603-4b46-bdea-e573a3b5a7d5\n")),(0,i.kt)("p",null,"Full example:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-ini"},"spark.openlineage.transport.type=http\nspark.openlineage.transport.url=http://localhost:5000\nspark.openlineage.transport.endpoint=/api/v1/lineage\nspark.openlineage.transport.urlParams.param0=value0\nspark.openlineage.transport.urlParams.param1=value1\nspark.openlineage.transport.timeoutInMillis=5000\nspark.openlineage.transport.auth.type=api_key\nspark.openlineage.transport.auth.apiKey=f38d2189-c603-4b46-bdea-e573a3b5a7d5\nspark.openlineage.transport.headers.X-Some-Extra-Header=abc\nspark.openlineage.transport.compression=gzip\n")),(0,i.kt)("details",null,(0,i.kt)("summary",null,"URL parsing within Spark integration"),(0,i.kt)("p",null,(0,i.kt)("p",null,"You can supply http parameters using values in url, the parsed ",(0,i.kt)("inlineCode",{parentName:"p"},"spark.openlineage.*")," properties are located in url as follows:"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"{transport.url}/{transport.endpoint}/namespaces/{namespace}/jobs/{parentJobName}/runs/{parentRunId}?app_name={appName}&api_key={transport.apiKey}&timeout={transport.timeout}&xxx={transport.urlParams.xxx}")),(0,i.kt)("p",null,"example:"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"http://localhost:5000/api/v1/namespaces/ns_name/jobs/job_name/runs/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx?app_name=app&api_key=abc&timeout=5000&xxx=xxx"))))),(0,i.kt)(l.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,i.kt)("p",null,"Anonymous connection:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-ini"},"spark.openlineage.transport.type=http\nspark.openlineage.transport.url=http://localhost:5000\n")),(0,i.kt)("p",null,"With authorization:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-ini"},"openlineage.transport.type=http\nopenlineage.transport.url=http://localhost:5000\nopenlineage.transport.auth.type=api_key\nopenlineage.transport.auth.apiKey=f38d2189-c603-4b46-bdea-e573a3b5a7d5\n")),(0,i.kt)("p",null,"Full example:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-ini"},"openlineage.transport.type=http\nopenlineage.transport.url=http://localhost:5000\nopenlineage.transport.endpoint=/api/v1/lineage\nopenlineage.transport.urlParams.param0=value0\nopenlineage.transport.urlParams.param1=value1\nopenlineage.transport.timeoutInMillis=5000\nopenlineage.transport.auth.type=api_key\nopenlineage.transport.auth.apiKey=f38d2189-c603-4b46-bdea-e573a3b5a7d5\nopenlineage.transport.headers.X-Some-Extra-Header=abc\nopenlineage.transport.compression=gzip\n"))),(0,i.kt)(l.Z,{value:"java",label:"Java Code",mdxType:"TabItem"},(0,i.kt)("p",null,"Anonymous connection:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},'import io.openlineage.client.OpenLineageClient;\nimport io.openlineage.client.transports.HttpConfig;\nimport io.openlineage.client.transports.HttpTransport;\n\nHttpConfig httpConfig = new HttpConfig();\nhttpConfig.setUrl("http://localhost:5000");\n\nOpenLineageClient client = OpenLineageClient.builder()\n  .transport(\n    new HttpTransport(httpConfig))\n  .build();\n')),(0,i.kt)("p",null,"With authorization:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},'import io.openlineage.client.OpenLineageClient;\nimport io.openlineage.client.transports.ApiKeyTokenProvider;\nimport io.openlineage.client.transports.HttpConfig;\nimport io.openlineage.client.transports.HttpTransport;\n\nApiKeyTokenProvider apiKeyTokenProvider = new ApiKeyTokenProvider();\napiKeyTokenProvider.setApiKey("f38d2189-c603-4b46-bdea-e573a3b5a7d5");\n\nHttpConfig httpConfig = new HttpConfig();\nhttpConfig.setUrl("http://localhost:5000");\nhttpConfig.setAuth(apiKeyTokenProvider);\n\nOpenLineageClient client = OpenLineageClient.builder()\n  .transport(\n    new HttpTransport(httpConfig))\n  .build();\n')),(0,i.kt)("p",null,"Full example:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},'import java.util.Map;\n\nimport io.openlineage.client.OpenLineageClient;\nimport io.openlineage.client.transports.ApiKeyTokenProvider;\nimport io.openlineage.client.transports.HttpConfig;\nimport io.openlineage.client.transports.HttpTransport;\n\nMap<String, String> queryParams = Map.of(\n    "param0", "value0",\n    "param1", "value1"\n);\n\nMap<String, String> headers = Map.of(\n  "X-Some-Extra-Header", "abc"\n);\n\nApiKeyTokenProvider apiKeyTokenProvider = new ApiKeyTokenProvider();\napiKeyTokenProvider.setApiKey("f38d2189-c603-4b46-bdea-e573a3b5a7d5");\n\nHttpConfig httpConfig = new HttpConfig();\nhttpConfig.setUrl("http://localhost:5000");\nhttpConfig.setEndpoint("/api/v1/lineage");\nhttpConfig.setUrlParams(queryParams);\nhttpConfig.setAuth(apiKeyTokenProvider);\nhttpConfig.setTimeoutInMillis(headers);\nhttpConfig.setHeaders(5000);\nhttpConfig.setCompression(HttpConfig.Compression.GZIP);\n\nOpenLineageClient client = OpenLineageClient.builder()\n  .transport(\n    new HttpTransport(httpConfig))\n  .build();\n')))),(0,i.kt)("h3",{id:"kafka"},(0,i.kt)("a",{parentName:"h3",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java/src/main/java/io/openlineage/client/transports/KafkaTransport.java"},"Kafka")),(0,i.kt)("p",null,"If a transport type is set to ",(0,i.kt)("inlineCode",{parentName:"p"},"kafka"),", then the below parameters would be read and used when building KafkaProducer.\nThis transport requires the artifact ",(0,i.kt)("inlineCode",{parentName:"p"},"org.apache.kafka:kafka-clients:3.1.0")," (or compatible) on your classpath."),(0,i.kt)("h4",{id:"configuration-1"},"Configuration"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"type")," - string, must be ",(0,i.kt)("inlineCode",{parentName:"p"},'"kafka"'),". Required.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"topicName")," - string specifying the topic on what events will be sent. Required.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"properties")," - a dictionary containing a Kafka producer config as in ",(0,i.kt)("a",{parentName:"p",href:"http://kafka.apache.org/0100/documentation.html#producerconfigs"},"Kafka producer config"),". Required.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"localServerId")," - ",(0,i.kt)("strong",{parentName:"p"},"deprecated"),", renamed to ",(0,i.kt)("inlineCode",{parentName:"p"},"messageKey")," since v1.13.0.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"messageKey")," - string, key for all Kafka messages produced by transport. Optional, default value described below. Added in v1.13.0."),(0,i.kt)("p",{parentName:"li"},"Default values for ",(0,i.kt)("inlineCode",{parentName:"p"},"messageKey")," are:"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"run:{parentJob.namespace}/{parentJob.name}")," - for RunEvent with parent facet"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"run:{job.namespace}/{job.name}")," - for RunEvent"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"job:{job.namespace}/{job.name}")," - for JobEvent"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"dataset:{dataset.namespace}/{dataset.name}")," - for DatasetEvent")))),(0,i.kt)("h4",{id:"behavior-1"},"Behavior"),(0,i.kt)("p",null,"Events are serialized to JSON, and then dispatched to the Kafka topic."),(0,i.kt)("h4",{id:"notes"},"Notes"),(0,i.kt)("p",null,"It is recommended to provide ",(0,i.kt)("inlineCode",{parentName:"p"},"messageKey")," if Job hierarchy is used. It can be any string, but it should be the same for all jobs in\nhierarchy, like ",(0,i.kt)("inlineCode",{parentName:"p"},"Airflow task -> Spark application -> Spark task runs"),"."),(0,i.kt)("h4",{id:"examples-1"},"Examples"),(0,i.kt)(r.Z,{groupId:"integrations",mdxType:"Tabs"},(0,i.kt)(l.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: kafka\n  topicName: openlineage.events\n  properties:\n    bootstrap.servers: localhost:9092,another.host:9092\n    acks: all\n    retries: 3\n    key.serializer: org.apache.kafka.common.serialization.StringSerializer\n    value.serializer: org.apache.kafka.common.serialization.StringSerializer\n  messageKey: some-value\n"))),(0,i.kt)(l.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-ini"},"spark.openlineage.transport.type=kafka\nspark.openlineage.transport.topicName=openlineage.events\nspark.openlineage.transport.properties.bootstrap.servers=localhost:9092,another.host:9092\nspark.openlineage.transport.properties.acks=all\nspark.openlineage.transport.properties.retries=3\nspark.openlineage.transport.properties.key.serializer=org.apache.kafka.common.serialization.StringSerializer\nspark.openlineage.transport.properties.value.serializer=org.apache.kafka.common.serialization.StringSerializer\nspark.openlineage.transport.messageKey=some-value\n"))),(0,i.kt)(l.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-ini"},"openlineage.transport.type=kafka\nopenlineage.transport.topicName=openlineage.events\nopenlineage.transport.properties.bootstrap.servers=localhost:9092,another.host:9092\nopenlineage.transport.properties.acks=all\nopenlineage.transport.properties.retries=3\nopenlineage.transport.properties.key.serializer=org.apache.kafka.common.serialization.StringSerializer\nopenlineage.transport.properties.value.serializer=org.apache.kafka.common.serialization.StringSerializer\nopenlineage.transport.messageKey=some-value\n"))),(0,i.kt)(l.Z,{value:"java",label:"Java Code",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},'import java.util.Properties;\n\nimport io.openlineage.client.OpenLineageClient;\nimport io.openlineage.client.transports.KafkaConfig;\nimport io.openlineage.client.transports.KafkaTransport;\n\nProperties kafkaProperties = new Properties();\nkafkaProperties.setProperty("bootstrap.servers", "localhost:9092,another.host:9092");\nkafkaProperties.setProperty("acks", "all");\nkafkaProperties.setProperty("retries", "3");\nkafkaProperties.setProperty("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");\nkafkaProperties.setProperty("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");\n\nKafkaConfig kafkaConfig = new KafkaConfig();\nKafkaConfig.setTopicName("openlineage.events");\nKafkaConfig.setProperties(kafkaProperties);\nKafkaConfig.setLocalServerId("some-value");\n\nOpenLineageClient client = OpenLineageClient.builder()\n  .transport(\n    new KafkaTransport(httpConfig))\n  .build();\n')))),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"Notes"),":\nIt is recommended to provide ",(0,i.kt)("inlineCode",{parentName:"p"},"messageKey")," if Job hierarchy is used. It can be any string, but it should be the same for all jobs in\nhierarchy, like ",(0,i.kt)("inlineCode",{parentName:"p"},"Airflow task -> Spark application"),"."),(0,i.kt)("p",null,"Default values are:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"run:{parentJob.namespace}/{parentJob.name}/{parentRun.id}")," - for RunEvent with parent facet"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"run:{job.namespace}/{job.name}/{run.id}")," - for RunEvent"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"job:{job.namespace}/{job.name}")," - for JobEvent"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"dataset:{dataset.namespace}/{dataset.name}")," - for DatasetEvent")),(0,i.kt)("h3",{id:"kinesis"},(0,i.kt)("a",{parentName:"h3",href:"https://github.com/OpenLineage/OpenLineage/blob/main/client/java/src/main/java/io/openlineage/client/transports/KinesisTransport.java"},"Kinesis")),(0,i.kt)("p",null,"If a transport type is set to ",(0,i.kt)("inlineCode",{parentName:"p"},"kinesis"),", then the below parameters would be read and used when building KinesisProducer.\nAlso, KinesisTransport depends on you to provide artifact ",(0,i.kt)("inlineCode",{parentName:"p"},"com.amazonaws:amazon-kinesis-producer:0.14.0")," or compatible on your classpath."),(0,i.kt)("h4",{id:"configuration-2"},"Configuration"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"type")," - string, must be ",(0,i.kt)("inlineCode",{parentName:"li"},'"kinesis"'),". Required."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"streamName")," - the streamName of the Kinesis. Required."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"region")," - the region of the Kinesis. Required."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"roleArn")," - the roleArn which is allowed to read/write to Kinesis stream. Optional."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"properties")," - a dictionary that contains a ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/awslabs/amazon-kinesis-producer/blob/master/java/amazon-kinesis-producer-sample/default_config.properties"},"Kinesis allowed properties"),". Optional.")),(0,i.kt)("h4",{id:"behavior-2"},"Behavior"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Events are serialized to JSON, and then dispatched to the Kinesis stream."),(0,i.kt)("li",{parentName:"ul"},"The partition key is generated as ",(0,i.kt)("inlineCode",{parentName:"li"},"{jobNamespace}:{jobName}"),"."),(0,i.kt)("li",{parentName:"ul"},"Two constructors are available: one accepting both ",(0,i.kt)("inlineCode",{parentName:"li"},"KinesisProducer")," and ",(0,i.kt)("inlineCode",{parentName:"li"},"KinesisConfig")," and another solely accepting ",(0,i.kt)("inlineCode",{parentName:"li"},"KinesisConfig"),".")),(0,i.kt)("h4",{id:"examples-2"},"Examples"),(0,i.kt)(r.Z,{groupId:"integrations",mdxType:"Tabs"},(0,i.kt)(l.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: kinesis\n  streamName: your_kinesis_stream_name\n  region: your_aws_region\n  roleArn: arn:aws:iam::account-id:role/role-name\n  properties:\n    VerifyCertificate: true\n    ConnectTimeout: 6000\n"))),(0,i.kt)(l.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-ini"},"spark.openlineage.transport.type=kinesis\nspark.openlineage.transport.streamName=your_kinesis_stream_name\nspark.openlineage.transport.region=your_aws_region\nspark.openlineage.transport.roleArn=arn:aws:iam::account-id:role/role-name\nspark.openlineage.transport.properties.VerifyCertificate=true\nspark.openlineage.transport.properties.ConnectTimeout=6000\n"))),(0,i.kt)(l.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-ini"},"openlineage.transport.type=kinesis\nopenlineage.transport.streamName=your_kinesis_stream_name\nopenlineage.transport.region=your_aws_region\nopenlineage.transport.roleArn=arn:aws:iam::account-id:role/role-name\nopenlineage.transport.properties.VerifyCertificate=true\nopenlineage.transport.properties.ConnectTimeout=6000\n"))),(0,i.kt)(l.Z,{value:"java",label:"Java Code",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},'import java.util.Properties;\n\nimport io.openlineage.client.OpenLineageClient;\nimport io.openlineage.client.transports.KinesisConfig;\nimport io.openlineage.client.transports.KinesisTransport;\n\nProperties kinesisProperties = new Properties();\nkinesisProperties.setProperty("property_name_1", "value_1");\nkinesisProperties.setProperty("property_name_2", "value_2");\n\nKinesisConfig kinesisConfig = new KinesisConfig();\nkinesisConfig.setStreamName("your_kinesis_stream_name");\nkinesisConfig.setRegion("your_aws_region");\nkinesisConfig.setRoleArn("arn:aws:iam::account-id:role/role-name");\nkinesisConfig.setProperties(kinesisProperties);\n\nOpenLineageClient client = OpenLineageClient.builder()\n  .transport(\n    new KinesisTransport(httpConfig))\n  .build();\n')))),(0,i.kt)("h3",{id:"console"},(0,i.kt)("a",{parentName:"h3",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java/src/main/java/io/openlineage/client/transports/ConsoleTransport.java"},"Console")),(0,i.kt)("p",null,"This straightforward transport emits OpenLineage events directly to the console through a logger.\nNo additional configuration is required."),(0,i.kt)("h4",{id:"behavior-3"},"Behavior"),(0,i.kt)("p",null,"Events are serialized to JSON. Then each event is logged with ",(0,i.kt)("inlineCode",{parentName:"p"},"INFO")," level to logger with name ",(0,i.kt)("inlineCode",{parentName:"p"},"ConsoleTransport"),"."),(0,i.kt)("h4",{id:"notes-1"},"Notes"),(0,i.kt)("p",null,"Be cautious when using the ",(0,i.kt)("inlineCode",{parentName:"p"},"DEBUG")," log level, as it might result in double-logging due to the ",(0,i.kt)("inlineCode",{parentName:"p"},"OpenLineageClient")," also logging."),(0,i.kt)("h4",{id:"configuration-3"},"Configuration"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"type")," - string, must be ",(0,i.kt)("inlineCode",{parentName:"li"},'"console"'),". Required.")),(0,i.kt)("h4",{id:"examples-3"},"Examples"),(0,i.kt)(r.Z,{groupId:"integrations",mdxType:"Tabs"},(0,i.kt)(l.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: console\n"))),(0,i.kt)(l.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-ini"},"spark.openlineage.transport.type=console\n"))),(0,i.kt)(l.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-ini"},"openlineage.transport.type=console\n"))),(0,i.kt)(l.Z,{value:"java",label:"Java Code",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"import java.util.Properties;\n\nimport io.openlineage.client.OpenLineageClient;\nimport io.openlineage.client.transports.ConsoleTransport;\n\nOpenLineageClient client = OpenLineageClient.builder()\n  .transport(\n    new ConsoleTransport())\n  .build();\n")))),(0,i.kt)("h3",{id:"file"},(0,i.kt)("a",{parentName:"h3",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java/src/main/java/io/openlineage/client/transports/FileTransport.java"},"File")),(0,i.kt)("p",null,"Designed mainly for integration testing, the ",(0,i.kt)("inlineCode",{parentName:"p"},"FileTransport")," emits OpenLineage events to a given file."),(0,i.kt)("h4",{id:"configuration-4"},"Configuration"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"type")," - string, must be ",(0,i.kt)("inlineCode",{parentName:"li"},'"file"'),". Required."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"location")," - string specifying the path of the file. Required.")),(0,i.kt)("h4",{id:"behavior-4"},"Behavior"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"If the target file is absent, it's created."),(0,i.kt)("li",{parentName:"ul"},"Events are serialized to JSON, and then appended to a file, separated by newlines."),(0,i.kt)("li",{parentName:"ul"},"Intrinsic newline characters within the event JSON are eliminated to ensure one-line events.")),(0,i.kt)("h4",{id:"notes-for-yarnkubernetes"},"Notes for Yarn/Kubernetes"),(0,i.kt)("p",null,"This transport type is pretty useless on Spark/Flink applications deployed to Yarn or Kubernetes cluster:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Each executor will write file to a local filesystem of Yarn container/K8s pod. So resulting file will be removed when such container/pod is destroyed."),(0,i.kt)("li",{parentName:"ul"},"Kubernetes persistent volumes are not destroyed after pod removal. But all the executors will write to the same network disk in parallel, producing a broken file.")),(0,i.kt)("h4",{id:"examples-4"},"Examples"),(0,i.kt)(r.Z,{groupId:"integrations",mdxType:"Tabs"},(0,i.kt)(l.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: file\n  location: /path/to/your/file\n"))),(0,i.kt)(l.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-ini"},"spark.openlineage.transport.type=file\nspark.openlineage.transport.location=/path/to/your/filext\n"))),(0,i.kt)(l.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-ini"},"openlineage.transport.type=file\nopenlineage.transport.location=/path/to/your/file\n"))),(0,i.kt)(l.Z,{value:"java",label:"Java Code",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},'import java.util.Properties;\n\nimport io.openlineage.client.OpenLineageClient;\nimport io.openlineage.client.transports.FileConfig;\nimport io.openlineage.client.transports.FileTransport;\n\nFileConfig fileConfig = new FileConfig("/path/to/your/file");\n\nOpenLineageClient client = OpenLineageClient.builder()\n  .transport(\n    new FileTransport(fileConfig))\n  .build();\n')))))}p.isMDXComponent=!0},3058:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>u,contentTitle:()=>p,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>m});var a=n(87462),i=(n(67294),n(3905)),r=n(55154),l=n(81742);const o={sidebar_position:4,title:"Apache Flink"},p=void 0,s={unversionedId:"integrations/flink",id:"integrations/flink",title:"Apache Flink",description:"Apache Flink is one of the most popular stream processing frameworks. Apache Flink jobs run on clusters,",source:"@site/docs/integrations/flink.md",sourceDirName:"integrations",slug:"/integrations/flink",permalink:"/docs/integrations/flink",draft:!1,editUrl:"https://github.com/OpenLineage/docs/tree/main/docs/integrations/flink.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4,title:"Apache Flink"},sidebar:"tutorialSidebar",previous:{title:"Job Hierarchy",permalink:"/docs/integrations/airflow/job-hierarchy"},next:{title:"dbt",permalink:"/docs/integrations/dbt"}},u={},m=[{value:"Getting lineage from Flink",id:"getting-lineage-from-flink",level:2},{value:"Limitations",id:"limitations",level:2},{value:"Usage",id:"usage",level:2},{value:"Configuring Openlineage connector",id:"configuring-openlineage-connector",level:2},{value:"Flink Configuration parameters",id:"flink-configuration-parameters",level:3},{value:"Transports",id:"transports",level:2},{value:"Circuit Breakers",id:"circuit-breakers",level:2}],k={toc:m};function d(e){let{components:t,...n}=e;return(0,i.kt)("wrapper",(0,a.Z)({},k,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Apache Flink")," is one of the most popular stream processing frameworks. Apache Flink jobs run on clusters,\nwhich are composed of two types of nodes: ",(0,i.kt)("inlineCode",{parentName:"p"},"TaskManagers")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"JobManagers"),". While clusters typically consists of\nmultiple ",(0,i.kt)("inlineCode",{parentName:"p"},"TaskManagers"),", only reason to run multiple JobManagers is high availability. The jobs are ",(0,i.kt)("em",{parentName:"p"},"submitted"),"\nto ",(0,i.kt)("inlineCode",{parentName:"p"},"JobManager")," by ",(0,i.kt)("inlineCode",{parentName:"p"},"JobClient"),", that compiles user application into dataflow graph which is understandable by ",(0,i.kt)("inlineCode",{parentName:"p"},"JobManager"),".\n",(0,i.kt)("inlineCode",{parentName:"p"},"JobManager")," then coordinates job execution: it splits the parallel units of a job\nto ",(0,i.kt)("inlineCode",{parentName:"p"},"TaskManagers"),", manages heartbeats, triggers checkpoints, reacts to failures and much more."),(0,i.kt)("p",null,"Apache Flink has multiple deployment modes - Session Mode, Application Mode and Per-Job mode. The most popular\nare Session Mode and Application Mode. Session Mode consists of a ",(0,i.kt)("inlineCode",{parentName:"p"},"JobManager")," managing multiple jobs sharing single\nFlink cluster. In this mode, ",(0,i.kt)("inlineCode",{parentName:"p"},"JobClient")," is executed on a machine that submits the job to the cluster."),(0,i.kt)("p",null,"Application Mode is used where cluster is utilized for a single job. In this mode, ",(0,i.kt)("inlineCode",{parentName:"p"},"JobClient"),", where the main method runs,\nis executed on the ",(0,i.kt)("inlineCode",{parentName:"p"},"JobManager"),"."),(0,i.kt)("p",null,"Flink jobs read data from ",(0,i.kt)("inlineCode",{parentName:"p"},"Sources")," and write data to ",(0,i.kt)("inlineCode",{parentName:"p"},"Sinks"),". In contrast to systems like Apache Spark, Flink jobs can write\ndata to multiple places - they can have multiple ",(0,i.kt)("inlineCode",{parentName:"p"},"Sinks"),"."),(0,i.kt)("h2",{id:"getting-lineage-from-flink"},"Getting lineage from Flink"),(0,i.kt)("p",null,"OpenLineage utilizes Flink's ",(0,i.kt)("inlineCode",{parentName:"p"},"JobListener")," interface. This interface is used by Flink to notify user of job submission,\nsuccessful finish of job, or job failure. Implementations of this interface are executed on ",(0,i.kt)("inlineCode",{parentName:"p"},"JobClient"),". "),(0,i.kt)("p",null,"When OpenLineage listener receives information that job was submitted, it extracts ",(0,i.kt)("inlineCode",{parentName:"p"},"Transformations")," from job's\n",(0,i.kt)("inlineCode",{parentName:"p"},"ExecutionEnvironment"),". The ",(0,i.kt)("inlineCode",{parentName:"p"},"Transformations")," represent logical operations in the dataflow graph; they are composed\nof both Flink's build-in operators, but also user-provided ",(0,i.kt)("inlineCode",{parentName:"p"},"Sources"),", ",(0,i.kt)("inlineCode",{parentName:"p"},"Sinks")," and functions. To get the lineage,\nOpenLineage integration processes dataflow graph. Currently, OpenLineage is interested only in information contained\nin ",(0,i.kt)("inlineCode",{parentName:"p"},"Sources")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"Sinks"),", as they are the places where Flink interacts with external systems. "),(0,i.kt)("p",null,"After job submission, OpenLineage integration starts actively listening to checkpoints - this gives insight into\nwhether the job runs properly."),(0,i.kt)("h2",{id:"limitations"},"Limitations"),(0,i.kt)("p",null,"Currently, OpenLineage's Flink integration is limited to getting information from jobs running in Application Mode."),(0,i.kt)("p",null,"OpenLineage integration extracts lineage only from following ",(0,i.kt)("inlineCode",{parentName:"p"},"Sources")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"Sinks"),":"),(0,i.kt)("table",null,(0,i.kt)("tbody",null,(0,i.kt)("tr",null,(0,i.kt)("th",null,"Sources"),(0,i.kt)("th",null,"Sinks")),(0,i.kt)("tr",null,(0,i.kt)("td",null,"KafkaSource"),(0,i.kt)("td",null,"KafkaSink (1)")),(0,i.kt)("tr",null,(0,i.kt)("td",null,"FlinkKafkaConsumer"),(0,i.kt)("td",null,"FlinkKafkaProducer")),(0,i.kt)("tr",null,(0,i.kt)("td",null,"IcebergFlinkSource"),(0,i.kt)("td",null,"IcebergFlinkSink")))),(0,i.kt)("p",null,"We expect this list to grow as we add support for more connectors."),(0,i.kt)("p",null,"(1) KafkaSink supports sinks that write to a single topic as well as multi topic sinks. The\nlimitation for multi topic sink is that: topics need to have the same schema and implementation\nof ",(0,i.kt)("inlineCode",{parentName:"p"},"KafkaRecordSerializationSchema")," must extend ",(0,i.kt)("inlineCode",{parentName:"p"},"KafkaTopicsDescriptor"),".\nMethods ",(0,i.kt)("inlineCode",{parentName:"p"},"isFixedTopics")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"getFixedTopics")," from ",(0,i.kt)("inlineCode",{parentName:"p"},"KafkaTopicsDescriptor")," are used to extract multiple topics\nfrom a sink. "),(0,i.kt)("h2",{id:"usage"},"Usage"),(0,i.kt)("p",null,"In your job, you need to set up ",(0,i.kt)("inlineCode",{parentName:"p"},"OpenLineageFlinkJobListener"),"."),(0,i.kt)("p",null,"For example:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"JobListener listener = OpenLineageFlinkJobListener.builder()\n    .executionEnvironment(streamExecutionEnvironment)\n    .build();\nstreamExecutionEnvironment.registerJobListener(listener);\n")),(0,i.kt)("p",null,"Also, OpenLineage needs certain parameters to be set in ",(0,i.kt)("inlineCode",{parentName:"p"},"flink-conf.yaml"),":"),(0,i.kt)("table",null,(0,i.kt)("tbody",null,(0,i.kt)("tr",null,(0,i.kt)("th",null,"Configuration Key"),(0,i.kt)("th",null,"Description"),(0,i.kt)("th",null,"Expected Value"),(0,i.kt)("th",null,"Default")),(0,i.kt)("tr",null,(0,i.kt)("td",null,"execution.attached"),(0,i.kt)("td",null,"This setting needs to be true if OpenLineage is to detect job start and failure"),(0,i.kt)("td",null,"true"),(0,i.kt)("td",null,"false")))),(0,i.kt)("p",null,"OpenLineage jar needs to be present on ",(0,i.kt)("inlineCode",{parentName:"p"},"JobManager"),"."),(0,i.kt)("p",null,"When the ",(0,i.kt)("inlineCode",{parentName:"p"},"JobListener")," is configured, you need to point the OpenLineage integration where the events should end up.\nIf you're using ",(0,i.kt)("inlineCode",{parentName:"p"},"Marquez"),", simplest way to do that is to set up ",(0,i.kt)("inlineCode",{parentName:"p"},"OPENLINEAGE_URL")," environment\nvariable to ",(0,i.kt)("inlineCode",{parentName:"p"},"Marquez")," URL. More advanced settings are ",(0,i.kt)("a",{parentName:"p",href:"/docs/client/java/"},"in the client documentation."),"."),(0,i.kt)("h2",{id:"configuring-openlineage-connector"},"Configuring Openlineage connector"),(0,i.kt)("p",null,"Flink Openlineage connector utilizes standard ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java"},"Java client for Openlineage"),"\nand allows all the configuration features present there to be used. The configuration can be passed with:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"openlineage.yml")," file with a environment property ",(0,i.kt)("inlineCode",{parentName:"li"},"OPENLINEAGE_CONFIG")," being set and pointing to configuration file. File structure and allowed options are described ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java#configuration"},"here"),"."),(0,i.kt)("li",{parentName:"ul"},"Standard Flink configuration with the parameters defined below.")),(0,i.kt)("h3",{id:"flink-configuration-parameters"},"Flink Configuration parameters"),(0,i.kt)("p",null,"The following parameters can be specified:"),(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,i.kt)("th",{parentName:"tr",align:null},"Definition"),(0,i.kt)("th",{parentName:"tr",align:null},"Example"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"openlineage.transport.type"),(0,i.kt)("td",{parentName:"tr",align:null},"The transport type used for event emit, default type is ",(0,i.kt)("inlineCode",{parentName:"td"},"console")),(0,i.kt)("td",{parentName:"tr",align:null},"http")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"openlineage.facets.disabled"),(0,i.kt)("td",{parentName:"tr",align:null},"List of facets to disable, enclosed in ",(0,i.kt)("inlineCode",{parentName:"td"},"[]")," (required from 0.21.x) and separated by ",(0,i.kt)("inlineCode",{parentName:"td"},";"),", default is ",(0,i.kt)("inlineCode",{parentName:"td"},"[spark_unknown;spark.logicalPlan;]")," (currently must contain ",(0,i.kt)("inlineCode",{parentName:"td"},";"),")"),(0,i.kt)("td",{parentName:"tr",align:null},"[","some_facet1;some_facet1","]")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"openlineage.job.owners.<ownership-type",">"),(0,i.kt)("td",{parentName:"tr",align:null},"Specifies ownership of the job. Multiple entries with different types are allowed. Config key name and value are used to create job ownership type and name (available since 1.13)."),(0,i.kt)("td",{parentName:"tr",align:null},'openlineage.job.owners.team="Some Team"')))),(0,i.kt)("h2",{id:"transports"},"Transports"),(0,i.kt)(r.ZP,{mdxType:"Transports"}),(0,i.kt)("h2",{id:"circuit-breakers"},"Circuit Breakers"),(0,i.kt)(l.ZP,{mdxType:"CircuitBreakers"}))}d.isMDXComponent=!0}}]);