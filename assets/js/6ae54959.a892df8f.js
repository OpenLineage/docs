"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8605],{3905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>u});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var p=n.createContext({}),s=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},m=function(e){var t=s(e.components);return n.createElement(p.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,p=e.parentName,m=o(e,["components","mdxType","originalType","parentName"]),c=s(a),u=r,k=c["".concat(p,".").concat(u)]||c[u]||d[u]||i;return a?n.createElement(k,l(l({ref:t},m),{},{components:a})):n.createElement(k,l({ref:t},m))}));function u(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,l=new Array(i);l[0]=c;var o={};for(var p in t)hasOwnProperty.call(t,p)&&(o[p]=t[p]);o.originalType=e,o.mdxType="string"==typeof e?e:r,l[1]=o;for(var s=2;s<i;s++)l[s]=a[s];return n.createElement.apply(null,l)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},5824:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>d,frontMatter:()=>i,metadata:()=>o,toc:()=>s});var n=a(7462),r=(a(7294),a(3905));const i={title:"1.5.0",sidebar_position:9952},l="1.5.0 - 2023-11-2",o={unversionedId:"releases/1_5_0",id:"releases/1_5_0",title:"1.5.0",description:"Added",source:"@site/docs/releases/1_5_0.md",sourceDirName:"releases",slug:"/releases/1_5_0",permalink:"/docs/releases/1_5_0",draft:!1,editUrl:"https://github.com/OpenLineage/docs/tree/main/docs/releases/1_5_0.md",tags:[],version:"current",sidebarPosition:9952,frontMatter:{title:"1.5.0",sidebar_position:9952},sidebar:"tutorialSidebar",previous:{title:"OpenLineage Proxy",permalink:"/docs/development/ol-proxy"},next:{title:"1.4.1",permalink:"/docs/releases/1_4_1"}},p={},s=[{value:"Added",id:"added",level:3},{value:"Changed",id:"changed",level:3},{value:"Fixed",id:"fixed",level:3}],m={toc:s};function d(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"150---2023-11-2"},"1.5.0 - 2023-11-2"),(0,r.kt)("h3",{id:"added"},"Added"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Flink: add Flink lineage for Cassandra Connectors")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2175"},(0,r.kt)("inlineCode",{parentName:"a"},"#2175"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/HuangZhenQiu"},"@HuangZhenQiu"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Adds Flink Cassandra source and sink visitors and Flink Cassandra Integration test.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: support ",(0,r.kt)("inlineCode",{parentName:"strong"},"rdd")," and ",(0,r.kt)("inlineCode",{parentName:"strong"},"toDF")," operations available in Spark Scala API")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2188"},(0,r.kt)("inlineCode",{parentName:"a"},"#2188"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/pawel-big-lebowski"},"@pawel-big-lebowski"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Includes the first Scala integration test, fixes ",(0,r.kt)("inlineCode",{parentName:"em"},"ExternalRddVisitor")," and adds support for extracting inputs from ",(0,r.kt)("inlineCode",{parentName:"em"},"MapPartitionsRDD")," and ",(0,r.kt)("inlineCode",{parentName:"em"},"ParallelCollectionRDD")," plan nodes.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: support Databricks Runtime 13.3")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2185"},(0,r.kt)("inlineCode",{parentName:"a"},"#2185"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/pawel-big-lebowski"},"@pawel-big-lebowski"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Modifies the Spark integration to support the latest Databricks Runtime version."))),(0,r.kt)("h3",{id:"changed"},"Changed"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Airflow: loosen attrs and requests versions")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2107"},(0,r.kt)("inlineCode",{parentName:"a"},"#2107"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/JDarDagran"},"@JDarDagran"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Lowers the version requirements for attrs and requests and removes an unnecessary dependency.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"dbt: render yaml configs lazily")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2221"},(0,r.kt)("inlineCode",{parentName:"a"},"#2221"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/JDarDagran"},"@JDarDagran"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Don't render each entry in yaml files at start.")," ")),(0,r.kt)("h3",{id:"fixed"},"Fixed"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Airflow/Athena: change dataset name to its location")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2167"},(0,r.kt)("inlineCode",{parentName:"a"},"#2167"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/sophiely"},"@sophiely"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Replaces the dataset and namespace with the data's physical location for more complete lineage across integrations.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Python client: skip redaction in column lineage facet")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2177"},(0,r.kt)("inlineCode",{parentName:"a"},"#2177"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/JDarDagran"},"@JDarDagran"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Redacted fields in ",(0,r.kt)("inlineCode",{parentName:"em"},"ColumnLineageDatasetFacetFieldsAdditionalInputFields")," are now skipped.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: unify dataset naming for RDD jobs and Spark SQL")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2181"},(0,r.kt)("inlineCode",{parentName:"a"},"#2181"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/pawel-big-lebowski"},"@pawel-big-lebowski"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Use the same mechanism for RDD jobs to extract dataset identifier as used for Spark SQL.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: ensure a single ",(0,r.kt)("inlineCode",{parentName:"strong"},"START")," and a single ",(0,r.kt)("inlineCode",{parentName:"strong"},"COMPLETE")," event are sent")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2103"},(0,r.kt)("inlineCode",{parentName:"a"},"#2103"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/pawel-big-lebowski"},"@pawel-big-lebowski"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"For Spark SQL at least four events are sent triggered by different SparkListener methods. Each of them is required and used to collect facets unavailable elsewhere. However, there should be only one ",(0,r.kt)("inlineCode",{parentName:"em"},"START")," and ",(0,r.kt)("inlineCode",{parentName:"em"},"COMPLETE")," events emitted. Other events should be sent as ",(0,r.kt)("inlineCode",{parentName:"em"},"RUNNING"),". Please keep in mind that Spark integration remains stateless to limit the memory footprint, and it is the backend responsibility to merge several Openlineage events into a meaningful snapshot of metadata changes."))))}d.isMDXComponent=!0}}]);