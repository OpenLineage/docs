"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[529],{3905:(e,a,t)=>{t.d(a,{Zo:()=>p,kt:()=>m});var n=t(67294);function s(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function o(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function i(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?o(Object(t),!0).forEach((function(a){s(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function r(e,a){if(null==e)return{};var t,n,s=function(e,a){if(null==e)return{};var t,n,s={},o=Object.keys(e);for(n=0;n<o.length;n++)t=o[n],a.indexOf(t)>=0||(s[t]=e[t]);return s}(e,a);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)t=o[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(s[t]=e[t])}return s}var l=n.createContext({}),c=function(e){var a=n.useContext(l),t=a;return e&&(t="function"==typeof e?e(a):i(i({},a),e)),t},p=function(e){var a=c(e.components);return n.createElement(l.Provider,{value:a},e.children)},d={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},h=n.forwardRef((function(e,a){var t=e.components,s=e.mdxType,o=e.originalType,l=e.parentName,p=r(e,["components","mdxType","originalType","parentName"]),h=c(t),m=s,u=h["".concat(l,".").concat(m)]||h[m]||d[m]||o;return t?n.createElement(u,i(i({ref:a},p),{},{components:t})):n.createElement(u,i({ref:a},p))}));function m(e,a){var t=arguments,s=a&&a.mdxType;if("string"==typeof e||s){var o=t.length,i=new Array(o);i[0]=h;var r={};for(var l in a)hasOwnProperty.call(a,l)&&(r[l]=a[l]);r.originalType=e,r.mdxType="string"==typeof e?e:s,i[1]=r;for(var c=2;c<o;c++)i[c]=t[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,t)}h.displayName="MDXCreateElement"},21410:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>r,toc:()=>c});var n=t(87462),s=(t(67294),t(3905));const o={title:"What's in a Namespace?",date:new Date("2023-01-13T00:00:00.000Z"),authors:["Robinson"],description:"Namespaces enable powerful insights into distributed workflows."},i=void 0,r={permalink:"/blog/whats-in-a-namespace",source:"@site/blog/whats-in-a-namespace/index.mdx",title:"What's in a Namespace?",description:"Namespaces enable powerful insights into distributed workflows.",date:"2023-01-13T00:00:00.000Z",formattedDate:"January 13, 2023",tags:[],readingTime:10.775,hasTruncateMarker:!0,authors:[{name:"Michael Robinson",title:"OpenLineage Community Manager",url:"https://github.com/merobi-hub",imageURL:"https://github.com/merobi-hub.png",key:"Robinson"}],frontMatter:{title:"What's in a Namespace?",date:"2023-01-13T00:00:00.000Z",authors:["Robinson"],description:"Namespaces enable powerful insights into distributed workflows."},prevItem:{title:"OpenLineage Advances to Incubation Stage with the LFAI & Data",permalink:"/blog/incubation-stage-lfai"},nextItem:{title:"At Manta, OpenLineage Opens Doors to New Insights",permalink:"/blog/manta-integration"}},l={authorsImageUrls:[void 0]},c=[{value:"Background",id:"background",level:3},{value:"Namespaces in the Spec",id:"namespaces-in-the-spec",level:3},{value:"Namespaces in the Wild",id:"namespaces-in-the-wild",level:3},{value:"Consulting the Marquez API",id:"consulting-the-marquez-api",level:3},{value:"Dataset Namespaces",id:"dataset-namespaces",level:3},{value:"Job Namespaces",id:"job-namespaces",level:3},{value:"What&#39;s the Point?",id:"whats-the-point",level:3},{value:"How to Learn More",id:"how-to-learn-more",level:3},{value:"Acknowledgments",id:"acknowledgments",level:3}],p={toc:c};function d(e){let{components:a,...o}=e;return(0,s.kt)("wrapper",(0,n.Z)({},p,o,{components:a,mdxType:"MDXLayout"}),(0,s.kt)("p",null,"Namespaces enable powerful insights into distributed workflows."),(0,s.kt)("h3",{id:"background"},"Background"),(0,s.kt)("p",null,"With all due respect to Shakespeare's ",(0,s.kt)("a",{parentName:"p",href:"https://shakespeare.folger.edu/shakespeares-works/romeo-and-juliet/act-2-scene-2/?search=rose/#line-2.2.41"},"Juliet"),", in the ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/OpenLineage/OpenLineage"},"OpenLineage")," spec at least, names in general -- and namespaces in particular -- are everything."),(0,s.kt)("p",null,"OK, that\u2019s an exaggeration, but not by much. The function of namespaces is to provide unique IDs for everything in the lineage graph so that jobs and datasets can be rendered as nodes. This means namespaces make stitching input and output datasets together as pipelines possible \u2013 which is to say they effectively make lineage possible. In the broader context of the spec, namespaces reflect the importance of naming and naming conventions to the way OpenLineage constructs lineage. "),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"Namespace Selector",src:t(48351).Z,width:"643",height:"459"})),(0,s.kt)("p",null,"In creating pipelines organized according to data sources (in the case of datasets) or schedulers (in the case of jobs), namespaces enable focused insight into data flows, even when datasets and workflows are distributed across an organization. This focus enabled by namespaces is key to the production of useful lineage. If everything lived in a single namespace, every lineage graph would show everything that happened in an ecosystem \u2013 and be too cluttered to be useful. "),(0,s.kt)("h3",{id:"namespaces-in-the-spec"},"Namespaces in the Spec"),(0,s.kt)("p",null,"A look at the spec provides additional detail about namespaces. In the spec, namespaces are at the top of the hierarchy, which means that they have priority over datasets, jobs, and the graphs that connect them. Namespaces contain graphs, in fact, along with just about everything else in a datasource or scheduler\u2019s domain. Ultimately, this reflects the spec\u2019s bias towards tracking dataset and job transformations. "),(0,s.kt)("p",null,"To wit: the same code applied to different input datasets results in different jobs (not different runs of the same job). If those jobs share a scheduler, they will also share a namespace \u2013 but not a graph, which makes tracking the transformations much easier. Similarly, if different input datasets share a datasource, they will also share a namespace (but not a graph). "),(0,s.kt)("p",null,"As you can see, the track switching can get a little complicated, but the namespace abstraction has some clear advantages."),(0,s.kt)("h3",{id:"namespaces-in-the-wild"},"Namespaces in the Wild"),(0,s.kt)("p",null,"Consider the common scenario in which multiple teams in an organization maintain pipelines that access the same datasets. Now, imagine trying to collect and display lineage from the organization\u2019s ecosystem without having a way to distinguish between the different pipelines that use the same datasets. The ambiguous metadata would make any graph so cluttered as to be practically meaningless. "),(0,s.kt)("p",null,"Suffice it to say, without a strategy for naming at that macro level of the ecosystem, creating a meaningful graph and tracking transformations is much more difficult. Namespaces also ensure that lineage is meaningful irrespective of the various sources of a job\u2019s metadata. A scope above the dataset and run makes heterogeneous, holistic lineage possible in the case of datasets and jobs."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"We define the unique name strategy per resource to ensure it is followed uniformly independently from who is producing metadata and we can connect lineage from various sources.\n")),(0,s.kt)("p",null,"In sum, namespaces make operational lineage possible \u2013 which is, while maybe not everything, close to it.  "),(0,s.kt)("h3",{id:"consulting-the-marquez-api"},"Consulting the Marquez API"),(0,s.kt)("p",null,"Thanks to the ",(0,s.kt)("a",{parentName:"p",href:"https://marquezproject.github.io/marquez/openapi.html"},"Marquez API reference"),", we know that a namespaces endpoint is available that we can query for all namespaces."),(0,s.kt)("p",null,"If you use curl to do so, here\u2019s what you\u2019ll get after building Marquez from source with seed data (using ",(0,s.kt)("inlineCode",{parentName:"p"},"./docker/up.sh --build --seed"),"):"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},'\u279c  marquez git:(main) \u2717 curl -v http://localhost:5000/api/v1/namespaces | jq\n{\n  "namespaces": [\n    {\n      "name": "default",\n      "createdAt": "2022-12-07T15:02:24.135154Z",\n      "updatedAt": "2022-12-07T15:02:24.135154Z",\n      "ownerName": "anonymous",\n      "description": "The default global namespace for dataset, job, and run metadata not belonging to a user-specified namespace.",\n      "isHidden": false\n    },\n    {\n      "name": "food_delivery",\n      "createdAt": "2020-02-22T22:42:42Z",\n      "updatedAt": "2020-02-22T22:42:42Z",\n      "ownerName": "anonymous",\n      "description": null,\n      "isHidden": false\n    }\n  ]\n}\n')),(0,s.kt)("p",null,"The namespaces endpoint returns all the available namespaces, which is helpful because, as we\u2019ll see, so much of the information available from the API requires a namespace. For this reason alone, you might say the namespace is the \u201croot\u201d of the object model."),(0,s.kt)("p",null,"Say you want to retrieve one or more datasets from the API. First, you\u2019ll need a namespace:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},'\u279c  marquez git:(main) \u2717 curl -v http://localhost:5000/api/v1/namespaces/food_delivery/datasets/public.drivers | jq\n{\n  "id": {\n    "namespace": "food_delivery",\n    "name": "public.drivers"\n  },\n  "type": "DB_TABLE",\n  "name": "public.drivers",\n  "physicalName": "public.drivers",\n  "createdAt": "2020-02-22T22:42:42Z",\n  "updatedAt": "2020-02-22T22:42:42Z",\n  "namespace": "food_delivery",\n  "sourceName": "default",\n  "fields": [\n    {\n      "name": "id",\n      "type": "INTEGER",\n      "tags": [],\n      "description": "The unique ID of the driver."\n    }, \u2026\n')),(0,s.kt)("p",null,"Say you want to retrieve a job. You\u2019ll need a namespace:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},'\u279c  marquez git:(main) \u2717 curl -v http://localhost:5000/api/v1/namespaces/food_delivery/jobs/etl_order_status | jq\n{\n  "id": {\n    "namespace": "food_delivery",\n    "name": "etl_order_status"\n  },\n  "type": "BATCH",\n  "name": "etl_order_status",\n  "simpleName": "etl_order_status",\n  "parentJobName": null,\n  "createdAt": "2020-02-22T22:42:42Z",\n  "updatedAt": "2020-02-22T22:44:52Z",\n  "namespace": "food_delivery",\n  "inputs": [],\n  "outputs": [\n    {\n      "namespace": "food_delivery",\n      "name": "public.order_status"\n    }\n  ], \u2026\n')),(0,s.kt)("p",null,"Runs? You\u2019ll need a namespace for those:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},'\u279c  marquez git:(main) \u2717 curl -v http://localhost:5000/api/v1/namespaces/food_delivery/jobs/etl_order_status/runs | jq\n{\n  "runs": [\n    {\n      "id": "b7098939-87f0-4207-878f-dfd8e8804d8a",\n      "createdAt": "2020-02-22T22:42:42Z",\n      "updatedAt": "2020-02-22T22:44:52Z",\n      "nominalStartTime": null,\n      "nominalEndTime": null,\n      "state": "COMPLETED",\n      "startedAt": "2020-02-22T22:42:42Z",\n      "endedAt": "2020-02-22T22:44:52Z",\n      "durationMs": 130000,\n      "args": {},\n      "jobVersion": {\n        "namespace": "food_delivery",\n        "name": "etl_order_status",\n        "version": "44ca508b-43cc-392f-bbd2-9ca77d501afa"\n      },\n      "inputVersions": [],\n      "outputVersions": [\n        {\n          "namespace": "food_delivery",\n          "name": "public.order_status",\n          "version": "0c16298c-cbe2-3547-8429-309917290570"\n        }\n      ],\n      "context": {\n        "sql": "INSERT INTO order_status (id, transitioned_at, status, order_id, customer_id, restaurant_id, driver_id)\\n SELECT id, transitioned_at, status, order_id, customer_id, restaurant_id, driver_id\\n   FROM tmp_order_status;"\n      },\n      "facets": {}\n    }\n  ]\n}\n')),(0,s.kt)("p",null,"As the API reveals, namespaces really are key in the spec: they organize and unlock most of the insights OpenLineage has to offer."),(0,s.kt)("h3",{id:"dataset-namespaces"},"Dataset Namespaces"),(0,s.kt)("p",null,"Having explored the thinking behind namespaces and their role in the spec, we can get into how they organize datasets and jobs. Let\u2019s start with datasets, the simpler of the two cases due to the more straightforward way datasets\u2019 namespaces are constructed."),(0,s.kt)("p",null,"In short, a dataset\u2019s namespace is always tied to its datasource. As the spec says, ",(0,s.kt)("inlineCode",{parentName:"p"},"the namespace for a dataset is the unique name for its datasource."),"  "),(0,s.kt)("p",null,"Data sources vary, however, so the specific construction of dataset namespaces also varies across datasource types. (But they tend to map to databases.)"),(0,s.kt)("p",null,"In the case of Postgres, Mysql, and Trino, for example, we derive the namespace of a dataset from a combination of the scheme, host, and port of the service instance:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"* Namespace: postgres://{host}:{port} of the service instance.  \n    * Scheme = postgres\n    * Authority = {host}:{port}\n* Namespace: mysql://{host}:{port} of the service instance.  \n    * Scheme = mysql\n    * Authority = {host}:{port}\n* Namespace: trino://{host}:{port} of the service instance.  \n    * Scheme = trino\n    * Authority = {host}:{port}\n")),(0,s.kt)("p",null,"Redshift requires a different strategy. It\u2019s possible to interact with Redshift via SQL and an API, so a Redshift namespace is composed of a cluster identifier, region name and port \u2013 the only common unique ID available to both methods: "),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"* Namespace: redshift://{cluster_identifier}.{region_name}:{port} of the cluster instance.  \n    * Scheme = redshift\n    * Authority = {cluster_identifier}:{port}\n")),(0,s.kt)("p",null,"Snowflake and Amazon\u2019s serverless Athena warehouse service, which do not require a port, are even simpler:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"* Namespace: awsathena://athena.{region_name}.amazonaws.com of the service instance.  \n    * Scheme = awsathena\n    * Authority = athena.{region_name}.amazonaws.com\n* Namespace: snowflake://{account name}  \n    * Scheme = snowflake\n    * Authority = {account name}\n")),(0,s.kt)("p",null,"And so on. As you can see, the provenance of dataset namespaces is pretty straightforward: it\u2019s the data source."),(0,s.kt)("p",null,"That said, sometimes deriving the data source of a dataset is not a simple operation. Some datasets can be identified two different ways, for example. A Spark dataset can be written using a Hive metastore and table name but read using the physical location of the data. Before we added the ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/OpenLineage/OpenLineage/blob/main/spec/facets/SymlinksDatasetFacet.json"},(0,s.kt)("inlineCode",{parentName:"a"},"SymlinksDatasetFacet")),", this naming conflict could break the lineage graph. Symlinks both provide alternative dataset names as a workaround in such cases and contain extra information about the datasets."),(0,s.kt)("h3",{id:"job-namespaces"},"Job Namespaces"),(0,s.kt)("p",null,"We\u2019ve seen that for datasets the namespace is determined by the data source. But jobs are a different animal, so their namespaces are also different. How is a job\u2019s namespace derived? "),(0,s.kt)("p",null,"As in the case of datasets, the unique naming of jobs is essential, and a job\u2019s unique name consists of a namespace and name. Unlike datasets, jobs descend from schedulers, not data sources. Also unlike datasets, jobs are reducible: a job is composed of executions, or runs (as you can see from the \u201cHistorial de Ejecuciones\u201d tab \u2013 if you were to take the new language switcher for a spin and select Spanish, that is!)."),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"Historial de Ejecuciones Tab",src:t(1693).Z,width:"815",height:"440"})),(0,s.kt)("p",null,"Consulting ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/OpenLineage/OpenLineage/blob/main/spec/Naming.md"},"the spec"),", we find more detail about the naming of jobs:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"Jobs have a name that is unique to them in their namespace by construction.\nThe Namespace is the root of the naming hierarchy. The job name is constructed to identify the job within that namespace.\nExample:  \n* Airflow:  \n    * Namespace: the namespace is assigned to the airflow instance. Ex: airflow-staging, airflow-prod\n    * Job: each task in a DAG is a job. name: {dag name}.{task name}\n* Spark:  \n    * Namespace: the namespace is provided as a configuration parameter as in airflow. If there's a parent job, we use the same namespace, otherwise it is provided by configuration.\n    * Spark app job name: the spark.app.name\n    * Spark action job name: {spark.app.name}.{node.name}\n")),(0,s.kt)("p",null,"So, while for datasets it\u2019s all about the datasource, for jobs it\u2019s all about the scheduler. And the ",(0,s.kt)("inlineCode",{parentName:"p"},"ParentRun")," facet makes tracking job namespaces possible."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},'{\n  "run": {\n    "runId": "run_uuid"\n  },\n  "job": {\n    "namespace": "job_namespace",\n    "name": "job_name"\n  }\n}\n')),(0,s.kt)("p",null,"For all events, if a parent job exists, the facet\u2019s ",(0,s.kt)("inlineCode",{parentName:"p"},"namespace")," value is used to assign a namespace. Otherwise, one is provided by configuration."),(0,s.kt)("h3",{id:"whats-the-point"},"What's the Point?"),(0,s.kt)("p",null,"But why bother with dataset namespaces in the first place? One answer to this question gets to what is, for some users, a primary value proposition of OpenLineage. A common use case for lineage collection involves tracking dataset access and transformation across jobs and teams in an organization \u2013 for monitoring the use of PII, for example. Tags are supported by OpenLineage and can be used to meet this need, but, depending on how an organization\u2019s ecosystem is constructed, namespaces can also help with this common governance use case."),(0,s.kt)("p",null,"Let\u2019s explore a simple example constructed using the ",(0,s.kt)("a",{parentName:"p",href:"https://openlineage.io/docs/client/python/"},"Python client"),". Imagine that a library\u2019s website has two components, a catalog and a blog, and that both features access the same user and profile tables, both of which contain PII."),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"Website Schematic",src:t(84553).Z,width:"592",height:"346"})),(0,s.kt)("p",null,"In the spec, a dataset is unique only within a namespace \u2013 not across multiple namespaces \u2013 so a number of different graphs are possible depending on how the datasets are produced and accessed across an organization. "),(0,s.kt)("p",null,"For example, if for some reason the ",(0,s.kt)("inlineCode",{parentName:"p"},"users")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"profiles")," tables shared two ",(0,s.kt)("em",{parentName:"p"},"different")," data sources, the tables would belong to two different namespaces (let\u2019s call them ",(0,s.kt)("inlineCode",{parentName:"p"},"catalog_project")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"blog_project"),"). While not a typical scenario, this would result in two different, uncluttered graphs of the multiple flows making use of the shared datasets:"),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"Catalog with Different Namespaces",src:t(36883).Z,width:"547",height:"454"})),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"Blog with Different Namespaces",src:t(9407).Z,width:"547",height:"454"})),(0,s.kt)("p",null,"The reason for the simplicity? The ",(0,s.kt)("inlineCode",{parentName:"p"},"users")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"profiles")," tables belong to ",(0,s.kt)("em",{parentName:"p"},"both")," the ",(0,s.kt)("inlineCode",{parentName:"p"},"catalog_project")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"blog_project")," namespaces."),(0,s.kt)("p",null,"A more typical scenario might involve single versions of the tables being produced by one data source, which would assign them to a single OpenLineage namespace. Ironically, a simpler approach like this results in a more complicated visualization. Notice that the graph remains the same regardless of the namespace selected:"),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"Catalog with One Namespace",src:t(25627).Z,width:"572",height:"534"})),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"Blog with One Namespace",src:t(32076).Z,width:"555",height:"534"})),(0,s.kt)("p",null,"One advantage of this architecture is that it results in graphs making clear that the datasets containing PII are shared by the two jobs. Depending on an organization\u2019s needs, developers might also find it more convenient to be able to see both jobs and their shared datasets in the same graph."),(0,s.kt)("p",null,"A third scenario might involve the isolation of PII by the use of a dedicated database and, by extension, a dedicated namespace (e.g., ",(0,s.kt)("inlineCode",{parentName:"p"},"user_data"),"). In the resulting visualization, the job views above remain the same, but the shared datasets containing PII are now collected in the ",(0,s.kt)("inlineCode",{parentName:"p"},"user_data")," namespace on the datasets page of the Marquez UI:"),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"Datasets in Dedicated Namespace",src:t(89415).Z,width:"555",height:"534"})),(0,s.kt)("p",null,"Namespaces offer organizations a range of insights into how their teams are accessing and transforming sensitive data."),(0,s.kt)("h3",{id:"how-to-learn-more"},"How to Learn More"),(0,s.kt)("p",null,"If you\u2019re new to OpenLineage and want to check out namespaces in action, a good entry point is the ",(0,s.kt)("a",{parentName:"p",href:"https://openlineage.io/docs/getting-started"},"Getting Started guide"),". There you can learn about the core model, collect run-level metadata using ",(0,s.kt)("a",{parentName:"p",href:"https://marquezproject.ai/"},"Marquez")," as the ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/OpenLineage/OpenLineage#scope"},"HTTP backend"),", and explore lineage in the Marquez UI."),(0,s.kt)("p",null,"Helpful resources for learning more about the namespaces include the ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/OpenLineage/OpenLineage/tree/main/spec"},"spec"),", where ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/OpenLineage/OpenLineage/blob/main/spec/Naming.md"},"Naming.md")," is the Rosetta stone for namespace construction and naming conventions in the project."),(0,s.kt)("p",null,"We also welcome contributions to the project. One of the existing ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/OpenLineage/OpenLineage/tree/main/integration"},"integrations")," might be a good place to start. Our growing list of partners includes Airflow, dbt, Dagster and Flink."),(0,s.kt)("p",null,"Sound fun? Check out the ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/MarquezProject/marquez/blob/main/CONTRIBUTING.md"},"new contributor guide")," to get started. "),(0,s.kt)("h3",{id:"acknowledgments"},"Acknowledgments"),(0,s.kt)("p",null,"Ross Turk (",(0,s.kt)("a",{parentName:"p",href:"https://github.com/rossturk"},"@rossturk"),") and Pawe\u0142 Leszczy\u0144ski (",(0,s.kt)("a",{parentName:"p",href:"https://github.com/pawel-big-lebowski"},"@pawel-big-lebowski"),") contributed valuable feedback and suggestions. Any faults are the author's own."))}d.isMDXComponent=!0},9407:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/blog_with_different_namespaces-8d681152f107107a1f1d21ad06c3e0c0.png"},32076:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/blog_with_one_namespace-0566ae8a3a3096f0dccfad9df2906c71.png"},36883:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/catalog_with_different_namespaces-778b97792fcc838bd0e4515598732965.png"},25627:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/catalog_with_one_namespace-deabce9bc090beb97e70a7bccb2b35d4.png"},1693:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/historial_de_ejecuciones-2e9e7921c41ab54cea30a16bef1b3b59.png"},48351:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/namespace_selector-6c021ed74a1d53b7fa180019b3254053.png"},89415:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/pii_namespace-a288ba2603f8a689491de9a58c61a8fc.png"},84553:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/website_schematic-329c636ec954fafc250d831d4d99ee77.png"}}]);