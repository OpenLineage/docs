"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5626],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>h});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function r(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=a.createContext({}),d=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},u=function(e){var t=d(e.components);return a.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,l=e.parentName,u=r(e,["components","mdxType","originalType","parentName"]),c=d(n),h=o,m=c["".concat(l,".").concat(h)]||c[h]||p[h]||i;return n?a.createElement(m,s(s({ref:t},u),{},{components:n})):a.createElement(m,s({ref:t},u))}));function h(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=n.length,s=new Array(i);s[0]=c;var r={};for(var l in t)hasOwnProperty.call(t,l)&&(r[l]=t[l]);r.originalType=e,r.mdxType="string"==typeof e?e:o,s[1]=r;for(var d=2;d<i;d++)s[d]=n[d];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},8707:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>i,metadata:()=>r,toc:()=>d});var a=n(7462),o=(n(7294),n(3905));const i={title:"Exploring Lineage History via the Marquez API",date:new Date("2021-07-08T00:00:00.000Z"),authors:["Collado"],description:"Taking advantage of recent changes to the Marquez API, this post shows how to diagnose job failures and explore the impact of code changes on downstream dependents."},s=void 0,r={permalink:"/blog/explore-lineage-api",source:"@site/blog/explore-lineage-api/index.mdx",title:"Exploring Lineage History via the Marquez API",description:"Taking advantage of recent changes to the Marquez API, this post shows how to diagnose job failures and explore the impact of code changes on downstream dependents.",date:"2021-07-08T00:00:00.000Z",formattedDate:"July 8, 2021",tags:[],readingTime:13.685,hasTruncateMarker:!0,authors:[{name:"Michael Collado",title:"OpenLineage Committer",url:"https://www.github.com/collado-mike",imageURL:"https://www.github.com/collado-mike.png",key:"Collado"}],frontMatter:{title:"Exploring Lineage History via the Marquez API",date:"2021-07-08T00:00:00.000Z",authors:["Collado"],description:"Taking advantage of recent changes to the Marquez API, this post shows how to diagnose job failures and explore the impact of code changes on downstream dependents."},prevItem:{title:"OpenLineage joins the LF AI & Data Foundation",permalink:"/blog/joining-lfai"},nextItem:{title:"Backfilling Airflow DAGs using Marquez",permalink:"/blog/backfilling-airflow-dags-using-marquez"}},l={authorsImageUrls:[void 0]},d=[{value:"Getting Started",id:"getting-started",level:2},{value:"The Jobs",id:"the-jobs",level:3},{value:"The Job Run",id:"the-job-run",level:3},{value:"Tracing Failures",id:"tracing-failures",level:2},{value:"Job Versions",id:"job-versions",level:3},{value:"Tracing Upstream Lineage",id:"tracing-upstream-lineage",level:2},{value:"Dataset Versions",id:"dataset-versions",level:3}],u={toc:d};function p(e){let{components:t,...n}=e;return(0,o.kt)("wrapper",(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"Taking advantage of recent changes to the Marquez API, this post shows how to diagnose job failures and explore the impact of code changes on downstream dependents."),(0,o.kt)("p",null,"Managing a data pipeline means tracking changes. Sometimes changes to your code, sometimes changes to\nsomebody else\u2019s schema, sometimes to the contents of the data itself. Sometimes you need to\ntrace the root cause of a problem- somebody changed an int to a string and all the downstream consumers\nbroke."),(0,o.kt)("p",null,"Sometimes you want to make a change and see how your consumers were affected- do all the jobs\nrun significantly faster after you filter out ","\u201c","unused","\u201d"," records? Or did somebody ",(0,o.kt)("a",{parentName:"p",href:"https://www.hyrumslaw.com/"},"rely on those\n","\u201c","unused","\u201d"," records")," to be present in the data?"),(0,o.kt)("p",null,'Do the recommendation models perform better after you "improved" the data cleaning job upstream? Can\nyou be certain it was your change that improved the performance?'),(0,o.kt)("p",null,"Sometimes the data itself just looks wrong and you need a way to verify that nothing has broken. Why\nwas there a huge drop in traffic to the food delivery site yesterday? Was there an outage you didn't\nhear about? Competitors outbidding your ads? Or did the website developers simply stop logging some\ncritical event, corrupting every table in your data warehouse?"),(0,o.kt)("p",null,"Typically, we think of data lineage in static terms-"),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"Job A produces Dataset X, which is consumed by Job B which joins it with Dataset Y and produces\nDataset Z, which is consumed by","\u2026")),(0,o.kt)("p",null,"It\u2019s a map\nthat we use to get our heads around the dependencies that exist between the datasets we use to make\ngood decisions (how much inventory should I stock in the warehouse to ensure customers get timely\ndeliveries?) or to make technical features our customers will love (how can I compile the perfect\nroad trip playlist given this customer's listening history?)."),(0,o.kt)("p",null,"But data lineage is much more than a static map of inputs and outputs. ",(0,o.kt)("em",{parentName:"p"},"Real time")," lineage and faceted\nmetadata give us visibility into how the map changes over time and even allow us to look back in\nhistory to see how changes in one part of the map cause ripples in other areas. Taking advantage of some\nrecent changes to the Marquez API, we\u2019ll demonstrate how to diagnose job failures and how to explore\nthe impact of code changes on downstream dependents."),(0,o.kt)("h2",{id:"getting-started"},"Getting Started"),(0,o.kt)("p",null,"To get started, we need a running instance of Marquez with a little bit of seed data. For these\nexercises, we'll assume you have a terminal with the following programs installed"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://www.docker.com/products/docker-desktop"},"docker")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://git-scm.com/book/en/v2/Getting-Started-Installing-Git"},"git")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://curl.se/download.html"},"curl")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://stedolan.github.io/jq/download/"},"jq")),(0,o.kt)("li",{parentName:"ul"},"less (optional)")),(0,o.kt)("p",null,"Download and install any dependencies you don't already have. You'll need the docker daemon running\n(see the docs for your platform to get that started). Then check out the Marquez repository\nfrom Github and run the docker image locally:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/MarquezProject/marquez\ncd marquez\n./docker/up.sh --seed\n")),(0,o.kt)("p",null,"This script uses ",(0,o.kt)("inlineCode",{parentName:"p"},"docker-compose")," to spin up a self-contained installation of Marquez, including a\nlocal database container, web frontend, and service instance. Additionally, it populates a set of\nsample data that's useful for exploring the API. You'll know when the seed job is done when you see\nthe following line in the output logs"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"seed-marquez-with-metadata exited with code 0\n")),(0,o.kt)("p",null,"Once the seed job is done, we can begin exploring the API."),(0,o.kt)("h3",{id:"the-jobs"},"The Jobs"),(0,o.kt)("p",null,"In a separate terminal window, type the following command"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'curl "http://localhost:5000/api/v1/namespaces/food_delivery/jobs/" | jq | less\n')),(0,o.kt)("p",null,"The output returned should look something like the following"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "jobs": [\n    {\n      "id": {\n        "namespace": "food_delivery",\n        "name": "example.delivery_times_7_days"\n      },\n      "type": "BATCH",\n      "name": "example.delivery_times_7_days",\n      "createdAt": "2021-06-24T21:50:39.229759Z",\n      "updatedAt": "2021-06-24T22:05:45.321952Z",\n      "namespace": "food_delivery",\n      "inputs": [\n        {\n          "namespace": "food_delivery",\n          "name": "public.delivery_7_days"\n        }\n      ],\n      "outputs": [],\n      "location": "https://github.com/example/jobs/blob/2294bc15eb49071f38425dc927e48655530a2f2e/delivery_times_7_days.py",\n      "context": {\n        "sql": "INSERT INTO top_delivery_times (order_id, order_placed_on, order_dispatched_on, order_delivered_on, order_delivery_time,\\n    customer_email, restaurant_id, driver_id)\\n  SELECT order_id, order_placed_on, order_delivered_on, DATEDIFF(minute, order_placed_on, order_delivered_on) AS order_delivery_time,\\n    customer_email, restaurant_id, driver_id\\n    FROM delivery_7_days\\nGROUP BY restaurant_id\\nORDER BY order_delivery_time DESC\\n   LIMIT 1;"\n      },\n      "description": "Determine weekly top delivery times by restaurant.",\n      "latestRun": {\n        "id": "f4fada30-dfcc-400c-9391-2d7a506b9139",\n        "createdAt": "2021-06-24T21:50:59.509739Z",\n        "updatedAt": "2021-06-24T22:05:45.321952Z",\n        "nominalStartTime": "2021-06-24T22:02:00Z",\n        "nominalEndTime": "2021-06-24T22:05:00Z",\n        "state": "FAILED",\n        "startedAt": "2021-06-24T22:02:39.321952Z",\n        "endedAt": "2021-06-24T22:05:45.321952Z",\n        "durationMs": 186000,\n        "args": {},\n        "jobVersion": {\n          "namespace": "food_delivery",\n          "name": "example.delivery_times_7_days",\n          "version": "e9eafa5b-e334-358d-a3b4-61c8d3de75f3"\n        },\n        "inputVersions": [\n          {\n            "namespace": "food_delivery",\n            "name": "public.delivery_7_days",\n            "version": "a40ec54f-b8e1-35f7-b868-58b27383b5ff"\n          }\n        ],\n        "outputVersions": [],\n        "context": {\n          "sql": "INSERT INTO top_delivery_times (order_id, order_placed_on, order_dispatched_on, order_delivered_on, order_delivery_time,\\n    customer_email, restaurant_id, driver_id)\\n  SELECT order_id, order_placed_on, order_delivered_on, DATEDIFF(minute, order_placed_on, order_delivered_on) AS order_delivery_time,\\n    customer_email, restaurant_id, driver_id\\n    FROM delivery_7_days\\nGROUP BY restaurant_id\\nORDER BY order_delivery_time DESC\\n   LIMIT 1;"\n        },\n        "facets": {}\n      },\n      "facets": {}\n    },\n   ...\n  ]\n}\n')),(0,o.kt)("p",null,"For brevity, I only included a single job- in this case, a job called ",(0,o.kt)("inlineCode",{parentName:"p"},"example.delivery_times_7_days"),"\nin the ",(0,o.kt)("inlineCode",{parentName:"p"},"food_delivery")," namespace (which we specified in the curl command). Your output will include\nmany more jobs."),(0,o.kt)("p",null,"There are a few things in the job output worth noting. The first is the id of the job:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'      "id": {\n        "namespace": "food_delivery",\n        "name": "example.delivery_times_7_days"\n      },\n')),(0,o.kt)("p",null,"There is no version information in the id, as this API refers to the unversioned job information. The\njob itself is mutable, in the sense that each time you query the API, the content of the job may\nchange as new versions are created."),(0,o.kt)("p",null,"The response includes the set of input and output datasets, as well as the current job source location:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'      "inputs": [\n        {\n          "namespace": "food_delivery",\n          "name": "public.delivery_7_days"\n        }\n      ],\n      "outputs": [],\n      "location": "https://github.com/example/jobs/blob/2294bc15eb49071f38425dc927e48655530a2f2e/delivery_times_7_days.py",\n')),(0,o.kt)("p",null,"If a new version of the job is created, any or all of these fields can change."),(0,o.kt)("h3",{id:"the-job-run"},"The Job Run"),(0,o.kt)("p",null,"The next thing to notice is the ",(0,o.kt)("inlineCode",{parentName:"p"},"latestRun")," field. This includes information about the latest Run\nof this job:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'      "latestRun": {\n        "id": "f4fada30-dfcc-400c-9391-2d7a506b9139",\n        "createdAt": "2021-06-24T21:50:59.509739Z",\n        "updatedAt": "2021-06-24T22:05:45.321952Z",\n        "nominalStartTime": "2021-06-24T22:02:00Z",\n        "nominalEndTime": "2021-06-24T22:05:00Z",\n        "state": "FAILED",\n        "startedAt": "2021-06-24T22:02:39.321952Z",\n        "endedAt": "2021-06-24T22:05:45.321952Z",\n        "durationMs": 186000,\n        "args": {},\n        "jobVersion": {\n          "namespace": "food_delivery",\n          "name": "example.delivery_times_7_days",\n          "version": "e9eafa5b-e334-358d-a3b4-61c8d3de75f3"\n        },\n        "inputVersions": [\n          {\n            "namespace": "food_delivery",\n            "name": "public.delivery_7_days",\n            "version": "a40ec54f-b8e1-35f7-b868-58b27383b5ff"\n          }\n        ],\n        "outputVersions": [],\n        "context": {\n          "sql": "INSERT INTO top_delivery_times (order_id, order_placed_on, order_dispatched_on, order_delivered_on, order_delivery_time,\\n    customer_email, restaurant_id, driver_id)\\n  SELECT order_id, order_placed_on, order_delivered_on, DATEDIFF(minute, order_placed_on, order_delivered_on) AS order_delivery_time,\\n    customer_email, restaurant_id, driver_id\\n    FROM delivery_7_days\\nGROUP BY restaurant_id\\nORDER BY order_delivery_time DESC\\n   LIMIT 1;"\n        },\n        "facets": {}\n      },\n')),(0,o.kt)("p",null,"Here, we see explicit version information in the ",(0,o.kt)("inlineCode",{parentName:"p"},"jobVersion"),", the ",(0,o.kt)("inlineCode",{parentName:"p"},"inputVersions"),", and the\n",(0,o.kt)("inlineCode",{parentName:"p"},"outputVersions")," fields. This is included because every Run is tied to exactly one immutable\nversion of a job and one immutable version of each input dataset and each output dataset (it's worth\nnoting that a Run can be tied to one version of a dataset as its input and another version of the\nsame dataset as its output- a SQL ",(0,o.kt)("inlineCode",{parentName:"p"},"MERGE")," statement is one common use case supported by this)."),(0,o.kt)("p",null,"The other important field to notice in the Run structure is the ",(0,o.kt)("inlineCode",{parentName:"p"},"state")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'        "state": "FAILED",\n')),(0,o.kt)("p",null,"Uh-oh. Looks like the last time this job ran, it failed."),(0,o.kt)("h2",{id:"tracing-failures"},"Tracing Failures"),(0,o.kt)("p",null,"The first question we have when diagnosing a failure is"),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"Is this the first time it's failed? Or has it been broken a while?")),(0,o.kt)("p",null,"Let's use the API to find out. Checking previous runs is easily accomplished by hitting the job's ",(0,o.kt)("inlineCode",{parentName:"p"},"runs"),"\nAPI. Job runs are returned in descending order by start time, so the latest runs should be at the top.\nSince we only want to check whether (and which) previous runs failed, we can use the following command:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'curl "http://localhost:5000/api/v1/namespaces/food_delivery/jobs/example.delivery_times_7_days/runs" | \\\n  jq \'.runs | map({"id": .id, "state": .state})\' | less\n')),(0,o.kt)("p",null,"I get the following output:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'[\n  {\n    "id": "cb436906-1c66-4ce4-b7ac-ceebfd1babf8",\n    "state": "FAILED"\n  },\n  {\n    "id": "34bd4d60-82a6-4cac-ad76-815e6d95a93c",\n    "state": "COMPLETED"\n  },\n  {\n    "id": "352c67c3-c8d7-4b3a-b7da-8532aa9b8335",\n    "state": "COMPLETED"\n  },\n  {\n    "id": "0c62b1cc-2e43-44d0-9443-0a1d9768fece",\n    "state": "COMPLETED"\n  },\n  {\n    "id": "5900de19-12f7-4a6e-8118-8e0792d98f65",\n    "state": "COMPLETED"\n  },\n  ...\n]\n')),(0,o.kt)("p",null,"This is an incomplete list of jobs, but it's obvious from this sampling that this is the first job failure\nin the recent execution history. What we want to see now is what changed between the last successful\nrun and this one. We'll need to grab the ",(0,o.kt)("inlineCode",{parentName:"p"},"id")," fields of each of the runs we want to compare. The run\nids in the seed data are randomly generated, so they'll be different if you're following along. Grab\nthe run ids with the following shell commands:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"FAILED_RUN_ID=$(curl \"http://localhost:5000/api/v1/namespaces/food_delivery/jobs/example.delivery_times_7_days/runs\" | jq -r '.runs[0].id')\nSUCCESSFUL_RUN_ID=$(curl \"http://localhost:5000/api/v1/namespaces/food_delivery/jobs/example.delivery_times_7_days/runs\" | jq -r '.runs[1].id')\n")),(0,o.kt)("p",null,"To get a specific run, we call the ",(0,o.kt)("inlineCode",{parentName:"p"},"/jobs/runs")," API. Since each Run ID is required to be unique, the\nAPI doesn't require a namespace or a job name. We can get the failed job run with"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'curl "http://localhost:5000/api/v1/jobs/runs/$FAILED_RUN_ID" | jq | less\n')),(0,o.kt)("p",null,"The output is the same as the ",(0,o.kt)("inlineCode",{parentName:"p"},"latestRun")," field of the ",(0,o.kt)("inlineCode",{parentName:"p"},"JobVersions")," API. Recall the output of that\nAPI includes these three important fields: the ",(0,o.kt)("inlineCode",{parentName:"p"},"jobVersion"),", the ",(0,o.kt)("inlineCode",{parentName:"p"},"inputVersions"),"\nand the ",(0,o.kt)("inlineCode",{parentName:"p"},"outputVersions"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'        "jobVersion": {\n          "namespace": "food_delivery",\n          "name": "example.delivery_times_7_days",\n          "version": "e9eafa5b-e334-358d-a3b4-61c8d3de75f3"\n        },\n        "inputVersions": [\n          {\n            "namespace": "food_delivery",\n            "name": "public.delivery_7_days",\n            "version": "a40ec54f-b8e1-35f7-b868-58b27383b5ff"\n          }\n        ],\n        "outputVersions": [],\n')),(0,o.kt)("p",null,"These fields give us what we need to trace the lineage of the specific job runs we want to compare."),(0,o.kt)("h3",{id:"job-versions"},"Job Versions"),(0,o.kt)("p",null,"The first thing to look at is the ",(0,o.kt)("inlineCode",{parentName:"p"},"jobVersion"),". Nearly 100% of the time, a job failure can be traced\nto a code change. Let's compare the job version of the failed run with the job version of the successful\none:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"diff <(curl -s \"http://localhost:5000/api/v1/jobs/runs/$FAILED_RUN_ID\" | jq -r '.jobVersion.version') \\\n     <(curl -s \"http://localhost:5000/api/v1/jobs/runs/$SUCCESSFUL_RUN_ID\" | jq -r '.jobVersion.version')\n1c1\n< e9eafa5b-e334-358d-a3b4-61c8d3de75f3\n---\n> 92d801c0-021e-3c3d-ba18-c9e8504b143d\n")),(0,o.kt)("p",null,"Right away, we see there is a difference. A number of factors contribute to the job versioning logic\nin Marquez:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"The source code location"),(0,o.kt)("li",{parentName:"ul"},"The job context"),(0,o.kt)("li",{parentName:"ul"},"The list of input datasets"),(0,o.kt)("li",{parentName:"ul"},"The list of output datasets")),(0,o.kt)("p",null,"The version generation code is a deterministic function of these four inputs, so if any of them change,\nthe version will change. Let's find out what changed between the two job versions. To do the diff,\nwe ought to get rid of anything we expect to differ ahead of time: the ",(0,o.kt)("inlineCode",{parentName:"p"},"version"),", the ",(0,o.kt)("inlineCode",{parentName:"p"},"createdAt"),"\nand ",(0,o.kt)("inlineCode",{parentName:"p"},"updatedAt")," timestamps, and the ",(0,o.kt)("inlineCode",{parentName:"p"},"latestRun"),". The ",(0,o.kt)("inlineCode",{parentName:"p"},"version")," field is also nested within the job\nversion's ",(0,o.kt)("inlineCode",{parentName:"p"},"id")," field, so we'll omit that too."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'FAILED_JOB_VERSION=$(curl -s "http://localhost:5000/api/v1/jobs/runs/$FAILED_RUN_ID" | jq -r \'.jobVersion.version\')\nSUCCESSFUL_JOB_VERSION=$(curl -s "http://localhost:5000/api/v1/jobs/runs/$SUCCESSFUL_RUN_ID" | jq -r \'.jobVersion.version\')\n\ndiff <(curl -s "http://localhost:5000/api/v1/namespaces/food_delivery/jobs/example.delivery_times_7_days/versions/$FAILED_JOB_VERSION" | \\\n      jq \'del(.["id", "version", "createdAt", "updatedAt", "latestRun"])\') \\\n     <(curl -s "http://localhost:5000/api/v1/namespaces/food_delivery/jobs/example.delivery_times_7_days/versions/$SUCCESSFUL_JOB_VERSION" | \\\n      jq \'del(.["id", "version", "createdAt", "updatedAt", "latestRun"])\')\n14c14,23\n<   "outputs": []\n---\n>   "outputs": [\n>     {\n>       "namespace": "food_delivery",\n>       "name": "public.top_delivery_times"\n>     },\n>     {\n>       "namespace": "food_delivery",\n>       "name": "public.discounts"\n>     }\n>   ]\n')),(0,o.kt)("p",null,"Oh, interesting! The two job versions only differ because of the output datasets. This is an\ninteresting point that should be addressed in the Marquez API- the version generation is constructed\nwhen the run completes, ",(0,o.kt)("em",{parentName:"p"},"even if the job run failed"),". Sometimes this has no impact on the versioning,\nas the output datasets can be determined before the job run executes. But sometimes we see impacts\nlike this where a job run failed before we had a chance to discover the output datasets."),(0,o.kt)("h2",{id:"tracing-upstream-lineage"},"Tracing Upstream Lineage"),(0,o.kt)("p",null,"So what gives? The job code didn't actually change! So what caused the failure?"),(0,o.kt)("p",null,"Here's where the lineage tracking becomes useful. Recall again, the run output gave us\n3 interesting fields: the ",(0,o.kt)("inlineCode",{parentName:"p"},"jobVersion"),", the ",(0,o.kt)("inlineCode",{parentName:"p"},"inputVersions"),", and the ",(0,o.kt)("inlineCode",{parentName:"p"},"outputVersions"),".\nWe already know that the ",(0,o.kt)("inlineCode",{parentName:"p"},"outputVersions")," is empty because the latest failed run didn't have\na chance to determine the outputs. But we can take a look at the input datasets."),(0,o.kt)("h3",{id:"dataset-versions"},"Dataset Versions"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'diff <(curl -s "http://localhost:5000/api/v1/jobs/runs/$FAILED_RUN_ID" | jq -r \'.inputVersions\') \\\n     <(curl -s "http://localhost:5000/api/v1/jobs/runs/$SUCCESSFUL_RUN_ID" | jq -r \'.inputVersions\')\n5c5\n<     "version": "a40ec54f-b8e1-35f7-b868-58b27383b5ff"\n---\n>     "version": "5e439f1f-1a44-3700-961f-60c79c75a1ec"\n')),(0,o.kt)("p",null,"Dataset versions work differently from job versions. They don't only change when the structure changes.\nEvery time a job run ",(0,o.kt)("em",{parentName:"p"},"modifies or writes to")," a dataset, the dataset version changes. Unless a job schedule is more\nfrequent than its upstream job's schedule (e.g., an hourly job consuming a daily generated dataset),\nit is expected that each job run consumes a different version of a dataset. To find out if there is\na significant difference, we have to compare the two versions with the dataset's ",(0,o.kt)("inlineCode",{parentName:"p"},"versions")," API."),(0,o.kt)("p",null,"We know there's only a single input dataset, so we'll keep this simple, but you could also write a loop to\ncheck multiple input datasets if needed."),(0,o.kt)("p",null,"In this post, we omit the structure of the ",(0,o.kt)("inlineCode",{parentName:"p"},"datasetVersion"),", but you can explore it yourself with the following:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'FAILED_DATASET_VERSION=$(curl -s "http://localhost:5000/api/v1/jobs/runs/$FAILED_RUN_ID" | jq -r \'.inputVersions[0].version\')\ncurl -s "http://localhost:5000/api/v1/namespaces/food_delivery/datasets/public.delivery_7_days/versions/$FAILED_DATASET_VERSION" | jq | less\n')),(0,o.kt)("p",null,"As with the job versions, we'll omit some of the data we expect to be different in order to produce\na useful diff:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'FAILED_DATASET_VERSION=$(curl -s "http://localhost:5000/api/v1/jobs/runs/$FAILED_RUN_ID" | jq -r \'.inputVersions[0].version\')\nSUCCESSFUL_DATASET_VERSION=$(curl -s "http://localhost:5000/api/v1/jobs/runs/$SUCCESSFUL_RUN_ID" | jq -r \'.inputVersions[0].version\')\n\ndiff <(curl -s "http://localhost:5000/api/v1/namespaces/food_delivery/datasets/public.delivery_7_days/versions/$FAILED_DATASET_VERSION" | \\\n      jq \'del(.["id", "version", "createdAt", "createdByRun"])\') \\\n     <(curl -s "http://localhost:5000/api/v1/namespaces/food_delivery/datasets/public.delivery_7_days/versions/$SUCCESSFUL_DATASET_VERSION" | \\\n      jq \'del(.["id", "version", "createdAt", "createdByRun"])\')\n58c58\n<       "type": "VARCHAR",\n---\n>       "type": "INTEGER",\n')),(0,o.kt)("p",null,"Hey! Somehow one of the fields was converted from a an ",(0,o.kt)("inlineCode",{parentName:"p"},"INT")," to a ",(0,o.kt)("inlineCode",{parentName:"p"},"VARCHAR"),"! One of the helpful fields\nin the ",(0,o.kt)("inlineCode",{parentName:"p"},"version")," API is the ",(0,o.kt)("inlineCode",{parentName:"p"},"createdByRun"),", which is similar to the ",(0,o.kt)("inlineCode",{parentName:"p"},"jobVersion"),"'s ",(0,o.kt)("inlineCode",{parentName:"p"},"latestRun"),".\nIt provides the job run that last altered the dataset, creating the new version."),(0,o.kt)("p",null,"We can quickly compare the job versions of the runs that created these two dataset versions:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'diff <(curl -s "http://localhost:5000/api/v1/namespaces/food_delivery/datasets/public.delivery_7_days/versions/$FAILED_DATASET_VERSION" | \\\n      jq \'.createdByRun.jobVersion\') \\\n    <(curl -s "http://localhost:5000/api/v1/namespaces/food_delivery/datasets/public.delivery_7_days/versions/$SUCCESSFUL_DATASET_VERSION" | \\\n      jq \'.createdByRun.jobVersion\')\n4c4\n<   "version": "c222a72e-92cc-3bb6-b3b7-c174cbc76387"\n---\n>   "version": "76c375bf-58ac-3d19-b94f-424fe2784601"\n')),(0,o.kt)("p",null,"And we can do a quick comparison of the two job versions. Since the job name is different,\nwe'll let jq generate the endpoints for us"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'diff <(curl -s $(curl -s "http://localhost:5000/api/v1/namespaces/food_delivery/datasets/public.delivery_7_days/versions/$FAILED_DATASET_VERSION" | \\\n      jq -r \'.createdByRun.jobVersion | "http://localhost:5000/api/v1/namespaces/" + .namespace + "/jobs/" + .name + "/versions/" + .version\') | \\\n      jq \'del(.["id", "version", "createdAt", "updatedAt", "latestRun"])\') \\\n    <(curl -s $(curl -s "http://localhost:5000/api/v1/namespaces/food_delivery/datasets/public.delivery_7_days/versions/$SUCCESSFUL_DATASET_VERSION" | \\\n      jq -r \'.createdByRun.jobVersion | "http://localhost:5000/api/v1/namespaces/" + .namespace + "/jobs/" + .name + "/versions/" + .version\') | \\\n      jq \'del(.["id", "version", "createdAt", "updatedAt", "latestRun"])\')\n4c4\n<   "location": "https://github.com/example/jobs/blob/c87f2a40553cfa4ae7178083a068bf1d0c6ca3a8/etl_delivery_7_days.py",\n---\n>   "location": "https://github.com/example/jobs/blob/4d0b5d374261fdaf60a1fc588dd8f0d124b0e87f/etl_delivery_7_days.py",\n')),(0,o.kt)("p",null,"And there it is. Because nearly 100% of the time, a job failure can be traced to a code change. In\nthis example, the job immediately upstream decided to change the output schema of its dataset. In\nreality, it's not always so straightforward. Sometimes the upstream job is just a passthrough- maybe\nit applies some filters to a subset of the columns and writes out whatever schema it's given.\nIn that case, the job immediately upstream would have succeeded without a change in the job version.\nOr the code change in the upstream job could be innocuous. Maybe someone added a comment or fixed an\nunrelated bug. We might do some follow up and discover we have to continue our search upstream."),(0,o.kt)("p",null,"But the Marquez API actually gives us that ability. Using the ",(0,o.kt)("inlineCode",{parentName:"p"},"/lineage")," API, we can even explore the\ndownsteam impact of changes. So if you owned the ",(0,o.kt)("inlineCode",{parentName:"p"},"etl_delivery_7_days")," job and wanted to see what the\nimpact of changing the varchar to an int was on running jobs, the following jq recursive script\nwill let you walk the downstream jobs and show the state of the last run:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'# For readability, the jq filter is in a file broken into multiple lines\ncat recurse.jq\n  .graph as $graph | .graph[]\n  | select(.id == "job:food_delivery:example.etl_delivery_7_days")\n  | recurse(.outEdges[] | .destination as $nodeId | $graph[] | select(.id == $nodeId))\n  | select(.type == "JOB")\n  | {"id": .id, "state": .data.latestRun.state}\n\ncurl -s "http://localhost:5000/api/v1-beta/lineage?nodeId=job:food_delivery:example.etl_delivery_7_days" | jq -f recurse.jq less\n{\n  "id": "job:food_delivery:example.etl_delivery_7_days",\n  "state": "COMPLETED"\n}\n{\n  "id": "job:food_delivery:example.delivery_times_7_days",\n  "state": "FAILED"\n}\n')),(0,o.kt)("p",null,"In this post, we did everything manually with bash (because the shell is your most powerful tool when\ndebugging a live outage you've never encountered before; and let's be honest- how many outages ",(0,o.kt)("em",{parentName:"p"},"aren't"),"\nsomething you've never encountered before), but this could easily have been done in Java or Go or Python.\nThe ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/MarquezProject/marquez/blob/main/spec/openapi.yml"},"openapi spec"),"\nin the Marquez repo can be used to generate a client in whatever language you want to write your ops\ntool in. So build some tooling and help your next debugging session run a little more smoothly."),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"But wait! What about the times when the job isn't ",(0,o.kt)("em",{parentName:"p"},"failing"),", but the data is wrong!")),(0,o.kt)("p",null,"Ah, the data quality checks! This is where the extensibility of the OpenLineage model comes to our\nrescue with a field in the responses that we completely glossed over"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'      "facets": {}\n')),(0,o.kt)("p",null,"But I think that's a topic for another post."))}p.isMDXComponent=!0}}]);