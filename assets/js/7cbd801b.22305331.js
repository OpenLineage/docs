"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6677],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>k});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function p(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var o=n.createContext({}),s=function(e){var t=n.useContext(o),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},u=function(e){var t=s(e.components);return n.createElement(o.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,o=e.parentName,u=p(e,["components","mdxType","originalType","parentName"]),d=s(a),k=r,c=d["".concat(o,".").concat(k)]||d[k]||m[k]||l;return a?n.createElement(c,i(i({ref:t},u),{},{components:a})):n.createElement(c,i({ref:t},u))}));function k(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,i=new Array(l);i[0]=d;var p={};for(var o in t)hasOwnProperty.call(t,o)&&(p[o]=t[o]);p.originalType=e,p.mdxType="string"==typeof e?e:r,i[1]=p;for(var s=2;s<l;s++)i[s]=a[s];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},85162:(e,t,a)=>{a.d(t,{Z:()=>i});var n=a(67294),r=a(86010);const l="tabItem_Ymn6";function i(e){let{children:t,hidden:a,className:i}=e;return n.createElement("div",{role:"tabpanel",className:(0,r.Z)(l,i),hidden:a},t)}},74866:(e,t,a)=>{a.d(t,{Z:()=>x});var n=a(87462),r=a(67294),l=a(86010),i=a(76775),p=a(91980),o=a(67392),s=a(50012);function u(e){return function(e){return r.Children.map(e,(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:a,attributes:n,default:r}}=e;return{value:t,label:a,attributes:n,default:r}}))}function m(e){const{values:t,children:a}=e;return(0,r.useMemo)((()=>{const e=t??u(a);return function(e){const t=(0,o.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,a])}function d(e){let{value:t,tabValues:a}=e;return a.some((e=>e.value===t))}function k(e){let{queryString:t=!1,groupId:a}=e;const n=(0,i.k6)(),l=function(e){let{queryString:t=!1,groupId:a}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!a)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return a??null}({queryString:t,groupId:a});return[(0,p._X)(l),(0,r.useCallback)((e=>{if(!l)return;const t=new URLSearchParams(n.location.search);t.set(l,e),n.replace({...n.location,search:t.toString()})}),[l,n])]}function c(e){const{defaultValue:t,queryString:a=!1,groupId:n}=e,l=m(e),[i,p]=(0,r.useState)((()=>function(e){let{defaultValue:t,tabValues:a}=e;if(0===a.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!d({value:t,tabValues:a}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${a.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const n=a.find((e=>e.default))??a[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:l}))),[o,u]=k({queryString:a,groupId:n}),[c,g]=function(e){let{groupId:t}=e;const a=function(e){return e?`docusaurus.tab.${e}`:null}(t),[n,l]=(0,s.Nk)(a);return[n,(0,r.useCallback)((e=>{a&&l.set(e)}),[a,l])]}({groupId:n}),h=(()=>{const e=o??c;return d({value:e,tabValues:l})?e:null})();(0,r.useLayoutEffect)((()=>{h&&p(h)}),[h]);return{selectedValue:i,selectValue:(0,r.useCallback)((e=>{if(!d({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);p(e),u(e),g(e)}),[u,g,l]),tabValues:l}}var g=a(12466),h=a(72389);const N="tabList__CuJ",f="tabItem_LNqP";function b(e){let{className:t,block:a,selectedValue:i,selectValue:p,tabValues:o}=e;const s=[],{blockElementScrollPositionUntilNextRender:u}=(0,g.o5)(),m=e=>{const t=e.currentTarget,a=s.indexOf(t),n=o[a].value;n!==i&&(u(t),p(n))},d=e=>{let t=null;switch(e.key){case"Enter":m(e);break;case"ArrowRight":{const a=s.indexOf(e.currentTarget)+1;t=s[a]??s[0];break}case"ArrowLeft":{const a=s.indexOf(e.currentTarget)-1;t=s[a]??s[s.length-1];break}}t?.focus()};return r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,l.Z)("tabs",{"tabs--block":a},t)},o.map((e=>{let{value:t,label:a,attributes:p}=e;return r.createElement("li",(0,n.Z)({role:"tab",tabIndex:i===t?0:-1,"aria-selected":i===t,key:t,ref:e=>s.push(e),onKeyDown:d,onClick:m},p,{className:(0,l.Z)("tabs__item",f,p?.className,{"tabs__item--active":i===t})}),a??t)})))}function y(e){let{lazy:t,children:a,selectedValue:n}=e;const l=(Array.isArray(a)?a:[a]).filter(Boolean);if(t){const e=l.find((e=>e.props.value===n));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return r.createElement("div",{className:"margin-top--md"},l.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==n}))))}function v(e){const t=c(e);return r.createElement("div",{className:(0,l.Z)("tabs-container",N)},r.createElement(b,(0,n.Z)({},e,t)),r.createElement(y,(0,n.Z)({},e,t)))}function x(e){const t=(0,h.Z)();return r.createElement(v,(0,n.Z)({key:String(t)},e))}},81742:(e,t,a)=>{a.d(t,{ZP:()=>o});var n=a(87462),r=(a(67294),a(3905)),l=a(74866),i=a(85162);const p={toc:[{value:"Simple Memory Circuit Breaker",id:"simple-memory-circuit-breaker",level:3},{value:"Java Runtime Circuit Breaker",id:"java-runtime-circuit-breaker",level:3},{value:"Custom Circuit Breaker",id:"custom-circuit-breaker",level:3}]};function o(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"This feature is available in OpenLineage versions >= 1.9.0.")),(0,r.kt)("p",null,"To prevent from over-instrumentation OpenLineage integration provides a circuit breaker mechanism\nthat stops OpenLineage from creating, serializing and sending OpenLineage events."),(0,r.kt)("h3",{id:"simple-memory-circuit-breaker"},"Simple Memory Circuit Breaker"),(0,r.kt)("p",null,"Simple circuit breaker which is working based only on free memory within JVM. Configuration should\ncontain free memory threshold limit (percentage). Default value is ",(0,r.kt)("inlineCode",{parentName:"p"},"20%"),". The circuit breaker\nwill close within first call if free memory is low. ",(0,r.kt)("inlineCode",{parentName:"p"},"circuitCheckIntervalInMillis")," parameter is used\nto configure a frequency circuit breaker is called. Default value is ",(0,r.kt)("inlineCode",{parentName:"p"},"1000ms"),", when no entry in config."),(0,r.kt)(l.Z,{groupId:"integrations",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"circuitBreaker:\n  type: simpleMemory\n  memoryThreshold: 20\n  circuitCheckIntervalInMillis: 1000\n"))),(0,r.kt)(i.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.type"),(0,r.kt)("td",{parentName:"tr",align:null},"Circuit breaker type selected"),(0,r.kt)("td",{parentName:"tr",align:null},"simpleMemory")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.memoryThreshold"),(0,r.kt)("td",{parentName:"tr",align:null},"Memory threshold"),(0,r.kt)("td",{parentName:"tr",align:null},"20")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.circuitCheckIntervalInMillis"),(0,r.kt)("td",{parentName:"tr",align:null},"Frequency of checking circuit breaker"),(0,r.kt)("td",{parentName:"tr",align:null},"1000"))))),(0,r.kt)(i.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.type"),(0,r.kt)("td",{parentName:"tr",align:null},"Circuit breaker type selected"),(0,r.kt)("td",{parentName:"tr",align:null},"simpleMemory")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.memoryThreshold"),(0,r.kt)("td",{parentName:"tr",align:null},"Memory threshold"),(0,r.kt)("td",{parentName:"tr",align:null},"20")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.circuitCheckIntervalInMillis"),(0,r.kt)("td",{parentName:"tr",align:null},"Frequency of checking circuit breaker"),(0,r.kt)("td",{parentName:"tr",align:null},"1000")))))),(0,r.kt)("h3",{id:"java-runtime-circuit-breaker"},"Java Runtime Circuit Breaker"),(0,r.kt)("p",null,"More complex version of circuit breaker. The amount of free memory can be low as long as\namount of time spent on Garbage Collection is acceptable. ",(0,r.kt)("inlineCode",{parentName:"p"},"JavaRuntimeCircuitBreaker")," closes\nwhen free memory drops below threshold and amount of time spent on garbage collection exceeds\ngiven threshold (",(0,r.kt)("inlineCode",{parentName:"p"},"10%")," by default). The circuit breaker is always open when checked for the first time\nas GC threshold is computed since the previous circuit breaker call.\n",(0,r.kt)("inlineCode",{parentName:"p"},"circuitCheckIntervalInMillis")," parameter is used\nto configure a frequency circuit breaker is called.\nDefault value is ",(0,r.kt)("inlineCode",{parentName:"p"},"1000ms"),", when no entry in config."),(0,r.kt)(l.Z,{groupId:"integrations",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"circuitBreaker:\n  type: javaRuntime\n  memoryThreshold: 20\n  gcCpuThreshold: 10\n  circuitCheckIntervalInMillis: 1000\n"))),(0,r.kt)(i.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.type"),(0,r.kt)("td",{parentName:"tr",align:null},"Circuit breaker type selected"),(0,r.kt)("td",{parentName:"tr",align:null},"javaRuntime")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.memoryThreshold"),(0,r.kt)("td",{parentName:"tr",align:null},"Memory threshold"),(0,r.kt)("td",{parentName:"tr",align:null},"20")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.gcCpuThreshold"),(0,r.kt)("td",{parentName:"tr",align:null},"Garbage Collection CPU threshold"),(0,r.kt)("td",{parentName:"tr",align:null},"10")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.circuitCheckIntervalInMillis"),(0,r.kt)("td",{parentName:"tr",align:null},"Frequency of checking circuit breaker"),(0,r.kt)("td",{parentName:"tr",align:null},"1000"))))),(0,r.kt)(i.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.type"),(0,r.kt)("td",{parentName:"tr",align:null},"Circuit breaker type selected"),(0,r.kt)("td",{parentName:"tr",align:null},"javaRuntime")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.memoryThreshold"),(0,r.kt)("td",{parentName:"tr",align:null},"Memory threshold"),(0,r.kt)("td",{parentName:"tr",align:null},"20")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.gcCpuThreshold"),(0,r.kt)("td",{parentName:"tr",align:null},"Garbage Collection CPU threshold"),(0,r.kt)("td",{parentName:"tr",align:null},"10")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.circuitCheckIntervalInMillis"),(0,r.kt)("td",{parentName:"tr",align:null},"Frequency of checking circuit breaker"),(0,r.kt)("td",{parentName:"tr",align:null},"1000")))))),(0,r.kt)("h3",{id:"custom-circuit-breaker"},"Custom Circuit Breaker"),(0,r.kt)("p",null,"List of available circuit breakers can be extended with custom one loaded via ServiceLoader\nwith own implementation of ",(0,r.kt)("inlineCode",{parentName:"p"},"io.openlineage.client.circuitBreaker.CircuitBreakerBuilder"),"."))}o.isMDXComponent=!0},55154:(e,t,a)=>{a.d(t,{ZP:()=>o});var n=a(87462),r=(a(67294),a(3905)),l=a(74866),i=a(85162);const p={toc:[{value:"HTTP",id:"http",level:3},{value:"Overriden default configuration of the <code>HttpTransport</code>",id:"overriden-default-configuration-of-the-httptransport",level:4},{value:"URL parsing within Spark integration",id:"url-parsing-within-spark-integration",level:4},{value:"Kafka",id:"kafka",level:3},{value:"Kinesis",id:"kinesis",level:3},{value:"Console",id:"console",level:3},{value:"File",id:"file",level:3}]};function o(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Tip:")," See current list of ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java/src/main/java/io/openlineage/client/transports"},"all supported transports"),"."),(0,r.kt)("h3",{id:"http"},(0,r.kt)("a",{parentName:"h3",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java/src/main/java/io/openlineage/client/transports/HttpTransport.java"},"HTTP")),(0,r.kt)("p",null,"Allows sending events to HTTP endpoint (with optional authorization headers)."),(0,r.kt)(l.Z,{groupId:"spark",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"Yaml Config",label:"Yaml Config",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: http\n  url: http://localhost:5000\n")),(0,r.kt)("p",null,"With authorization:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: http\n  url: http://localhost:5000\n  endpoint: api/v1/lineage\n  auth:\n    type: api_key\n    api_key: f38d2189-c603-4b46-bdea-e573a3b5a7d5\n")),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Override the default configuration of the HttpTransport within Java client"),(0,r.kt)("p",null,(0,r.kt)("h4",{id:"overriden-default-configuration-of-the-httptransport"},"Overriden default configuration of the ",(0,r.kt)("inlineCode",{parentName:"h4"},"HttpTransport")),(0,r.kt)("p",null,"You can override the default configuration of the ",(0,r.kt)("inlineCode",{parentName:"p"},"HttpTransport")," by specifying the URL and API key when\ncreating a new client:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'OpenLineageClient client = OpenLineageClient.builder()\n  .transport(\n    HttpTransport.builder()\n      .url("http://localhost:5000")\n      .apiKey("f38d2189-c603-4b46-bdea-e573a3b5a7d5")\n      .build())\n  .build();\n')),(0,r.kt)("p",null,"To configure the client with query params appended on each HTTP request, use:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'Map<String, String> queryParamsToAppend = Map.of(\n  "param0","value0",\n  "param1", "value1"\n);\n\n// Connect to http://localhost:5000\nOpenLineageClient client = OpenLineageClient.builder()\n  .transport(\n    HttpTransport.builder()\n      .url("http://localhost:5000", queryParamsToAppend)\n      .apiKey("f38d2189-c603-4b46-bdea-e573a3b5a7d5")\n      .build())\n  .build();\n\n// Define a simple OpenLineage START or COMPLETE event\nOpenLineage.RunEvent startOrCompleteRun = ...\n\n// Emit OpenLineage event to http://localhost:5000/api/v1/lineage?param0=value0&param1=value1\nclient.emit(startOrCompleteRun);\n'))))),(0,r.kt)(i.Z,{value:"Spark Config",label:"Spark Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.endpoint"),(0,r.kt)("td",{parentName:"tr",align:null},"Path to resource"),(0,r.kt)("td",{parentName:"tr",align:null},"/api/v1/lineage")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.auth.type"),(0,r.kt)("td",{parentName:"tr",align:null},"The type of authentication method to use"),(0,r.kt)("td",{parentName:"tr",align:null},"api_key")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.auth.apiKey"),(0,r.kt)("td",{parentName:"tr",align:null},"An API key to be used when sending events to the OpenLineage server"),(0,r.kt)("td",{parentName:"tr",align:null},"abcdefghijk")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.timeout"),(0,r.kt)("td",{parentName:"tr",align:null},"Timeout for sending OpenLineage info in milliseconds"),(0,r.kt)("td",{parentName:"tr",align:null},"5000")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.urlParams.xyz"),(0,r.kt)("td",{parentName:"tr",align:null},"A URL parameter (replace xyz) and value to be included in requests to the OpenLineage API server"),(0,r.kt)("td",{parentName:"tr",align:null},"abcdefghijk")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.url"),(0,r.kt)("td",{parentName:"tr",align:null},"The hostname of the OpenLineage API server where events should be reported, it can have other properties embeded"),(0,r.kt)("td",{parentName:"tr",align:null},"http://localhost:5000")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.headers.xyz"),(0,r.kt)("td",{parentName:"tr",align:null},"Request headers (replace xyz) and value to be included in requests to the OpenLineage API server"),(0,r.kt)("td",{parentName:"tr",align:null},"abcdefghijk")))),(0,r.kt)("details",null,(0,r.kt)("summary",null,"URL parsing within Spark integration"),(0,r.kt)("p",null,(0,r.kt)("h4",{id:"url-parsing-within-spark-integration"},"URL parsing within Spark integration"),(0,r.kt)("p",null,"You can supply http parameters using values in url, the parsed ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.openlineage.*")," properties are located in url as follows:"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"{transport.url}/{transport.endpoint}/namespaces/{namespace}/jobs/{parentJobName}/runs/{parentRunId}?app_name={appName}&api_key={transport.apiKey}&timeout={transport.timeout}&xxx={transport.urlParams.xxx}")),(0,r.kt)("p",null,"example:"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"http://localhost:5000/api/v1/namespaces/ns_name/jobs/job_name/runs/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx?app_name=app&api_key=abc&timeout=5000&xxx=xxx"))))),(0,r.kt)(i.Z,{value:"Flink Config",label:"Flink Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.endpoint"),(0,r.kt)("td",{parentName:"tr",align:null},"Path to resource"),(0,r.kt)("td",{parentName:"tr",align:null},"/api/v1/lineage")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.auth.type"),(0,r.kt)("td",{parentName:"tr",align:null},"The type of authentication method to use"),(0,r.kt)("td",{parentName:"tr",align:null},"api_key")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.auth.apiKey"),(0,r.kt)("td",{parentName:"tr",align:null},"An API key to be used when sending events to the OpenLineage server"),(0,r.kt)("td",{parentName:"tr",align:null},"abcdefghijk")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.timeout"),(0,r.kt)("td",{parentName:"tr",align:null},"Timeout for sending OpenLineage info in milliseconds"),(0,r.kt)("td",{parentName:"tr",align:null},"5000")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.urlParams.xyz"),(0,r.kt)("td",{parentName:"tr",align:null},"A URL parameter (replace xyz) and value to be included in requests to the OpenLineage API server"),(0,r.kt)("td",{parentName:"tr",align:null},"abcdefghijk")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.url"),(0,r.kt)("td",{parentName:"tr",align:null},"The hostname of the OpenLineage API server where events should be reported, it can have other properties embeded"),(0,r.kt)("td",{parentName:"tr",align:null},"http://localhost:5000")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.headers.xyz"),(0,r.kt)("td",{parentName:"tr",align:null},"Request headers (replace xyz) and value to be included in requests to the OpenLineage API server"),(0,r.kt)("td",{parentName:"tr",align:null},"abcdefghijk")))))),(0,r.kt)("h3",{id:"kafka"},(0,r.kt)("a",{parentName:"h3",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java/src/main/java/io/openlineage/client/transports/KafkaTransport.java"},"Kafka")),(0,r.kt)("p",null,"If a transport type is set to ",(0,r.kt)("inlineCode",{parentName:"p"},"kafka"),", then the below parameters would be read and used when building KafkaProducer.\nThis transport requires the artifact ",(0,r.kt)("inlineCode",{parentName:"p"},"org.apache.kafka:kafka-clients:3.1.0")," (or compatible) on your classpath."),(0,r.kt)(l.Z,{groupId:"integrations",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: kafka\n  topicName: openlineage.events\n  # Kafka properties (see: http://kafka.apache.org/0100/documentation.html#producerconfigs)\n  properties:\n    bootstrap.servers: localhost:9092,another.host:9092\n    acks: all\n    retries: 3\n    key.serializer: org.apache.kafka.common.serialization.StringSerializer\n    value.serializer: org.apache.kafka.common.serialization.StringSerializer\n"))),(0,r.kt)(i.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.topicName"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, name of the topic"),(0,r.kt)("td",{parentName:"tr",align:null},"topic-name")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.localServerId"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, id of local server"),(0,r.kt)("td",{parentName:"tr",align:null},"xxxxxxxx")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.properties.","[xxx]"),(0,r.kt)("td",{parentName:"tr",align:null},"Optional, the ","[xxx]"," is property of Kafka client"),(0,r.kt)("td",{parentName:"tr",align:null},"1"))))),(0,r.kt)(i.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.topicName"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, name of the topic"),(0,r.kt)("td",{parentName:"tr",align:null},"topic-name")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.localServerId"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, id of local server"),(0,r.kt)("td",{parentName:"tr",align:null},"xxxxxxxx")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.properties.","[xxx]"),(0,r.kt)("td",{parentName:"tr",align:null},"Optional, the ","[xxx]"," is property of Kafka client"),(0,r.kt)("td",{parentName:"tr",align:null},"1")))))),(0,r.kt)("h3",{id:"kinesis"},(0,r.kt)("a",{parentName:"h3",href:"https://github.com/OpenLineage/OpenLineage/blob/main/client/java/src/main/java/io/openlineage/client/transports/KinesisTransport.java"},"Kinesis")),(0,r.kt)("p",null,"If a transport type is set to ",(0,r.kt)("inlineCode",{parentName:"p"},"kinesis"),", then the below parameters would be read and used when building KinesisProducer.\nAlso, KinesisTransport depends on you to provide artifact ",(0,r.kt)("inlineCode",{parentName:"p"},"com.amazonaws:amazon-kinesis-producer:0.14.0")," or compatible on your classpath."),(0,r.kt)(l.Z,{groupId:"integrations",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: kinesis\n  streamName: your_kinesis_stream_name\n  topicName: openlineage.events\n  region: your_aws_region\n  roleArn: arn:aws:iam::account-id:role/role-name   # optional\n  properties:  # Refer to amazon-kinesis-producer's default configuration.md for the available properties\n    property_name_1: value_1\n    property_name_2: value_2\n"))),(0,r.kt)(i.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.streamName"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, the streamName of the Kinesis Stream"),(0,r.kt)("td",{parentName:"tr",align:null},"some-stream-name")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.region"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, the region of the stream"),(0,r.kt)("td",{parentName:"tr",align:null},"us-east-2")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.roleArn"),(0,r.kt)("td",{parentName:"tr",align:null},"Optional, the roleArn which is allowed to read/write to Kinesis stream"),(0,r.kt)("td",{parentName:"tr",align:null},"some-role-arn")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.properties.","[xxx]"),(0,r.kt)("td",{parentName:"tr",align:null},"Optional, the ","[xxx]"," is property of ",(0,r.kt)("a",{parentName:"td",href:"https://github.com/awslabs/amazon-kinesis-producer/blob/master/java/amazon-kinesis-producer-sample/default_config.properties"},"Kinesis allowd properties")),(0,r.kt)("td",{parentName:"tr",align:null},"1"))))),(0,r.kt)(i.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.streamName"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, the streamName of the Kinesis Stream"),(0,r.kt)("td",{parentName:"tr",align:null},"some-stream-name")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.region"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, the region of the stream"),(0,r.kt)("td",{parentName:"tr",align:null},"us-east-2")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.roleArn"),(0,r.kt)("td",{parentName:"tr",align:null},"Optional, the roleArn which is allowed to read/write to Kinesis stream"),(0,r.kt)("td",{parentName:"tr",align:null},"some-role-arn")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.properties.","[xxx]"),(0,r.kt)("td",{parentName:"tr",align:null},"Optional, the ","[xxx]"," is property of ",(0,r.kt)("a",{parentName:"td",href:"https://github.com/awslabs/amazon-kinesis-producer/blob/master/java/amazon-kinesis-producer-sample/default_config.properties"},"Kinesis allowd properties")),(0,r.kt)("td",{parentName:"tr",align:null},"1")))))),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Behavior"),":"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Events are serialized to JSON upon the ",(0,r.kt)("inlineCode",{parentName:"li"},"emit()")," call and dispatched to the Kinesis stream."),(0,r.kt)("li",{parentName:"ul"},"The partition key is generated by combining the job's namespace and name."),(0,r.kt)("li",{parentName:"ul"},"Two constructors are available: one accepting both ",(0,r.kt)("inlineCode",{parentName:"li"},"KinesisProducer")," and ",(0,r.kt)("inlineCode",{parentName:"li"},"KinesisConfig")," and another solely accepting ",(0,r.kt)("inlineCode",{parentName:"li"},"KinesisConfig"),".")),(0,r.kt)("h3",{id:"console"},(0,r.kt)("a",{parentName:"h3",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java/src/main/java/io/openlineage/client/transports/ConsoleTransport.java"},"Console")),(0,r.kt)("p",null,"This straightforward transport emits OpenLineage events directly to the console through a logger.\nBe cautious when using the DEBUG log level, as it might result in double-logging due to the ",(0,r.kt)("inlineCode",{parentName:"p"},"OpenLineageClient")," also logging.\nNo additional configuration is required."),(0,r.kt)(l.Z,{groupId:"integrations",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: console\n"))),(0,r.kt)(i.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"}),(0,r.kt)(i.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"})),(0,r.kt)("h3",{id:"file"},(0,r.kt)("a",{parentName:"h3",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java/src/main/java/io/openlineage/client/transports/FileTransport.java"},"File")),(0,r.kt)("p",null,"Designed mainly for integration testing, the ",(0,r.kt)("inlineCode",{parentName:"p"},"FileTransport")," appends OpenLineage events to a given file.\nEvents are newline-separated, with all pre-existing newline characters within the event JSON removed."),(0,r.kt)(l.Z,{groupId:"integrations",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: file\n  location: /path/to/your/file.txt\n"))),(0,r.kt)(i.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.location"),(0,r.kt)("td",{parentName:"tr",align:null},"File path"),(0,r.kt)("td",{parentName:"tr",align:null},"/path/to/your/file.txt"))))),(0,r.kt)(i.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.location"),(0,r.kt)("td",{parentName:"tr",align:null},"File path"),(0,r.kt)("td",{parentName:"tr",align:null},"/path/to/your/file.txt")))))),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Notes"),":"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"If the target file is absent, it's created."),(0,r.kt)("li",{parentName:"ul"},"Events are added to the file, separated by newlines."),(0,r.kt)("li",{parentName:"ul"},"Intrinsic newline characters within the event JSON are eliminated to ensure one-line events.")))}o.isMDXComponent=!0},60928:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>d,contentTitle:()=>u,default:()=>g,frontMatter:()=>s,metadata:()=>m,toc:()=>k});var n=a(87462),r=(a(67294),a(3905)),l=a(74866),i=a(85162),p=a(55154),o=a(81742);const s={sidebar_position:2,title:"Configuration"},u=void 0,m={unversionedId:"integrations/spark/configuration",id:"integrations/spark/configuration",title:"Configuration",description:"Configuring the OpenLineage Spark integration is straightforward. It uses built-in Spark configuration mechanisms.",source:"@site/docs/integrations/spark/configuration.md",sourceDirName:"integrations/spark",slug:"/integrations/spark/configuration",permalink:"/docs/integrations/spark/configuration",draft:!1,editUrl:"https://github.com/OpenLineage/docs/tree/main/docs/integrations/spark/configuration.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2,title:"Configuration"},sidebar:"tutorialSidebar",previous:{title:"Installation",permalink:"/docs/integrations/spark/installation"},next:{title:"Column-level Lineage",permalink:"/docs/integrations/spark/spark_column_lineage"}},d={},k=[{value:"Setting the properties directly in your application",id:"setting-the-properties-directly-in-your-application",level:4},{value:"Using <code>--conf</code> options with the CLI",id:"using---conf-options-with-the-cli",level:4},{value:"Adding properties to the <code>spark-defaults.conf</code> file in the <code>${SPARK_HOME}/conf</code> directory",id:"adding-properties-to-the-spark-defaultsconf-file-in-the-spark_homeconf-directory",level:4},{value:"Spark Config Parameters",id:"spark-config-parameters",level:4},{value:"Transports",id:"transports",level:2},{value:"Circuit Breakers",id:"circuit-breakers",level:2}],c={toc:k};function g(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"Configuring the OpenLineage Spark integration is straightforward. It uses built-in Spark configuration mechanisms."),(0,r.kt)("p",null,"Your options are:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"#setting-the-properties-directly-in-your-application"},"Setting the properties directly in your application"),"."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"#using---conf-options-with-the-cli"},"Using ",(0,r.kt)("inlineCode",{parentName:"a"},"--conf")," options with the CLI"),"."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"#adding-properties-to-the-spark-defaultsconf-file-in-the-spark_homeconf-directory"},"Adding properties to the ",(0,r.kt)("inlineCode",{parentName:"a"},"spark-defaults.conf")," file in the ",(0,r.kt)("inlineCode",{parentName:"a"},"${SPARK_HOME}/conf")," directory"),".")),(0,r.kt)("h4",{id:"setting-the-properties-directly-in-your-application"},"Setting the properties directly in your application"),(0,r.kt)("p",null,"The below example demonstrates how to set the properties directly in your application when\nconstructing\na ",(0,r.kt)("inlineCode",{parentName:"p"},"SparkSession"),"."),(0,r.kt)("admonition",{type:"warning"},(0,r.kt)("p",{parentName:"admonition"},"The setting ",(0,r.kt)("inlineCode",{parentName:"p"},'config("spark.extraListeners", "io.openlineage.spark.agent.OpenLineageSparkListener")')," is\n",(0,r.kt)("strong",{parentName:"p"},"extremely important"),". Without it, the OpenLineage Spark integration will not be invoked, rendering\nthe integration ineffective.")),(0,r.kt)(l.Z,{groupId:"spark-app-conf",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import org.apache.spark.sql.SparkSession\n\nobject OpenLineageExample extends App {\n  val spark = SparkSession.builder()\n    .appName("OpenLineageExample")\n    // This line is EXTREMELY important\n    .config("spark.extraListeners", "io.openlineage.spark.agent.OpenLineageSparkListener")\n    .config("spark.openlineage.transport.type", "http")\n    .config("spark.openlineage.transport.url", "http://localhost:5000/api/v1/lineage")\n    .config("spark.openlineage.namespace", "MyNamespace")\n    .config("spark.openlineage.parentJobName", "ParentJobName")\n    .config("spark.openlineage.parentRunId", "xxxx-xxxx-xxxx-xxxx")\n    .getOrCreate()\n\n  // ... your code\n\n  spark.stop()\n}\n'))),(0,r.kt)(i.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from pyspark.sql import SparkSession\n\nspark = SparkSession.builder\n    .appName("OpenLineageExample")\n    .config("spark.extraListeners", "io.openlineage.spark.agent.OpenLineageSparkListener")\n    .config("spark.openlineage.transport.type", "http")\n    .config("spark.openlineage.transport.url", "http://localhost:5000/api/v1/lineage")\n    .config("spark.openlineage.namespace", "MyNamespace")\n    .config("spark.openlineage.parentJobName", "ParentJobName")\n    .config("spark.openlineage.parentRunId", "xxxx-xxxx-xxxx-xxxx")\n    .getOrCreate()\n\n# ... your code\n\nspark.stop()\n')))),(0,r.kt)("h4",{id:"using---conf-options-with-the-cli"},"Using ",(0,r.kt)("inlineCode",{parentName:"h4"},"--conf")," options with the CLI"),(0,r.kt)("p",null,"The below example demonstrates how to use the ",(0,r.kt)("inlineCode",{parentName:"p"},"--conf")," option with ",(0,r.kt)("inlineCode",{parentName:"p"},"spark-submit"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'spark-submit \\\n  --conf "spark.extraListeners=io.openlineage.spark.agent.OpenLineageSparkListener" \\\n  --conf "spark.openlineage.transport.type=http" \\\n  --conf "spark.openlineage.transport.url=http://localhost:5000/api/v1/lineage" \\\n  --conf "spark.openlineage.namespace=MyNamespace" \\\n  --conf "spark.openlineage.parentJobName=ParentJobName" \\\n  --conf "spark.openlineage.parentRunId=xxxx-xxxx-xxxx-xxxx" \\\n  # ... other options\n')),(0,r.kt)("h4",{id:"adding-properties-to-the-spark-defaultsconf-file-in-the-spark_homeconf-directory"},"Adding properties to the ",(0,r.kt)("inlineCode",{parentName:"h4"},"spark-defaults.conf")," file in the ",(0,r.kt)("inlineCode",{parentName:"h4"},"${SPARK_HOME}/conf")," directory"),(0,r.kt)("admonition",{type:"warning"},(0,r.kt)("p",{parentName:"admonition"},"You may need to create this file if it does not exist. If it does exist, ",(0,r.kt)("strong",{parentName:"p"},"we strongly suggest that\nyou back it up before making any changes"),", particularly if you are not the only user of the Spark\ninstallation. A misconfiguration here can have devastating effects on the operation of your Spark\ninstallation, particularly in a shared environment.")),(0,r.kt)("p",null,"The below example demonstrates how to add properties to the ",(0,r.kt)("inlineCode",{parentName:"p"},"spark-defaults.conf")," file."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-properties"},"spark.extraListeners=io.openlineage.spark.agent.OpenLineageSparkListener\nspark.openlineage.transport.type=http\nspark.openlineage.transport.url=http://localhost:5000/api/v1/lineage\nspark.openlineage.namespace=MyNamespace\n")),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"The ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.extraListeners")," configuration parameter is ",(0,r.kt)("strong",{parentName:"p"},"non-additive"),". This means that if you set\n",(0,r.kt)("inlineCode",{parentName:"p"},"spark.extraListeners")," via the CLI or via ",(0,r.kt)("inlineCode",{parentName:"p"},"SparkSession#config"),", it will ",(0,r.kt)("strong",{parentName:"p"},"replace")," the value\nin ",(0,r.kt)("inlineCode",{parentName:"p"},"spark-defaults.conf"),". This is important to remember if you are using ",(0,r.kt)("inlineCode",{parentName:"p"},"spark-defaults.conf")," to\nset a default value for ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.extraListeners")," and then want to override it for a specific job.")),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"When it comes to configuration parameters like ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.openlineage.namespace"),", a default value can\nbe supplied in the ",(0,r.kt)("inlineCode",{parentName:"p"},"spark-defaults.conf")," file. This default value can be overridden by the\napplication at runtime, via the previously detailed methods. However, it is ",(0,r.kt)("strong",{parentName:"p"},"strongly")," recommended\nthat more dynamic or quickly changing parameters like ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.openlineage.parentRunId")," or\n",(0,r.kt)("inlineCode",{parentName:"p"},"spark.openlineage.parentJobName")," be set at runtime via the CLI or ",(0,r.kt)("inlineCode",{parentName:"p"},"SparkSession#config")," methods.")),(0,r.kt)("h4",{id:"spark-config-parameters"},"Spark Config Parameters"),(0,r.kt)("p",null,"The following parameters can be specified:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.type"),(0,r.kt)("td",{parentName:"tr",align:null},"The transport type used for event emit, default type is ",(0,r.kt)("inlineCode",{parentName:"td"},"console")),(0,r.kt)("td",{parentName:"tr",align:null},"http")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.namespace"),(0,r.kt)("td",{parentName:"tr",align:null},"The default namespace to be applied for any jobs submitted"),(0,r.kt)("td",{parentName:"tr",align:null},"MyNamespace")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.parentJobName"),(0,r.kt)("td",{parentName:"tr",align:null},"The job name to be used for the parent job facet"),(0,r.kt)("td",{parentName:"tr",align:null},"ParentJobName")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.parentRunId"),(0,r.kt)("td",{parentName:"tr",align:null},"The RunId of the parent job that initiated this Spark job"),(0,r.kt)("td",{parentName:"tr",align:null},"xxxx-xxxx-xxxx-xxxx")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.appName"),(0,r.kt)("td",{parentName:"tr",align:null},"Custom value overwriting Spark app name in events"),(0,r.kt)("td",{parentName:"tr",align:null},"AppName")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.facets.disabled"),(0,r.kt)("td",{parentName:"tr",align:null},"List of facets to disable, enclosed in ",(0,r.kt)("inlineCode",{parentName:"td"},"[]")," (required from 0.21.x) and separated by ",(0,r.kt)("inlineCode",{parentName:"td"},";"),", default is ",(0,r.kt)("inlineCode",{parentName:"td"},"[spark_unknown;]")," (currently must contain ",(0,r.kt)("inlineCode",{parentName:"td"},";"),")"),(0,r.kt)("td",{parentName:"tr",align:null},"[","spark_unknown;spark.logicalPlan","]")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.capturedProperties"),(0,r.kt)("td",{parentName:"tr",align:null},"comma separated list of properties to be captured in spark properties facet (default ",(0,r.kt)("inlineCode",{parentName:"td"},"spark.master"),", ",(0,r.kt)("inlineCode",{parentName:"td"},"spark.app.name"),")"),(0,r.kt)("td",{parentName:"tr",align:null},'"spark.example1,spark.example2"')),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.dataset.removePath.pattern"),(0,r.kt)("td",{parentName:"tr",align:null},"Java regular expression that removes ",(0,r.kt)("inlineCode",{parentName:"td"},"?<remove>")," named group from dataset path. Can be used to last path subdirectories from paths like ",(0,r.kt)("inlineCode",{parentName:"td"},"s3://my-whatever-path/year=2023/month=04")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"(.*)(?<remove>\\/.*\\/.*)"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.jobName.appendDatasetName"),(0,r.kt)("td",{parentName:"tr",align:null},"Decides whether output dataset name should be appended to job name. By default ",(0,r.kt)("inlineCode",{parentName:"td"},"true"),"."),(0,r.kt)("td",{parentName:"tr",align:null},"false")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.jobName.replaceDotWithUnderscore"),(0,r.kt)("td",{parentName:"tr",align:null},"Replaces dots in job name with underscore. Can be used to mimic legacy behaviour on Databricks platform. By default ",(0,r.kt)("inlineCode",{parentName:"td"},"false"),"."),(0,r.kt)("td",{parentName:"tr",align:null},"false")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.debugFacet"),(0,r.kt)("td",{parentName:"tr",align:null},"Determines whether debug facet shall be generated and included within the event. Set ",(0,r.kt)("inlineCode",{parentName:"td"},"enabled")," to turn it on. By default, facet is disabled."),(0,r.kt)("td",{parentName:"tr",align:null},"enabled")))),(0,r.kt)("h2",{id:"transports"},"Transports"),(0,r.kt)(p.ZP,{mdxType:"Transports"}),(0,r.kt)("h2",{id:"circuit-breakers"},"Circuit Breakers"),(0,r.kt)(o.ZP,{mdxType:"CircuitBreakers"}))}g.isMDXComponent=!0}}]);