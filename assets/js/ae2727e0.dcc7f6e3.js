"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5828],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>k});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var p=n.createContext({}),s=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},u=function(e){var t=s(e.components);return n.createElement(p.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,p=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),d=s(a),k=r,c=d["".concat(p,".").concat(k)]||d[k]||m[k]||l;return a?n.createElement(c,i(i({ref:t},u),{},{components:a})):n.createElement(c,i({ref:t},u))}));function k(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,i=new Array(l);i[0]=d;var o={};for(var p in t)hasOwnProperty.call(t,p)&&(o[p]=t[p]);o.originalType=e,o.mdxType="string"==typeof e?e:r,i[1]=o;for(var s=2;s<l;s++)i[s]=a[s];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},85162:(e,t,a)=>{a.d(t,{Z:()=>i});var n=a(67294),r=a(86010);const l="tabItem_Ymn6";function i(e){let{children:t,hidden:a,className:i}=e;return n.createElement("div",{role:"tabpanel",className:(0,r.Z)(l,i),hidden:a},t)}},74866:(e,t,a)=>{a.d(t,{Z:()=>x});var n=a(87462),r=a(67294),l=a(86010),i=a(76775),o=a(91980),p=a(67392),s=a(50012);function u(e){return function(e){return r.Children.map(e,(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:a,attributes:n,default:r}}=e;return{value:t,label:a,attributes:n,default:r}}))}function m(e){const{values:t,children:a}=e;return(0,r.useMemo)((()=>{const e=t??u(a);return function(e){const t=(0,p.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,a])}function d(e){let{value:t,tabValues:a}=e;return a.some((e=>e.value===t))}function k(e){let{queryString:t=!1,groupId:a}=e;const n=(0,i.k6)(),l=function(e){let{queryString:t=!1,groupId:a}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!a)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return a??null}({queryString:t,groupId:a});return[(0,o._X)(l),(0,r.useCallback)((e=>{if(!l)return;const t=new URLSearchParams(n.location.search);t.set(l,e),n.replace({...n.location,search:t.toString()})}),[l,n])]}function c(e){const{defaultValue:t,queryString:a=!1,groupId:n}=e,l=m(e),[i,o]=(0,r.useState)((()=>function(e){let{defaultValue:t,tabValues:a}=e;if(0===a.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!d({value:t,tabValues:a}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${a.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const n=a.find((e=>e.default))??a[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:l}))),[p,u]=k({queryString:a,groupId:n}),[c,g]=function(e){let{groupId:t}=e;const a=function(e){return e?`docusaurus.tab.${e}`:null}(t),[n,l]=(0,s.Nk)(a);return[n,(0,r.useCallback)((e=>{a&&l.set(e)}),[a,l])]}({groupId:n}),h=(()=>{const e=p??c;return d({value:e,tabValues:l})?e:null})();(0,r.useLayoutEffect)((()=>{h&&o(h)}),[h]);return{selectedValue:i,selectValue:(0,r.useCallback)((e=>{if(!d({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);o(e),u(e),g(e)}),[u,g,l]),tabValues:l}}var g=a(12466),h=a(72389);const b="tabList__CuJ",N="tabItem_LNqP";function f(e){let{className:t,block:a,selectedValue:i,selectValue:o,tabValues:p}=e;const s=[],{blockElementScrollPositionUntilNextRender:u}=(0,g.o5)(),m=e=>{const t=e.currentTarget,a=s.indexOf(t),n=p[a].value;n!==i&&(u(t),o(n))},d=e=>{let t=null;switch(e.key){case"Enter":m(e);break;case"ArrowRight":{const a=s.indexOf(e.currentTarget)+1;t=s[a]??s[0];break}case"ArrowLeft":{const a=s.indexOf(e.currentTarget)-1;t=s[a]??s[s.length-1];break}}t?.focus()};return r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,l.Z)("tabs",{"tabs--block":a},t)},p.map((e=>{let{value:t,label:a,attributes:o}=e;return r.createElement("li",(0,n.Z)({role:"tab",tabIndex:i===t?0:-1,"aria-selected":i===t,key:t,ref:e=>s.push(e),onKeyDown:d,onClick:m},o,{className:(0,l.Z)("tabs__item",N,o?.className,{"tabs__item--active":i===t})}),a??t)})))}function y(e){let{lazy:t,children:a,selectedValue:n}=e;const l=(Array.isArray(a)?a:[a]).filter(Boolean);if(t){const e=l.find((e=>e.props.value===n));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return r.createElement("div",{className:"margin-top--md"},l.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==n}))))}function v(e){const t=c(e);return r.createElement("div",{className:(0,l.Z)("tabs-container",b)},r.createElement(f,(0,n.Z)({},e,t)),r.createElement(y,(0,n.Z)({},e,t)))}function x(e){const t=(0,h.Z)();return r.createElement(v,(0,n.Z)({key:String(t)},e))}},81742:(e,t,a)=>{a.d(t,{ZP:()=>p});var n=a(87462),r=(a(67294),a(3905)),l=a(74866),i=a(85162);const o={toc:[{value:"Simple Memory Circuit Breaker",id:"simple-memory-circuit-breaker",level:3},{value:"Java Runtime Circuit Breaker",id:"java-runtime-circuit-breaker",level:3},{value:"Custom Circuit Breaker",id:"custom-circuit-breaker",level:3}]};function p(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},o,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"This feature is available in OpenLineage versions >= 1.9.0.")),(0,r.kt)("p",null,"To prevent from over-instrumentation OpenLineage integration provides a circuit breaker mechanism\nthat stops OpenLineage from creating, serializing and sending OpenLineage events."),(0,r.kt)("h3",{id:"simple-memory-circuit-breaker"},"Simple Memory Circuit Breaker"),(0,r.kt)("p",null,"Simple circuit breaker which is working based only on free memory within JVM. Configuration should\ncontain free memory threshold limit (percentage). Default value is ",(0,r.kt)("inlineCode",{parentName:"p"},"20%"),". The circuit breaker\nwill close within first call if free memory is low. ",(0,r.kt)("inlineCode",{parentName:"p"},"circuitCheckIntervalInMillis")," parameter is used\nto configure a frequency circuit breaker is called. Default value is ",(0,r.kt)("inlineCode",{parentName:"p"},"1000ms"),", when no entry in config."),(0,r.kt)(l.Z,{groupId:"integrations",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"circuitBreaker:\n  type: simpleMemory\n  memoryThreshold: 20\n  circuitCheckIntervalInMillis: 1000\n"))),(0,r.kt)(i.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.type"),(0,r.kt)("td",{parentName:"tr",align:null},"Circuit breaker type selected"),(0,r.kt)("td",{parentName:"tr",align:null},"simpleMemory")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.memoryThreshold"),(0,r.kt)("td",{parentName:"tr",align:null},"Memory threshold"),(0,r.kt)("td",{parentName:"tr",align:null},"20")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.circuitCheckIntervalInMillis"),(0,r.kt)("td",{parentName:"tr",align:null},"Frequency of checking circuit breaker"),(0,r.kt)("td",{parentName:"tr",align:null},"1000"))))),(0,r.kt)(i.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.type"),(0,r.kt)("td",{parentName:"tr",align:null},"Circuit breaker type selected"),(0,r.kt)("td",{parentName:"tr",align:null},"simpleMemory")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.memoryThreshold"),(0,r.kt)("td",{parentName:"tr",align:null},"Memory threshold"),(0,r.kt)("td",{parentName:"tr",align:null},"20")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.circuitCheckIntervalInMillis"),(0,r.kt)("td",{parentName:"tr",align:null},"Frequency of checking circuit breaker"),(0,r.kt)("td",{parentName:"tr",align:null},"1000")))))),(0,r.kt)("h3",{id:"java-runtime-circuit-breaker"},"Java Runtime Circuit Breaker"),(0,r.kt)("p",null,"More complex version of circuit breaker. The amount of free memory can be low as long as\namount of time spent on Garbage Collection is acceptable. ",(0,r.kt)("inlineCode",{parentName:"p"},"JavaRuntimeCircuitBreaker")," closes\nwhen free memory drops below threshold and amount of time spent on garbage collection exceeds\ngiven threshold (",(0,r.kt)("inlineCode",{parentName:"p"},"10%")," by default). The circuit breaker is always open when checked for the first time\nas GC threshold is computed since the previous circuit breaker call.\n",(0,r.kt)("inlineCode",{parentName:"p"},"circuitCheckIntervalInMillis")," parameter is used\nto configure a frequency circuit breaker is called.\nDefault value is ",(0,r.kt)("inlineCode",{parentName:"p"},"1000ms"),", when no entry in config."),(0,r.kt)(l.Z,{groupId:"integrations",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"circuitBreaker:\n  type: javaRuntime\n  memoryThreshold: 20\n  gcCpuThreshold: 10\n  circuitCheckIntervalInMillis: 1000\n"))),(0,r.kt)(i.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.type"),(0,r.kt)("td",{parentName:"tr",align:null},"Circuit breaker type selected"),(0,r.kt)("td",{parentName:"tr",align:null},"javaRuntime")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.memoryThreshold"),(0,r.kt)("td",{parentName:"tr",align:null},"Memory threshold"),(0,r.kt)("td",{parentName:"tr",align:null},"20")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.gcCpuThreshold"),(0,r.kt)("td",{parentName:"tr",align:null},"Garbage Collection CPU threshold"),(0,r.kt)("td",{parentName:"tr",align:null},"10")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.circuitBreaker.circuitCheckIntervalInMillis"),(0,r.kt)("td",{parentName:"tr",align:null},"Frequency of checking circuit breaker"),(0,r.kt)("td",{parentName:"tr",align:null},"1000"))))),(0,r.kt)(i.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.type"),(0,r.kt)("td",{parentName:"tr",align:null},"Circuit breaker type selected"),(0,r.kt)("td",{parentName:"tr",align:null},"javaRuntime")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.memoryThreshold"),(0,r.kt)("td",{parentName:"tr",align:null},"Memory threshold"),(0,r.kt)("td",{parentName:"tr",align:null},"20")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.gcCpuThreshold"),(0,r.kt)("td",{parentName:"tr",align:null},"Garbage Collection CPU threshold"),(0,r.kt)("td",{parentName:"tr",align:null},"10")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.circuitBreaker.circuitCheckIntervalInMillis"),(0,r.kt)("td",{parentName:"tr",align:null},"Frequency of checking circuit breaker"),(0,r.kt)("td",{parentName:"tr",align:null},"1000")))))),(0,r.kt)("h3",{id:"custom-circuit-breaker"},"Custom Circuit Breaker"),(0,r.kt)("p",null,"List of available circuit breakers can be extended with custom one loaded via ServiceLoader\nwith own implementation of ",(0,r.kt)("inlineCode",{parentName:"p"},"io.openlineage.client.circuitBreaker.CircuitBreakerBuilder"),"."))}p.isMDXComponent=!0},55154:(e,t,a)=>{a.d(t,{ZP:()=>p});var n=a(87462),r=(a(67294),a(3905)),l=a(74866),i=a(85162);const o={toc:[{value:"HTTP",id:"http",level:3},{value:"Overriden default configuration of the <code>HttpTransport</code>",id:"overriden-default-configuration-of-the-httptransport",level:4},{value:"URL parsing within Spark integration",id:"url-parsing-within-spark-integration",level:4},{value:"Kafka",id:"kafka",level:3},{value:"Kinesis",id:"kinesis",level:3},{value:"Console",id:"console",level:3},{value:"File",id:"file",level:3}]};function p(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},o,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Tip:")," See current list of ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java/src/main/java/io/openlineage/client/transports"},"all supported transports"),"."),(0,r.kt)("h3",{id:"http"},(0,r.kt)("a",{parentName:"h3",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java/src/main/java/io/openlineage/client/transports/HttpTransport.java"},"HTTP")),(0,r.kt)("p",null,"Allows sending events to HTTP endpoint (with optional authorization headers)."),(0,r.kt)(l.Z,{groupId:"spark",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"Yaml Config",label:"Yaml Config",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: http\n  url: http://localhost:5000\n")),(0,r.kt)("p",null,"With authorization:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: http\n  url: http://localhost:5000\n  endpoint: api/v1/lineage\n  auth:\n    type: api_key\n    api_key: f38d2189-c603-4b46-bdea-e573a3b5a7d5\n")),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Override the default configuration of the HttpTransport within Java client"),(0,r.kt)("p",null,(0,r.kt)("h4",{id:"overriden-default-configuration-of-the-httptransport"},"Overriden default configuration of the ",(0,r.kt)("inlineCode",{parentName:"h4"},"HttpTransport")),(0,r.kt)("p",null,"You can override the default configuration of the ",(0,r.kt)("inlineCode",{parentName:"p"},"HttpTransport")," by specifying the URL and API key when\ncreating a new client:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'OpenLineageClient client = OpenLineageClient.builder()\n  .transport(\n    HttpTransport.builder()\n      .url("http://localhost:5000")\n      .apiKey("f38d2189-c603-4b46-bdea-e573a3b5a7d5")\n      .build())\n  .build();\n')),(0,r.kt)("p",null,"To configure the client with query params appended on each HTTP request, use:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'Map<String, String> queryParamsToAppend = Map.of(\n  "param0","value0",\n  "param1", "value1"\n);\n\n// Connect to http://localhost:5000\nOpenLineageClient client = OpenLineageClient.builder()\n  .transport(\n    HttpTransport.builder()\n      .url("http://localhost:5000", queryParamsToAppend)\n      .apiKey("f38d2189-c603-4b46-bdea-e573a3b5a7d5")\n      .build())\n  .build();\n\n// Define a simple OpenLineage START or COMPLETE event\nOpenLineage.RunEvent startOrCompleteRun = ...\n\n// Emit OpenLineage event to http://localhost:5000/api/v1/lineage?param0=value0&param1=value1\nclient.emit(startOrCompleteRun);\n'))))),(0,r.kt)(i.Z,{value:"Spark Config",label:"Spark Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.endpoint"),(0,r.kt)("td",{parentName:"tr",align:null},"Path to resource"),(0,r.kt)("td",{parentName:"tr",align:null},"/api/v1/lineage")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.auth.type"),(0,r.kt)("td",{parentName:"tr",align:null},"The type of authentication method to use"),(0,r.kt)("td",{parentName:"tr",align:null},"api_key")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.auth.apiKey"),(0,r.kt)("td",{parentName:"tr",align:null},"An API key to be used when sending events to the OpenLineage server"),(0,r.kt)("td",{parentName:"tr",align:null},"abcdefghijk")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.timeout"),(0,r.kt)("td",{parentName:"tr",align:null},"Timeout for sending OpenLineage info in milliseconds"),(0,r.kt)("td",{parentName:"tr",align:null},"5000")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.urlParams.xyz"),(0,r.kt)("td",{parentName:"tr",align:null},"A URL parameter (replace xyz) and value to be included in requests to the OpenLineage API server"),(0,r.kt)("td",{parentName:"tr",align:null},"abcdefghijk")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.url"),(0,r.kt)("td",{parentName:"tr",align:null},"The hostname of the OpenLineage API server where events should be reported, it can have other properties embeded"),(0,r.kt)("td",{parentName:"tr",align:null},"http://localhost:5000")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.headers.xyz"),(0,r.kt)("td",{parentName:"tr",align:null},"Request headers (replace xyz) and value to be included in requests to the OpenLineage API server"),(0,r.kt)("td",{parentName:"tr",align:null},"abcdefghijk")))),(0,r.kt)("details",null,(0,r.kt)("summary",null,"URL parsing within Spark integration"),(0,r.kt)("p",null,(0,r.kt)("h4",{id:"url-parsing-within-spark-integration"},"URL parsing within Spark integration"),(0,r.kt)("p",null,"You can supply http parameters using values in url, the parsed ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.openlineage.*")," properties are located in url as follows:"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"{transport.url}/{transport.endpoint}/namespaces/{namespace}/jobs/{parentJobName}/runs/{parentRunId}?app_name={appName}&api_key={transport.apiKey}&timeout={transport.timeout}&xxx={transport.urlParams.xxx}")),(0,r.kt)("p",null,"example:"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"http://localhost:5000/api/v1/namespaces/ns_name/jobs/job_name/runs/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx?app_name=app&api_key=abc&timeout=5000&xxx=xxx"))))),(0,r.kt)(i.Z,{value:"Flink Config",label:"Flink Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.endpoint"),(0,r.kt)("td",{parentName:"tr",align:null},"Path to resource"),(0,r.kt)("td",{parentName:"tr",align:null},"/api/v1/lineage")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.auth.type"),(0,r.kt)("td",{parentName:"tr",align:null},"The type of authentication method to use"),(0,r.kt)("td",{parentName:"tr",align:null},"api_key")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.auth.apiKey"),(0,r.kt)("td",{parentName:"tr",align:null},"An API key to be used when sending events to the OpenLineage server"),(0,r.kt)("td",{parentName:"tr",align:null},"abcdefghijk")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.timeout"),(0,r.kt)("td",{parentName:"tr",align:null},"Timeout for sending OpenLineage info in milliseconds"),(0,r.kt)("td",{parentName:"tr",align:null},"5000")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.urlParams.xyz"),(0,r.kt)("td",{parentName:"tr",align:null},"A URL parameter (replace xyz) and value to be included in requests to the OpenLineage API server"),(0,r.kt)("td",{parentName:"tr",align:null},"abcdefghijk")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.url"),(0,r.kt)("td",{parentName:"tr",align:null},"The hostname of the OpenLineage API server where events should be reported, it can have other properties embeded"),(0,r.kt)("td",{parentName:"tr",align:null},"http://localhost:5000")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.headers.xyz"),(0,r.kt)("td",{parentName:"tr",align:null},"Request headers (replace xyz) and value to be included in requests to the OpenLineage API server"),(0,r.kt)("td",{parentName:"tr",align:null},"abcdefghijk")))))),(0,r.kt)("h3",{id:"kafka"},(0,r.kt)("a",{parentName:"h3",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java/src/main/java/io/openlineage/client/transports/KafkaTransport.java"},"Kafka")),(0,r.kt)("p",null,"If a transport type is set to ",(0,r.kt)("inlineCode",{parentName:"p"},"kafka"),", then the below parameters would be read and used when building KafkaProducer.\nThis transport requires the artifact ",(0,r.kt)("inlineCode",{parentName:"p"},"org.apache.kafka:kafka-clients:3.1.0")," (or compatible) on your classpath."),(0,r.kt)(l.Z,{groupId:"integrations",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: kafka\n  topicName: openlineage.events\n  # Kafka properties (see: http://kafka.apache.org/0100/documentation.html#producerconfigs)\n  properties:\n    bootstrap.servers: localhost:9092,another.host:9092\n    acks: all\n    retries: 3\n    key.serializer: org.apache.kafka.common.serialization.StringSerializer\n    value.serializer: org.apache.kafka.common.serialization.StringSerializer\n"))),(0,r.kt)(i.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.topicName"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, name of the topic"),(0,r.kt)("td",{parentName:"tr",align:null},"topic-name")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.localServerId"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, id of local server"),(0,r.kt)("td",{parentName:"tr",align:null},"xxxxxxxx")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.properties.","[xxx]"),(0,r.kt)("td",{parentName:"tr",align:null},"Optional, the ","[xxx]"," is property of Kafka client"),(0,r.kt)("td",{parentName:"tr",align:null},"1"))))),(0,r.kt)(i.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.topicName"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, name of the topic"),(0,r.kt)("td",{parentName:"tr",align:null},"topic-name")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.localServerId"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, id of local server"),(0,r.kt)("td",{parentName:"tr",align:null},"xxxxxxxx")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.properties.","[xxx]"),(0,r.kt)("td",{parentName:"tr",align:null},"Optional, the ","[xxx]"," is property of Kafka client"),(0,r.kt)("td",{parentName:"tr",align:null},"1")))))),(0,r.kt)("h3",{id:"kinesis"},(0,r.kt)("a",{parentName:"h3",href:"https://github.com/OpenLineage/OpenLineage/blob/main/client/java/src/main/java/io/openlineage/client/transports/KinesisTransport.java"},"Kinesis")),(0,r.kt)("p",null,"If a transport type is set to ",(0,r.kt)("inlineCode",{parentName:"p"},"kinesis"),", then the below parameters would be read and used when building KinesisProducer.\nAlso, KinesisTransport depends on you to provide artifact ",(0,r.kt)("inlineCode",{parentName:"p"},"com.amazonaws:amazon-kinesis-producer:0.14.0")," or compatible on your classpath."),(0,r.kt)(l.Z,{groupId:"integrations",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: kinesis\n  streamName: your_kinesis_stream_name\n  topicName: openlineage.events\n  region: your_aws_region\n  roleArn: arn:aws:iam::account-id:role/role-name   # optional\n  properties:  # Refer to amazon-kinesis-producer's default configuration.md for the available properties\n    property_name_1: value_1\n    property_name_2: value_2\n"))),(0,r.kt)(i.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.streamName"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, the streamName of the Kinesis Stream"),(0,r.kt)("td",{parentName:"tr",align:null},"some-stream-name")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.region"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, the region of the stream"),(0,r.kt)("td",{parentName:"tr",align:null},"us-east-2")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.roleArn"),(0,r.kt)("td",{parentName:"tr",align:null},"Optional, the roleArn which is allowed to read/write to Kinesis stream"),(0,r.kt)("td",{parentName:"tr",align:null},"some-role-arn")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.properties.","[xxx]"),(0,r.kt)("td",{parentName:"tr",align:null},"Optional, the ","[xxx]"," is property of ",(0,r.kt)("a",{parentName:"td",href:"https://github.com/awslabs/amazon-kinesis-producer/blob/master/java/amazon-kinesis-producer-sample/default_config.properties"},"Kinesis allowd properties")),(0,r.kt)("td",{parentName:"tr",align:null},"1"))))),(0,r.kt)(i.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.streamName"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, the streamName of the Kinesis Stream"),(0,r.kt)("td",{parentName:"tr",align:null},"some-stream-name")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.region"),(0,r.kt)("td",{parentName:"tr",align:null},"Required, the region of the stream"),(0,r.kt)("td",{parentName:"tr",align:null},"us-east-2")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.roleArn"),(0,r.kt)("td",{parentName:"tr",align:null},"Optional, the roleArn which is allowed to read/write to Kinesis stream"),(0,r.kt)("td",{parentName:"tr",align:null},"some-role-arn")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.properties.","[xxx]"),(0,r.kt)("td",{parentName:"tr",align:null},"Optional, the ","[xxx]"," is property of ",(0,r.kt)("a",{parentName:"td",href:"https://github.com/awslabs/amazon-kinesis-producer/blob/master/java/amazon-kinesis-producer-sample/default_config.properties"},"Kinesis allowd properties")),(0,r.kt)("td",{parentName:"tr",align:null},"1")))))),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Behavior"),":"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Events are serialized to JSON upon the ",(0,r.kt)("inlineCode",{parentName:"li"},"emit()")," call and dispatched to the Kinesis stream."),(0,r.kt)("li",{parentName:"ul"},"The partition key is generated by combining the job's namespace and name."),(0,r.kt)("li",{parentName:"ul"},"Two constructors are available: one accepting both ",(0,r.kt)("inlineCode",{parentName:"li"},"KinesisProducer")," and ",(0,r.kt)("inlineCode",{parentName:"li"},"KinesisConfig")," and another solely accepting ",(0,r.kt)("inlineCode",{parentName:"li"},"KinesisConfig"),".")),(0,r.kt)("h3",{id:"console"},(0,r.kt)("a",{parentName:"h3",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java/src/main/java/io/openlineage/client/transports/ConsoleTransport.java"},"Console")),(0,r.kt)("p",null,"This straightforward transport emits OpenLineage events directly to the console through a logger.\nBe cautious when using the DEBUG log level, as it might result in double-logging due to the ",(0,r.kt)("inlineCode",{parentName:"p"},"OpenLineageClient")," also logging.\nNo additional configuration is required."),(0,r.kt)(l.Z,{groupId:"integrations",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: console\n"))),(0,r.kt)(i.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"}),(0,r.kt)(i.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"})),(0,r.kt)("h3",{id:"file"},(0,r.kt)("a",{parentName:"h3",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java/src/main/java/io/openlineage/client/transports/FileTransport.java"},"File")),(0,r.kt)("p",null,"Designed mainly for integration testing, the ",(0,r.kt)("inlineCode",{parentName:"p"},"FileTransport")," appends OpenLineage events to a given file.\nEvents are newline-separated, with all pre-existing newline characters within the event JSON removed."),(0,r.kt)(l.Z,{groupId:"integrations",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"yaml",label:"Yaml Config",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"transport:\n  type: file\n  location: /path/to/your/file.txt\n"))),(0,r.kt)(i.Z,{value:"spark",label:"Spark Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"spark.openlineage.transport.location"),(0,r.kt)("td",{parentName:"tr",align:null},"File path"),(0,r.kt)("td",{parentName:"tr",align:null},"/path/to/your/file.txt"))))),(0,r.kt)(i.Z,{value:"flink",label:"Flink Config",mdxType:"TabItem"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.location"),(0,r.kt)("td",{parentName:"tr",align:null},"File path"),(0,r.kt)("td",{parentName:"tr",align:null},"/path/to/your/file.txt")))))),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Notes"),":"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"If the target file is absent, it's created."),(0,r.kt)("li",{parentName:"ul"},"Events are added to the file, separated by newlines."),(0,r.kt)("li",{parentName:"ul"},"Intrinsic newline characters within the event JSON are eliminated to ensure one-line events.")))}p.isMDXComponent=!0},3058:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>u,contentTitle:()=>p,default:()=>k,frontMatter:()=>o,metadata:()=>s,toc:()=>m});var n=a(87462),r=(a(67294),a(3905)),l=a(55154),i=a(81742);const o={sidebar_position:4,title:"Apache Flink"},p=void 0,s={unversionedId:"integrations/flink",id:"integrations/flink",title:"Apache Flink",description:"Apache Flink is one of the most popular stream processing frameworks. Apache Flink jobs run on clusters,",source:"@site/docs/integrations/flink.md",sourceDirName:"integrations",slug:"/integrations/flink",permalink:"/docs/integrations/flink",draft:!1,editUrl:"https://github.com/OpenLineage/docs/tree/main/docs/integrations/flink.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4,title:"Apache Flink"},sidebar:"tutorialSidebar",previous:{title:"Job Hierarchy",permalink:"/docs/integrations/airflow/job-hierarchy"},next:{title:"dbt",permalink:"/docs/integrations/dbt"}},u={},m=[{value:"Getting lineage from Flink",id:"getting-lineage-from-flink",level:2},{value:"Limitations",id:"limitations",level:2},{value:"Usage",id:"usage",level:2},{value:"Configuring Openlineage connector",id:"configuring-openlineage-connector",level:2},{value:"Flink Configuration parameters",id:"flink-configuration-parameters",level:3},{value:"Transports",id:"transports",level:2},{value:"Circuit Breakers",id:"circuit-breakers",level:2}],d={toc:m};function k(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Apache Flink")," is one of the most popular stream processing frameworks. Apache Flink jobs run on clusters,\nwhich are composed of two types of nodes: ",(0,r.kt)("inlineCode",{parentName:"p"},"TaskManagers")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"JobManagers"),". While clusters typically consists of\nmultiple ",(0,r.kt)("inlineCode",{parentName:"p"},"TaskManagers"),", only reason to run multiple JobManagers is high availability. The jobs are ",(0,r.kt)("em",{parentName:"p"},"submitted"),"\nto ",(0,r.kt)("inlineCode",{parentName:"p"},"JobManager")," by ",(0,r.kt)("inlineCode",{parentName:"p"},"JobClient"),", that compiles user application into dataflow graph which is understandable by ",(0,r.kt)("inlineCode",{parentName:"p"},"JobManager"),".\n",(0,r.kt)("inlineCode",{parentName:"p"},"JobManager")," then coordinates job execution: it splits the parallel units of a job\nto ",(0,r.kt)("inlineCode",{parentName:"p"},"TaskManagers"),", manages heartbeats, triggers checkpoints, reacts to failures and much more."),(0,r.kt)("p",null,"Apache Flink has multiple deployment modes - Session Mode, Application Mode and Per-Job mode. The most popular\nare Session Mode and Application Mode. Session Mode consists of a ",(0,r.kt)("inlineCode",{parentName:"p"},"JobManager")," managing multiple jobs sharing single\nFlink cluster. In this mode, ",(0,r.kt)("inlineCode",{parentName:"p"},"JobClient")," is executed on a machine that submits the job to the cluster."),(0,r.kt)("p",null,"Application Mode is used where cluster is utilized for a single job. In this mode, ",(0,r.kt)("inlineCode",{parentName:"p"},"JobClient"),", where the main method runs,\nis executed on the ",(0,r.kt)("inlineCode",{parentName:"p"},"JobManager"),"."),(0,r.kt)("p",null,"Flink jobs read data from ",(0,r.kt)("inlineCode",{parentName:"p"},"Sources")," and write data to ",(0,r.kt)("inlineCode",{parentName:"p"},"Sinks"),". In contrast to systems like Apache Spark, Flink jobs can write\ndata to multiple places - they can have multiple ",(0,r.kt)("inlineCode",{parentName:"p"},"Sinks"),"."),(0,r.kt)("h2",{id:"getting-lineage-from-flink"},"Getting lineage from Flink"),(0,r.kt)("p",null,"OpenLineage utilizes Flink's ",(0,r.kt)("inlineCode",{parentName:"p"},"JobListener")," interface. This interface is used by Flink to notify user of job submission,\nsuccessful finish of job, or job failure. Implementations of this interface are executed on ",(0,r.kt)("inlineCode",{parentName:"p"},"JobClient"),". "),(0,r.kt)("p",null,"When OpenLineage listener receives information that job was submitted, it extracts ",(0,r.kt)("inlineCode",{parentName:"p"},"Transformations")," from job's\n",(0,r.kt)("inlineCode",{parentName:"p"},"ExecutionEnvironment"),". The ",(0,r.kt)("inlineCode",{parentName:"p"},"Transformations")," represent logical operations in the dataflow graph; they are composed\nof both Flink's build-in operators, but also user-provided ",(0,r.kt)("inlineCode",{parentName:"p"},"Sources"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Sinks")," and functions. To get the lineage,\nOpenLineage integration processes dataflow graph. Currently, OpenLineage is interested only in information contained\nin ",(0,r.kt)("inlineCode",{parentName:"p"},"Sources")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"Sinks"),", as they are the places where Flink interacts with external systems. "),(0,r.kt)("p",null,"After job submission, OpenLineage integration starts actively listening to checkpoints - this gives insight into\nwhether the job runs properly."),(0,r.kt)("h2",{id:"limitations"},"Limitations"),(0,r.kt)("p",null,"Currently OpenLineage's Flink integration is limited to getting information from jobs running in Application Mode."),(0,r.kt)("p",null,"OpenLineage integration extracts lineage only from following ",(0,r.kt)("inlineCode",{parentName:"p"},"Sources")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"Sinks"),":"),(0,r.kt)("table",null,(0,r.kt)("tbody",null,(0,r.kt)("tr",null,(0,r.kt)("th",null,"Sources"),(0,r.kt)("th",null,"Sinks")),(0,r.kt)("tr",null,(0,r.kt)("td",null,"KafkaSource"),(0,r.kt)("td",null,"KafkaSink (1)")),(0,r.kt)("tr",null,(0,r.kt)("td",null,"FlinkKafkaConsumer"),(0,r.kt)("td",null,"FlinkKafkaProducer")),(0,r.kt)("tr",null,(0,r.kt)("td",null,"IcebergFlinkSource"),(0,r.kt)("td",null,"IcebergFlinkSink")))),(0,r.kt)("p",null,"We expect this list to grow as we add support for more connectors."),(0,r.kt)("p",null,"(1) KafkaSink supports sinks that write to a single topic as well as multi topic sinks. The\nlimitation for multi topic sink is that: topics need to have the same schema and implementation\nof ",(0,r.kt)("inlineCode",{parentName:"p"},"KafkaRecordSerializationSchema")," must extend ",(0,r.kt)("inlineCode",{parentName:"p"},"KafkaTopicsDescriptor"),".\nMethods ",(0,r.kt)("inlineCode",{parentName:"p"},"isFixedTopics")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"getFixedTopics")," from ",(0,r.kt)("inlineCode",{parentName:"p"},"KafkaTopicsDescriptor")," are used to extract multiple topics\nfrom a sink. "),(0,r.kt)("h2",{id:"usage"},"Usage"),(0,r.kt)("p",null,"In your job, you need to set up ",(0,r.kt)("inlineCode",{parentName:"p"},"OpenLineageFlinkJobListener"),"."),(0,r.kt)("p",null,"For example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},"    JobListener listener = JobListener listener = OpenLineageFlinkJobListener.builder()\n        .executionEnvironment(streamExecutionEnvironment)\n        .build();\n    streamExecutionEnvironment.registerJobListener(listener);\n")),(0,r.kt)("p",null,"Also, OpenLineage needs certain parameters to be set in ",(0,r.kt)("inlineCode",{parentName:"p"},"flink-conf.yaml"),":"),(0,r.kt)("table",null,(0,r.kt)("tbody",null,(0,r.kt)("tr",null,(0,r.kt)("th",null,"Configuration Key"),(0,r.kt)("th",null,"Description"),(0,r.kt)("th",null,"Expected Value"),(0,r.kt)("th",null,"Default")),(0,r.kt)("tr",null,(0,r.kt)("td",null,"execution.attached"),(0,r.kt)("td",null,"This setting needs to be true if OpenLineage is to detect job start and failure"),(0,r.kt)("td",null,"true"),(0,r.kt)("td",null,"false")))),(0,r.kt)("p",null,"OpenLineage jar needs to be present on ",(0,r.kt)("inlineCode",{parentName:"p"},"JobManager"),"."),(0,r.kt)("p",null,"When the ",(0,r.kt)("inlineCode",{parentName:"p"},"JobListener")," is configured, you need to point the OpenLineage integration where the events should end up.\nIf you're using ",(0,r.kt)("inlineCode",{parentName:"p"},"Marquez"),", simplest way to do that is to set up ",(0,r.kt)("inlineCode",{parentName:"p"},"OPENLINEAGE_URL")," environment\nvariable to ",(0,r.kt)("inlineCode",{parentName:"p"},"Marquez")," URL. More advanced settings are ",(0,r.kt)("a",{parentName:"p",href:"/docs/client/java/"},"in the client documentation."),"."),(0,r.kt)("h2",{id:"configuring-openlineage-connector"},"Configuring Openlineage connector"),(0,r.kt)("p",null,"Flink Openlineage connector utilizes standard ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java"},"Java client for Openlineage"),"\nand allows all the configuration features present there to be used. The configuration can be passed with:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"openlineage.yml")," file with a environment property ",(0,r.kt)("inlineCode",{parentName:"li"},"OPENLINEAGE_CONFIG")," being set and pointing to configuration file. File structure and allowed options are described ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/tree/main/client/java#configuration"},"here"),"."),(0,r.kt)("li",{parentName:"ul"},"Standard Flink configuration with the parameters defined below.")),(0,r.kt)("h3",{id:"flink-configuration-parameters"},"Flink Configuration parameters"),(0,r.kt)("p",null,"The following parameters can be specified:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"Definition"),(0,r.kt)("th",{parentName:"tr",align:null},"Example"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.transport.type"),(0,r.kt)("td",{parentName:"tr",align:null},"The transport type used for event emit, default type is ",(0,r.kt)("inlineCode",{parentName:"td"},"console")),(0,r.kt)("td",{parentName:"tr",align:null},"http")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"openlineage.facets.disabled"),(0,r.kt)("td",{parentName:"tr",align:null},"List of facets to disable, enclosed in ",(0,r.kt)("inlineCode",{parentName:"td"},"[]")," (required from 0.21.x) and separated by ",(0,r.kt)("inlineCode",{parentName:"td"},";")),(0,r.kt)("td",{parentName:"tr",align:null},"[","some_facet1;some_facet1","]")))),(0,r.kt)("h2",{id:"transports"},"Transports"),(0,r.kt)(l.ZP,{mdxType:"Transports"}),(0,r.kt)("h2",{id:"circuit-breakers"},"Circuit Breakers"),(0,r.kt)(i.ZP,{mdxType:"CircuitBreakers"}))}k.isMDXComponent=!0}}]);