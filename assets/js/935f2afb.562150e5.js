"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"About OpenLineage","href":"/docs/","docId":"index"},{"type":"category","label":"Core Specification","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Object Model","href":"/docs/spec/object-model","docId":"spec/object-model"},{"type":"link","label":"Naming Conventions","href":"/docs/spec/naming","docId":"spec/naming"},{"type":"link","label":"The Run Cycle","href":"/docs/spec/run-cycle","docId":"spec/run-cycle"},{"type":"category","label":"Facets & Extensibility","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Run Facets","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Error Message Facet","href":"/docs/spec/facets/run-facets/error_message","docId":"spec/facets/run-facets/error_message"},{"type":"link","label":"External Query Facet","href":"/docs/spec/facets/run-facets/external_query","docId":"spec/facets/run-facets/external_query"},{"type":"link","label":"Nominal Time Facet","href":"/docs/spec/facets/run-facets/nominal_time","docId":"spec/facets/run-facets/nominal_time"},{"type":"link","label":"Parent Run Facet","href":"/docs/spec/facets/run-facets/parent_run","docId":"spec/facets/run-facets/parent_run"}],"href":"/docs/spec/facets/run-facets/"},{"type":"category","label":"Job Facets","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Documentation Facet","href":"/docs/spec/facets/job-facets/documentation","docId":"spec/facets/job-facets/documentation"},{"type":"link","label":"Ownership Job Facet","href":"/docs/spec/facets/job-facets/ownership","docId":"spec/facets/job-facets/ownership"},{"type":"link","label":"Source Code Facet","href":"/docs/spec/facets/job-facets/source-code","docId":"spec/facets/job-facets/source-code"},{"type":"link","label":"Source Code Location Facet","href":"/docs/spec/facets/job-facets/source-code-location","docId":"spec/facets/job-facets/source-code-location"},{"type":"link","label":"SQL Job Facet","href":"/docs/spec/facets/job-facets/sql","docId":"spec/facets/job-facets/sql"},{"type":"link","label":"Job type Job Facet","href":"/docs/spec/facets/job-facets/job-type","docId":"spec/facets/job-facets/job-type"}],"href":"/docs/spec/facets/job-facets/"},{"type":"category","label":"Dataset Facets","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Column Level Lineage Dataset Facet","href":"/docs/spec/facets/dataset-facets/column_lineage_facet","docId":"spec/facets/dataset-facets/column_lineage_facet"},{"type":"link","label":"Datasource Facet","href":"/docs/spec/facets/dataset-facets/data_source","docId":"spec/facets/dataset-facets/data_source"},{"type":"link","label":"Data Quality Assertions Facet","href":"/docs/spec/facets/dataset-facets/data_quality_assertions","docId":"spec/facets/dataset-facets/data_quality_assertions"},{"type":"link","label":"Lifecycle State Change Facet","href":"/docs/spec/facets/dataset-facets/lifecycle_state_change","docId":"spec/facets/dataset-facets/lifecycle_state_change"},{"type":"link","label":"Ownership Dataset Facet","href":"/docs/spec/facets/dataset-facets/ownership","docId":"spec/facets/dataset-facets/ownership"},{"type":"link","label":"Schema Dataset Facet","href":"/docs/spec/facets/dataset-facets/schema","docId":"spec/facets/dataset-facets/schema"},{"type":"link","label":"Storage Facet","href":"/docs/spec/facets/dataset-facets/storage","docId":"spec/facets/dataset-facets/storage"},{"type":"link","label":"Symlinks Facet","href":"/docs/spec/facets/dataset-facets/symlinks","docId":"spec/facets/dataset-facets/symlinks"},{"type":"link","label":"Version Facet","href":"/docs/spec/facets/dataset-facets/version_facet","docId":"spec/facets/dataset-facets/version_facet"},{"type":"category","label":"Input Dataset Facets","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Data Quality Metrics Facet","href":"/docs/spec/facets/dataset-facets/input-dataset-facets/data_quality_metrics","docId":"spec/facets/dataset-facets/input-dataset-facets/data_quality_metrics"}]},{"type":"category","label":"Output Dataset Facets","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Output Statistics Facet","href":"/docs/spec/facets/dataset-facets/output-dataset-facets/output_statistics","docId":"spec/facets/dataset-facets/output-dataset-facets/output_statistics"}]}],"href":"/docs/spec/facets/dataset-facets/"},{"type":"link","label":"Custom Facets","href":"/docs/spec/facets/custom-facets","docId":"spec/facets/custom-facets"}],"href":"/docs/spec/facets/"},{"type":"link","label":"Producers","href":"/docs/spec/producers","docId":"spec/producers"},{"type":"link","label":"Working with Schemas","href":"/docs/spec/schemas","docId":"spec/schemas"},{"type":"link","label":"Job Hierarchy","href":"/docs/spec/job-hierarchy","docId":"spec/job-hierarchy"}]},{"type":"category","label":"Client Libraries","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Java","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Configuration","href":"/docs/client/java/configuration","docId":"client/java/configuration"},{"type":"link","label":"Usage Example","href":"/docs/client/java/usage","docId":"client/java/usage"}],"href":"/docs/client/java/"},{"type":"link","label":"Python","href":"/docs/client/python","docId":"client/python"}]},{"type":"category","label":"Integrations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"OpenLineage Integrations","href":"/docs/integrations/about","docId":"integrations/about"},{"type":"category","label":"Apache Spark","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Main Concepts","href":"/docs/integrations/spark/main_concept","docId":"integrations/spark/main_concept"},{"type":"category","label":"Configuration","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Usage","href":"/docs/integrations/spark/configuration/usage","docId":"integrations/spark/configuration/usage"},{"type":"link","label":"Spark Config Parameters","href":"/docs/integrations/spark/configuration/spark_conf","docId":"integrations/spark/configuration/spark_conf"},{"type":"link","label":"Transport","href":"/docs/integrations/spark/configuration/transport","docId":"integrations/spark/configuration/transport"},{"type":"link","label":"Circuit Breaker","href":"/docs/integrations/spark/configuration/circuit_breaker","docId":"integrations/spark/configuration/circuit_breaker"},{"type":"link","label":"Scheduling from Airflow","href":"/docs/integrations/spark/configuration/airflow","docId":"integrations/spark/configuration/airflow"}]},{"type":"link","label":"Installation","href":"/docs/integrations/spark/installation","docId":"integrations/spark/installation"},{"type":"category","label":"Quickstart","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Quickstart with Jupyter","href":"/docs/integrations/spark/quickstart/quickstart_local","docId":"integrations/spark/quickstart/quickstart_local"},{"type":"link","label":"Quickstart with Databricks","href":"/docs/integrations/spark/quickstart/quickstart_databricks","docId":"integrations/spark/quickstart/quickstart_databricks"}]},{"type":"link","label":"Column-Level Lineage","href":"/docs/integrations/spark/spark_column_lineage","docId":"integrations/spark/spark_column_lineage"},{"type":"link","label":"Extending","href":"/docs/integrations/spark/extending","docId":"integrations/spark/extending"},{"type":"link","label":"Job Hierarchy","href":"/docs/integrations/spark/job-hierarchy","docId":"integrations/spark/job-hierarchy"},{"type":"link","label":"Spark Integration Metrics","href":"/docs/integrations/spark/metrics","docId":"integrations/spark/metrics"}],"href":"/docs/integrations/spark/"},{"type":"category","label":"Apache Airflow","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Using the Airflow Integration","href":"/docs/integrations/airflow/usage","docId":"integrations/airflow/usage"},{"type":"link","label":"Supported Airflow versions","href":"/docs/integrations/airflow/older","docId":"integrations/airflow/older"},{"type":"link","label":"Preflight check DAG","href":"/docs/integrations/airflow/preflight-check-dag","docId":"integrations/airflow/preflight-check-dag"},{"type":"link","label":"Exposing Lineage in Airflow Operators","href":"/docs/integrations/airflow/default-extractors","docId":"integrations/airflow/default-extractors"},{"type":"link","label":"Manually Annotated Lineage","href":"/docs/integrations/airflow/manual","docId":"integrations/airflow/manual"},{"type":"category","label":"Extractors","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Custom Extractors","href":"/docs/integrations/airflow/extractors/custom-extractors","docId":"integrations/airflow/extractors/custom-extractors"},{"type":"link","label":"Testing Custom Extractors","href":"/docs/integrations/airflow/extractors/extractor-testing","docId":"integrations/airflow/extractors/extractor-testing"}]},{"type":"link","label":"Job Hierarchy","href":"/docs/integrations/airflow/job-hierarchy","docId":"integrations/airflow/job-hierarchy"}],"href":"/docs/integrations/airflow/"},{"type":"link","label":"Apache Flink","href":"/docs/integrations/flink","docId":"integrations/flink"},{"type":"link","label":"dbt","href":"/docs/integrations/dbt","docId":"integrations/dbt"},{"type":"link","label":"Great Expectations","href":"/docs/integrations/great-expectations","docId":"integrations/great-expectations"}]},{"type":"category","label":"Guides","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"About These Guides","href":"/docs/guides/about","docId":"guides/about"},{"type":"link","label":"Getting Started with Airflow and OpenLineage+Marquez","href":"/docs/guides/airflow-quickstart","docId":"guides/airflow-quickstart"},{"type":"link","label":"Using OpenLineage with Spark","href":"/docs/guides/spark","docId":"guides/spark"},{"type":"link","label":"Backfilling Airflow DAGs Using Marquez","href":"/docs/guides/airflow-backfill-dags","docId":"guides/airflow-backfill-dags"},{"type":"link","label":"Using Marquez with dbt","href":"/docs/guides/dbt","docId":"guides/dbt"},{"type":"link","label":"Understanding and Using Facets","href":"/docs/guides/facets","docId":"guides/facets"},{"type":"link","label":"Using the OpenLineage Proxy with Airflow","href":"/docs/guides/airflow_proxy","docId":"guides/airflow_proxy"}]},{"type":"link","label":"Frequently Asked Questions","href":"/docs/faq","docId":"faq"},{"type":"category","label":"Development","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Developing With OpenLineage","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Python","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Setup a development environment","href":"/docs/development/developing/python/setup","docId":"development/developing/python/setup"},{"type":"category","label":"Tests","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Client","href":"/docs/development/developing/python/tests/client","docId":"development/developing/python/tests/client"},{"type":"link","label":"Airflow","href":"/docs/development/developing/python/tests/airflow","docId":"development/developing/python/tests/airflow"},{"type":"link","label":"Common","href":"/docs/development/developing/python/tests/common","docId":"development/developing/python/tests/common"},{"type":"link","label":"Dagster","href":"/docs/development/developing/python/tests/dagster","docId":"development/developing/python/tests/dagster"}]},{"type":"category","label":"Troubleshooting","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Logging","href":"/docs/development/developing/python/troubleshooting/logging","docId":"development/developing/python/troubleshooting/logging"}]},{"type":"category","label":"API Reference","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Python Client","href":"/docs/development/developing/python/api-reference/openlineage.client","docId":"development/developing/python/api-reference/openlineage.client"}]}]},{"type":"category","label":"Java","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Setup a development environment","href":"/docs/development/developing/java/setup","docId":"development/developing/java/setup"},{"type":"category","label":"Troubleshooting","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Logging","href":"/docs/development/developing/java/troubleshooting/logging","docId":"development/developing/java/troubleshooting/logging"}]},{"type":"link","label":"Metrics Backends","href":"/docs/development/developing/java/adding_metrics","docId":"development/developing/java/adding_metrics"}]},{"type":"category","label":"Spark","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Build","href":"/docs/development/developing/spark/setup","docId":"development/developing/spark/setup"},{"type":"link","label":"Integrating with Spark extensions","href":"/docs/development/developing/spark/built_in_lineage","docId":"development/developing/spark/built_in_lineage"}]}],"href":"/docs/development/developing/"},{"type":"link","label":"Example Lineage Events","href":"/docs/development/examples","docId":"development/examples"},{"type":"link","label":"OpenLineage Proxy","href":"/docs/development/ol-proxy","docId":"development/ol-proxy"}]},{"type":"category","label":"Releases","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"1.12.0","href":"/docs/releases/1_12_0","docId":"releases/1_12_0"},{"type":"link","label":"1.11.3","href":"/docs/releases/1_11_3","docId":"releases/1_11_3"},{"type":"link","label":"1.10.2","href":"/docs/releases/1_10_2","docId":"releases/1_10_2"},{"type":"link","label":"1.9.1","href":"/docs/releases/1_9_1","docId":"releases/1_9_1"},{"type":"link","label":"1.8.0","href":"/docs/releases/1_8_0","docId":"releases/1_8_0"},{"type":"link","label":"1.7.0","href":"/docs/releases/1_7_0","docId":"releases/1_7_0"},{"type":"link","label":"1.6.2","href":"/docs/releases/1_6_2","docId":"releases/1_6_2"},{"type":"link","label":"1.5.0","href":"/docs/releases/1_5_0","docId":"releases/1_5_0"},{"type":"link","label":"1.4.1","href":"/docs/releases/1_4_1","docId":"releases/1_4_1"},{"type":"link","label":"1.3.1","href":"/docs/releases/1_3_1","docId":"releases/1_3_1"},{"type":"link","label":"1.2.2","href":"/docs/releases/1_2_2","docId":"releases/1_2_2"},{"type":"link","label":"1.1.0","href":"/docs/releases/1_1_0","docId":"releases/1_1_0"},{"type":"link","label":"1.0.0","href":"/docs/releases/1_0_0","docId":"releases/1_0_0"},{"type":"link","label":"0.30.1","href":"/docs/releases/0_30_1","docId":"releases/0_30_1"},{"type":"link","label":"0.29.2","href":"/docs/releases/0_29_2","docId":"releases/0_29_2"},{"type":"link","label":"0.28.0","href":"/docs/releases/0_28_0","docId":"releases/0_28_0"},{"type":"link","label":"0.27.2","href":"/docs/releases/0_27_2","docId":"releases/0_27_2"},{"type":"link","label":"0.27.1","href":"/docs/releases/0_27_1","docId":"releases/0_27_1"},{"type":"link","label":"0.26.0","href":"/docs/releases/0_26_0","docId":"releases/0_26_0"},{"type":"link","label":"0.25.0","href":"/docs/releases/0_25_0","docId":"releases/0_25_0"},{"type":"link","label":"0.24.0","href":"/docs/releases/0_24_0","docId":"releases/0_24_0"},{"type":"link","label":"0.23.0","href":"/docs/releases/0_23_0","docId":"releases/0_23_0"},{"type":"link","label":"0.22.0","href":"/docs/releases/0_22_0","docId":"releases/0_22_0"},{"type":"link","label":"0.21.1","href":"/docs/releases/0_21_1","docId":"releases/0_21_1"},{"type":"link","label":"0.20.6","href":"/docs/releases/0_20_6","docId":"releases/0_20_6"},{"type":"link","label":"0.20.4","href":"/docs/releases/0_20_4","docId":"releases/0_20_4"},{"type":"link","label":"0.19.2","href":"/docs/releases/0_19_2","docId":"releases/0_19_2"},{"type":"link","label":"0.18.0","href":"/docs/releases/0_18_0","docId":"releases/0_18_0"},{"type":"link","label":"0.17.0","href":"/docs/releases/0_17_0","docId":"releases/0_17_0"},{"type":"link","label":"0.16.1","href":"/docs/releases/0_16_1","docId":"releases/0_16_1"},{"type":"link","label":"0.15.1","href":"/docs/releases/0_15_1","docId":"releases/0_15_1"},{"type":"link","label":"0.14.1","href":"/docs/releases/0_14_1","docId":"releases/0_14_1"},{"type":"link","label":"0.14.0","href":"/docs/releases/0_14_0","docId":"releases/0_14_0"},{"type":"link","label":"0.13.1","href":"/docs/releases/0_13_1","docId":"releases/0_13_1"},{"type":"link","label":"0.13.0","href":"/docs/releases/0_13_0","docId":"releases/0_13_0"},{"type":"link","label":"0.12.0","href":"/docs/releases/0_12_0","docId":"releases/0_12_0"},{"type":"link","label":"0.11.0","href":"/docs/releases/0_11_0","docId":"releases/0_11_0"},{"type":"link","label":"0.10.0","href":"/docs/releases/0_10_0","docId":"releases/0_10_0"},{"type":"link","label":"0.9.0","href":"/docs/releases/0_9_0","docId":"releases/0_9_0"},{"type":"link","label":"0.8.2","href":"/docs/releases/0_8_2","docId":"releases/0_8_2"},{"type":"link","label":"0.8.1","href":"/docs/releases/0_8_1","docId":"releases/0_8_1"},{"type":"link","label":"0.7.1","href":"/docs/releases/0_7_1","docId":"releases/0_7_1"},{"type":"link","label":"0.6.2","href":"/docs/releases/0_6_2","docId":"releases/0_6_2"},{"type":"link","label":"0.6.1","href":"/docs/releases/0_6_1","docId":"releases/0_6_1"},{"type":"link","label":"0.6.0","href":"/docs/releases/0_6_0","docId":"releases/0_6_0"},{"type":"link","label":"0.5.2","href":"/docs/releases/0_5_2","docId":"releases/0_5_2"},{"type":"link","label":"0.5.1","href":"/docs/releases/0_5_1","docId":"releases/0_5_1"},{"type":"link","label":"0.4.0","href":"/docs/releases/0_4_0","docId":"releases/0_4_0"},{"type":"link","label":"0.3.1","href":"/docs/releases/0_3_1","docId":"releases/0_3_1"},{"type":"link","label":"0.3.0","href":"/docs/releases/0_3_0","docId":"releases/0_3_0"},{"type":"link","label":"0.2.3","href":"/docs/releases/0_2_3","docId":"releases/0_2_3"},{"type":"link","label":"0.2.2","href":"/docs/releases/0_2_2","docId":"releases/0_2_2"},{"type":"link","label":"0.2.1","href":"/docs/releases/0_2_1","docId":"releases/0_2_1"},{"type":"link","label":"0.2.0","href":"/docs/releases/0_2_0","docId":"releases/0_2_0"},{"type":"link","label":"0.1.0","href":"/docs/releases/0_1_0","docId":"releases/0_1_0"}]}]},"docs":{"client/java/configuration":{"id":"client/java/configuration","title":"Configuration","description":"We recommend configuring the client with an openlineage.yml file that contains all the","sidebar":"tutorialSidebar"},"client/java/java":{"id":"client/java/java","title":"Java","description":"Overview","sidebar":"tutorialSidebar"},"client/java/usage":{"id":"client/java/usage","title":"Usage Example","description":"1. Simple OpenLineage Client Test for Console Transport","sidebar":"tutorialSidebar"},"client/python":{"id":"client/python","title":"Python","description":"Overview","sidebar":"tutorialSidebar"},"development/developing/developing":{"id":"development/developing/developing","title":"Developing With OpenLineage","description":"As there are hundreds and possibly thousands databases, query engines and other tools you could use to process, create and move data, there\'s great chance that existing OpenLineage integration won\'t cover your needs.","sidebar":"tutorialSidebar"},"development/developing/java/adding_metrics":{"id":"development/developing/java/adding_metrics","title":"Metrics Backends","description":"To integrate additional metrics backend into the OpenLineage client, implement the MeterRegistryFactory interface and ensure it is utilized by the MicrometerProvider\'s getMetricsBuilders method.","sidebar":"tutorialSidebar"},"development/developing/java/setup":{"id":"development/developing/java/setup","title":"Setup a development environment","description":"This page needs your contribution! Please contribute new examples using the edit link at the bottom.","sidebar":"tutorialSidebar"},"development/developing/java/troubleshooting/logging":{"id":"development/developing/java/troubleshooting/logging","title":"Logging","description":"OpenLineage Java library is based on slf4j when generating logs. Being able to emit logs for various purposes is very helpful when troubleshooting OpenLineage.","sidebar":"tutorialSidebar"},"development/developing/python/api-reference/openlineage.client":{"id":"development/developing/python/api-reference/openlineage.client","title":"Python Client","description":"\\\\n\\\\n\\\\n On this page\\\\n  \\\\n\\\\n\\\\nopenlineage.client.client module\\\\nOpenLineageClientOptions\\\\nOpenLineageClientOptions.timeout\\\\nOpenLineageClientOptions.verify\\\\nOpenLineageClientOptions.apikey\\\\nOpenLineageClientOptions.adapter\\\\n\\\\n\\\\nOpenLineageClient\\\\nOpenLineageClient.emit()\\\\nOpenLineageClient.fromenvironment()\\\\nOpenLineageClient.fromdict()\\\\nOpenLineageClient.filterevent()\\\\nOpenLineageClient.config\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.eventv2 module\\\\nBaseEvent\\\\nBaseEvent.eventTime\\\\nBaseEvent.producer\\\\nBaseEvent.schemaURL\\\\nBaseEvent.skipredact\\\\nBaseEvent.eventtimecheck()\\\\nBaseEvent.producercheck()\\\\nBaseEvent.schemaurlcheck()\\\\n\\\\n\\\\nRunEvent\\\\nRunEvent.run\\\\nRunEvent.job\\\\nRunEvent.eventType\\\\nRunEvent.inputs\\\\nRunEvent.outputs\\\\n\\\\n\\\\nJobEvent\\\\nJobEvent.job\\\\nJobEvent.inputs\\\\nJobEvent.outputs\\\\n\\\\n\\\\nDatasetEvent\\\\nDatasetEvent.dataset\\\\n\\\\n\\\\nRunState\\\\nDataset\\\\nDataset.namespace\\\\nDataset.name\\\\nDataset.facets\\\\n\\\\n\\\\nInputDataset\\\\nInputDataset.inputFacets\\\\n\\\\n\\\\nOutputDataset\\\\nOutputDataset.outputFacets\\\\n\\\\n\\\\nRun\\\\nRun.runId\\\\nRun.facets\\\\nRun.runidcheck()\\\\n\\\\n\\\\nJob\\\\nJob.namespace\\\\nJob.name\\\\nJob.facets\\\\n\\\\n\\\\nsetproducer()\\\\n\\\\n\\\\nopenlineage.client.facet module\\\\nsetproducer()\\\\nBaseFacet\\\\nBaseFacet.skipredact\\\\n\\\\n\\\\nNominalTimeRunFacet\\\\nNominalTimeRunFacet.nominalStartTime\\\\nNominalTimeRunFacet.nominalEndTime\\\\n\\\\n\\\\nParentRunFacet\\\\nParentRunFacet.run\\\\nParentRunFacet.job\\\\nParentRunFacet.create()\\\\n\\\\n\\\\nDocumentationJobFacet\\\\nDocumentationJobFacet.description\\\\n\\\\n\\\\nSourceCodeLocationJobFacet\\\\nSourceCodeLocationJobFacet.type\\\\nSourceCodeLocationJobFacet.url\\\\n\\\\n\\\\nSqlJobFacet\\\\nSqlJobFacet.query\\\\n\\\\n\\\\nDocumentationDatasetFacet\\\\nDocumentationDatasetFacet.description\\\\n\\\\n\\\\nSchemaField\\\\nSchemaField.name\\\\nSchemaField.type\\\\nSchemaField.description\\\\n\\\\n\\\\nSchemaDatasetFacet\\\\nSchemaDatasetFacet.fields\\\\n\\\\n\\\\nDataSourceDatasetFacet\\\\nDataSourceDatasetFacet.name\\\\nDataSourceDatasetFacet.uri\\\\n\\\\n\\\\nOutputStatisticsOutputDatasetFacet\\\\nOutputStatisticsOutputDatasetFacet.rowCount\\\\nOutputStatisticsOutputDatasetFacet.size\\\\nOutputStatisticsOutputDatasetFacet.fileCount\\\\n\\\\n\\\\nColumnMetric\\\\nColumnMetric.nullCount\\\\nColumnMetric.distinctCount\\\\nColumnMetric.sum\\\\nColumnMetric.count\\\\nColumnMetric.min\\\\nColumnMetric.max\\\\nColumnMetric.quantiles\\\\n\\\\n\\\\nDataQualityMetricsInputDatasetFacet\\\\nDataQualityMetricsInputDatasetFacet.rowCount\\\\nDataQualityMetricsInputDatasetFacet.bytes\\\\nDataQualityMetricsInputDatasetFacet.fileCount\\\\nDataQualityMetricsInputDatasetFacet.columnMetrics\\\\n\\\\n\\\\nAssertion\\\\nAssertion.assertion\\\\nAssertion.success\\\\nAssertion.column\\\\n\\\\n\\\\nDataQualityAssertionsDatasetFacet\\\\nDataQualityAssertionsDatasetFacet.assertions\\\\n\\\\n\\\\nSourceCodeJobFacet\\\\nSourceCodeJobFacet.language\\\\nSourceCodeJobFacet.source\\\\n\\\\n\\\\nExternalQueryRunFacet\\\\nExternalQueryRunFacet.externalQueryId\\\\nExternalQueryRunFacet.source\\\\n\\\\n\\\\nErrorMessageRunFacet\\\\nErrorMessageRunFacet.message\\\\nErrorMessageRunFacet.programmingLanguage\\\\nErrorMessageRunFacet.stackTrace\\\\n\\\\n\\\\nSymlinksDatasetFacetIdentifiers\\\\nSymlinksDatasetFacetIdentifiers.namespace\\\\nSymlinksDatasetFacetIdentifiers.name\\\\nSymlinksDatasetFacetIdentifiers.type\\\\n\\\\n\\\\nSymlinksDatasetFacet\\\\nSymlinksDatasetFacet.identifiers\\\\n\\\\n\\\\nStorageDatasetFacet\\\\nStorageDatasetFacet.storageLayer\\\\nStorageDatasetFacet.fileFormat\\\\n\\\\n\\\\nOwnershipJobFacetOwners\\\\nOwnershipJobFacetOwners.name\\\\nOwnershipJobFacetOwners.type\\\\n\\\\n\\\\nOwnershipJobFacet\\\\nOwnershipJobFacet.owners\\\\n\\\\n\\\\nJobTypeJobFacet\\\\nJobTypeJobFacet.processingType\\\\nJobTypeJobFacet.integration\\\\nJobTypeJobFacet.jobType\\\\n\\\\n\\\\nDatasetVersionDatasetFacet\\\\nDatasetVersionDatasetFacet.datasetVersion\\\\n\\\\n\\\\nLifecycleStateChange\\\\nLifecycleStateChange.ALTER\\\\nLifecycleStateChange.CREATE\\\\nLifecycleStateChange.DROP\\\\nLifecycleStateChange.OVERWRITE\\\\nLifecycleStateChange.RENAME\\\\nLifecycleStateChange.TRUNCATE\\\\n\\\\n\\\\nLifecycleStateChangeDatasetFacetPreviousIdentifier\\\\nLifecycleStateChangeDatasetFacetPreviousIdentifier.name\\\\nLifecycleStateChangeDatasetFacetPreviousIdentifier.namespace\\\\n\\\\n\\\\nLifecycleStateChangeDatasetFacet\\\\nLifecycleStateChangeDatasetFacet.lifecycleStateChange\\\\nLifecycleStateChangeDatasetFacet.previousIdentifier\\\\n\\\\n\\\\nOwnershipDatasetFacetOwners\\\\nOwnershipDatasetFacetOwners.name\\\\nOwnershipDatasetFacetOwners.type\\\\n\\\\n\\\\nOwnershipDatasetFacet\\\\nOwnershipDatasetFacet.owners\\\\n\\\\n\\\\nColumnLineageDatasetFacetFieldsAdditionalInputFields\\\\nColumnLineageDatasetFacetFieldsAdditionalInputFields.namespace\\\\nColumnLineageDatasetFacetFieldsAdditionalInputFields.name\\\\nColumnLineageDatasetFacetFieldsAdditionalInputFields.field\\\\n\\\\n\\\\nColumnLineageDatasetFacetFieldsAdditional\\\\nColumnLineageDatasetFacetFieldsAdditional.inputFields\\\\nColumnLineageDatasetFacetFieldsAdditional.transformationDescription\\\\nColumnLineageDatasetFacetFieldsAdditional.transformationType\\\\n\\\\n\\\\nColumnLineageDatasetFacet\\\\nColumnLineageDatasetFacet.fields\\\\n\\\\n\\\\nProcessingEngineRunFacet\\\\nProcessingEngineRunFacet.version\\\\nProcessingEngineRunFacet.name\\\\nProcessingEngineRunFacet.openlineageAdapterVersion\\\\n\\\\n\\\\nExtractionError\\\\nExtractionError.errorMessage\\\\nExtractionError.stackTrace\\\\nExtractionError.task\\\\nExtractionError.taskNumber\\\\n\\\\n\\\\nExtractionErrorRunFacet\\\\nExtractionErrorRunFacet.totalTasks\\\\nExtractionErrorRunFacet.failedTasks\\\\nExtractionErrorRunFacet.errors\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.facetv2 module\\\\nBaseFacet\\\\nBaseFacet.skipredact\\\\n\\\\n\\\\nDatasetFacet\\\\nInputDatasetFacet\\\\nJobFacet\\\\nOutputDatasetFacet\\\\nRunFacet\\\\nsetproducer()\\\\n\\\\n\\\\nopenlineage.client.filter module\\\\nFilter\\\\nFilter.filterevent()\\\\n\\\\n\\\\nExactMatchFilter\\\\nExactMatchFilter.filterevent()\\\\n\\\\n\\\\nRegexFilter\\\\nRegexFilter.filterevent()\\\\n\\\\n\\\\ncreatefilter()\\\\n\\\\n\\\\nopenlineage.client.run module\\\\nRunState\\\\nRunState.START\\\\nRunState.RUNNING\\\\nRunState.COMPLETE\\\\nRunState.ABORT\\\\nRunState.FAIL\\\\nRunState.OTHER\\\\n\\\\n\\\\nDataset\\\\nDataset.namespace\\\\nDataset.name\\\\nDataset.facets\\\\n\\\\n\\\\nInputDataset\\\\nInputDataset.inputFacets\\\\n\\\\n\\\\nOutputDataset\\\\nOutputDataset.outputFacets\\\\n\\\\n\\\\nDatasetEvent\\\\nDatasetEvent.eventTime\\\\nDatasetEvent.producer\\\\nDatasetEvent.schemaURL\\\\nDatasetEvent.dataset\\\\n\\\\n\\\\nJob\\\\nJob.namespace\\\\nJob.name\\\\nJob.facets\\\\n\\\\n\\\\nJobEvent\\\\nJobEvent.eventTime\\\\nJobEvent.producer\\\\nJobEvent.schemaURL\\\\nJobEvent.job\\\\nJobEvent.inputs\\\\nJobEvent.outputs\\\\n\\\\n\\\\nRun\\\\nRun.runId\\\\nRun.facets\\\\nRun.check()\\\\n\\\\n\\\\nRunEvent\\\\nRunEvent.eventType\\\\nRunEvent.eventTime\\\\nRunEvent.run\\\\nRunEvent.job\\\\nRunEvent.producer\\\\nRunEvent.inputs\\\\nRunEvent.outputs\\\\nRunEvent.schemaURL\\\\nRunEvent.check()\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.serde module\\\\nSerde\\\\nSerde.removenullsandenums()\\\\nSerde.todict()\\\\nSerde.tojson()\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.utils module\\\\nimportfromstring()\\\\ntryimportfromstring()\\\\ngetonlyspecifiedfields()\\\\nRedactMixin\\\\nRedactMixin.skipredact\\\\n\\\\n\\\\nloadconfig()\\\\n\\\\n\\\\nopenlineage.client.generated.base module\\\\nsetproducer()\\\\nBaseEvent\\\\nBaseEvent.eventTime\\\\nBaseEvent.producer\\\\nBaseEvent.schemaURL\\\\nBaseEvent.skipredact\\\\nBaseEvent.eventtimecheck()\\\\nBaseEvent.producercheck()\\\\nBaseEvent.schemaurlcheck()\\\\n\\\\n\\\\nBaseFacet\\\\nBaseFacet.skipredact\\\\n\\\\n\\\\nDataset\\\\nDataset.namespace\\\\nDataset.name\\\\nDataset.facets\\\\n\\\\n\\\\nDatasetEvent\\\\nDatasetEvent.dataset\\\\n\\\\n\\\\nDatasetFacet\\\\nEventType\\\\nEventType.START\\\\nEventType.RUNNING\\\\nEventType.COMPLETE\\\\nEventType.ABORT\\\\nEventType.FAIL\\\\nEventType.OTHER\\\\n\\\\n\\\\nInputDataset\\\\nInputDataset.inputFacets\\\\n\\\\n\\\\nInputDatasetFacet\\\\nJob\\\\nJob.namespace\\\\nJob.name\\\\nJob.facets\\\\n\\\\n\\\\nJobEvent\\\\nJobEvent.job\\\\nJobEvent.inputs\\\\nJobEvent.outputs\\\\n\\\\n\\\\nJobFacet\\\\nOutputDataset\\\\nOutputDataset.outputFacets\\\\n\\\\n\\\\nOutputDatasetFacet\\\\nRun\\\\nRun.runId\\\\nRun.facets\\\\nRun.runidcheck()\\\\n\\\\n\\\\nRunEvent\\\\nRunEvent.run\\\\nRunEvent.job\\\\nRunEvent.eventType\\\\nRunEvent.inputs\\\\nRunEvent.outputs\\\\n\\\\n\\\\nRunFacet\\\\nStaticDataset\\\\n\\\\n\\\\nopenlineage.client.generated.columnlineagedataset module\\\\nColumnLineageDatasetFacet\\\\nColumnLineageDatasetFacet.fields\\\\n\\\\n\\\\nFields\\\\nFields.inputFields\\\\nFields.transformationDescription\\\\nFields.transformationType\\\\n\\\\n\\\\nInputField\\\\nInputField.namespace\\\\nInputField.name\\\\nInputField.field\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.dataqualityassertionsdataset module\\\\nAssertion\\\\nAssertion.assertion\\\\nAssertion.success\\\\nAssertion.column\\\\n\\\\n\\\\nDataQualityAssertionsDatasetFacet\\\\nDataQualityAssertionsDatasetFacet.assertions\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.dataqualitymetricsinputdataset module\\\\nColumnMetrics\\\\nColumnMetrics.nullCount\\\\nColumnMetrics.distinctCount\\\\nColumnMetrics.sum\\\\nColumnMetrics.count\\\\nColumnMetrics.min\\\\nColumnMetrics.max\\\\nColumnMetrics.quantiles\\\\n\\\\n\\\\nDataQualityMetricsInputDatasetFacet\\\\nDataQualityMetricsInputDatasetFacet.columnMetrics\\\\nDataQualityMetricsInputDatasetFacet.rowCount\\\\nDataQualityMetricsInputDatasetFacet.bytes\\\\nDataQualityMetricsInputDatasetFacet.fileCount\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.datasetversiondataset module\\\\nDatasetVersionDatasetFacet\\\\nDatasetVersionDatasetFacet.datasetVersion\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.datasourcedataset module\\\\nDatasourceDatasetFacet\\\\nDatasourceDatasetFacet.name\\\\nDatasourceDatasetFacet.uri\\\\nDatasourceDatasetFacet.uricheck()\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.documentationdataset module\\\\nDocumentationDatasetFacet\\\\nDocumentationDatasetFacet.description\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.documentationjob module\\\\nDocumentationJobFacet\\\\nDocumentationJobFacet.description\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.errormessagerun module\\\\nErrorMessageRunFacet\\\\nErrorMessageRunFacet.message\\\\nErrorMessageRunFacet.programmingLanguage\\\\nErrorMessageRunFacet.stackTrace\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.externalqueryrun module\\\\nExternalQueryRunFacet\\\\nExternalQueryRunFacet.externalQueryId\\\\nExternalQueryRunFacet.source\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.extractionerrorrun module\\\\nError\\\\nError.errorMessage\\\\nError.stackTrace\\\\nError.task\\\\nError.taskNumber\\\\n\\\\n\\\\nExtractionErrorRunFacet\\\\nExtractionErrorRunFacet.totalTasks\\\\nExtractionErrorRunFacet.failedTasks\\\\nExtractionErrorRunFacet.errors\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.jobtypejob module\\\\nJobTypeJobFacet\\\\nJobTypeJobFacet.processingType\\\\nJobTypeJobFacet.integration\\\\nJobTypeJobFacet.jobType\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.lifecyclestatechangedataset module\\\\nLifecycleStateChange\\\\nLifecycleStateChange.ALTER\\\\nLifecycleStateChange.CREATE\\\\nLifecycleStateChange.DROP\\\\nLifecycleStateChange.OVERWRITE\\\\nLifecycleStateChange.RENAME\\\\nLifecycleStateChange.TRUNCATE\\\\n\\\\n\\\\nLifecycleStateChangeDatasetFacet\\\\nLifecycleStateChangeDatasetFacet.lifecycleStateChange\\\\nLifecycleStateChangeDatasetFacet.previousIdentifier\\\\n\\\\n\\\\nPreviousIdentifier\\\\nPreviousIdentifier.name\\\\nPreviousIdentifier.namespace\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.nominaltimerun module\\\\nNominalTimeRunFacet\\\\nNominalTimeRunFacet.nominalStartTime\\\\nNominalTimeRunFacet.nominalEndTime\\\\nNominalTimeRunFacet.nominalstarttimecheck()\\\\nNominalTimeRunFacet.nominalendtimecheck()\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.outputstatisticsoutputdataset module\\\\nOutputStatisticsOutputDatasetFacet\\\\nOutputStatisticsOutputDatasetFacet.rowCount\\\\nOutputStatisticsOutputDatasetFacet.size\\\\nOutputStatisticsOutputDatasetFacet.fileCount\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.ownershipdataset module\\\\nOwner\\\\nOwner.name\\\\nOwner.type\\\\n\\\\n\\\\nOwnershipDatasetFacet\\\\nOwnershipDatasetFacet.owners\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.ownershipjob module\\\\nOwner\\\\nOwner.name\\\\nOwner.type\\\\n\\\\n\\\\nOwnershipJobFacet\\\\nOwnershipJobFacet.owners\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.parentrun module\\\\nJob\\\\nJob.namespace\\\\nJob.name\\\\n\\\\n\\\\nParentRunFacet\\\\nParentRunFacet.run\\\\nParentRunFacet.job\\\\nParentRunFacet.create()\\\\n\\\\n\\\\nRun\\\\nRun.runId\\\\nRun.runidcheck()\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.processingenginerun module\\\\nProcessingEngineRunFacet\\\\nProcessingEngineRunFacet.version\\\\nProcessingEngineRunFacet.name\\\\nProcessingEngineRunFacet.openlineageAdapterVersion\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.schemadataset module\\\\nSchemaDatasetFacet\\\\nSchemaDatasetFacet.fields\\\\n\\\\n\\\\nSchemaDatasetFacetFields\\\\nSchemaDatasetFacetFields.name\\\\nSchemaDatasetFacetFields.type\\\\nSchemaDatasetFacetFields.description\\\\nSchemaDatasetFacetFields.fields\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.sourcecodejob module\\\\nSourceCodeJobFacet\\\\nSourceCodeJobFacet.language\\\\nSourceCodeJobFacet.sourceCode\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.sourcecodelocationjob module\\\\nSourceCodeLocationJobFacet\\\\nSourceCodeLocationJobFacet.type\\\\nSourceCodeLocationJobFacet.url\\\\nSourceCodeLocationJobFacet.repoUrl\\\\nSourceCodeLocationJobFacet.path\\\\nSourceCodeLocationJobFacet.version\\\\nSourceCodeLocationJobFacet.tag\\\\nSourceCodeLocationJobFacet.branch\\\\nSourceCodeLocationJobFacet.urlcheck()\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.sqljob module\\\\nSQLJobFacet\\\\nSQLJobFacet.query\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.storagedataset module\\\\nStorageDatasetFacet\\\\nStorageDatasetFacet.storageLayer\\\\nStorageDatasetFacet.fileFormat\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.symlinksdataset module\\\\nIdentifier\\\\nIdentifier.namespace\\\\nIdentifier.name\\\\nIdentifier.type\\\\n\\\\n\\\\nSymlinksDatasetFacet\\\\nSymlinksDatasetFacet.identifiers\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.transport.console module\\\\nConsoleConfig\\\\nConsoleTransport\\\\nConsoleTransport.kind\\\\nConsoleTransport.configclass\\\\nConsoleTransport.emit()\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.transport.factory module\\\\nDefaultTransportFactory\\\\nDefaultTransportFactory.registertransport()\\\\nDefaultTransportFactory.create()\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.transport.file module\\\\nFileConfig\\\\nFileConfig.logfilepath\\\\nFileConfig.append\\\\nFileConfig.fromdict()\\\\n\\\\n\\\\nFileTransport\\\\nFileTransport.kind\\\\nFileTransport.configclass\\\\nFileTransport.emit()\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.transport.http module\\\\nTokenProvider\\\\nTokenProvider.getbearer()\\\\n\\\\n\\\\nHttpCompression\\\\nHttpCompression.GZIP\\\\n\\\\n\\\\nApiKeyTokenProvider\\\\nApiKeyTokenProvider.getbearer()\\\\n\\\\n\\\\ncreatetokenprovider()\\\\ngetsession()\\\\nHttpConfig\\\\nHttpConfig.url\\\\nHttpConfig.endpoint\\\\nHttpConfig.timeout\\\\nHttpConfig.verify\\\\nHttpConfig.auth\\\\nHttpConfig.compression\\\\nHttpConfig.session\\\\nHttpConfig.adapter\\\\nHttpConfig.fromdict()\\\\nHttpConfig.fromoptions()\\\\n\\\\n\\\\nHttpTransport\\\\nHttpTransport.kind\\\\nHttpTransport.configclass\\\\nHttpTransport.setadapter()\\\\nHttpTransport.emit()\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.transport.kafka module\\\\nKafkaConfig\\\\nKafkaConfig.config\\\\nKafkaConfig.topic\\\\nKafkaConfig.messageKey\\\\nKafkaConfig.flush\\\\nKafkaConfig.fromdict()\\\\n\\\\n\\\\nondelivery()\\\\nKafkaTransport\\\\nKafkaTransport.kind\\\\nKafkaTransport.configclass\\\\nKafkaTransport.emit()\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.transport.mskiam module\\\\nMSKIAMConfig\\\\nMSKIAMConfig.region\\\\nMSKIAMConfig.awsprofile\\\\nMSKIAMConfig.rolearn\\\\nMSKIAMConfig.awsdebugcreds\\\\n\\\\n\\\\nMSKIAMTransport\\\\nMSKIAMTransport.kind\\\\nMSKIAMTransport.configclass\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.transport.noop module\\\\nNoopConfig\\\\nNoopTransport\\\\nNoopTransport.kind\\\\nNoopTransport.configclass\\\\nNoopTransport.emit()\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.transport.transport module\\\\nConfig\\\\nConfig.fromdict()\\\\n\\\\n\\\\nTransport\\\\nTransport.kind\\\\nTransport.configclass\\\\nTransport.emit()\\\\n\\\\n\\\\nTransportFactory\\\\nTransportFactory.create()\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n Show Source\\\\n    \\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.client module\\\\n\\\\n\\\\nclass openlineage.client.client.OpenLineageClientOptions(timeout=5.0, verify=True, apikey=None, adapter=None)\\\\nBases\\\\n\\\\ntimeout (float)\\\\nverify (bool)\\\\napikey (Optionalstr])\\\\nadapter (Optional[HTTPAdapter])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntimeout bool\\\\n\\\\n\\\\n\\\\napikey HTTPAdapter\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.client.OpenLineageClient(url=None, options=None, session=None, transport=None, factory=None)\\\\nBases\\\\n\\\\nurl (str | None)\\\\noptions (OpenLineageClientOptions | None)\\\\nsession (Session | None)\\\\ntransport (Transport | None)\\\\nfactory (TransportFactory | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nemit(event)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod fromenvironment()\\\\n\\\\nReturn type\\\\nconfig (dict[str, str])\\\\n\\\\nReturn type\\\\nevent (Event)\\\\n\\\\nReturn type dict[str, Any]\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.eventv2 module\\\\n\\\\n\\\\nclass openlineage.client.eventv2.BaseEvent(, eventTime, producer=\'\')\\\\nBases\\\\n\\\\neventTime (str)\\\\nproducer (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\neventTime str\\\\n\\\\n\\\\n\\\\nschemaURL list[str]\\\\n\\\\n\\\\n\\\\neventtime_check(attribute, value)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproducer_check(attribute, value)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nschemaurl_check(attribute, value)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.event_v2.RunEvent(, eventTime, producer=\'\', run, job, eventType=None, inputs=Nothing.NOTHING, outputs=Nothing.NOTHING)\\\\nBases\\\\n\\\\neventTime (str)\\\\nproducer (str)\\\\nrun (Run)\\\\njob (Job)\\\\neventType (EventType | None)\\\\ninputs (list[InputDataset] | None)\\\\noutputs (list[OutputDataset] | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nrun Job\\\\n\\\\n\\\\n\\\\neventType list[InputDataset] | None\\\\nThe set of input datasets.\\\\n\\\\n\\\\n\\\\noutputs BaseEvent\\\\n\\\\nParameters Job\\\\n\\\\n\\\\n\\\\ninputs list[OutputDataset] | None\\\\nThe set of output datasets.\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.eventv2.DatasetEvent(, eventTime, producer=\'\', dataset)\\\\nBases\\\\n\\\\neventTime (str)\\\\nproducer (str)\\\\ndataset (StaticDataset)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndataset RedactMixin\\\\n\\\\nParameters str\\\\nThe namespace containing that dataset\\\\n\\\\n\\\\n\\\\nname dict[str, DatasetFacet] | None\\\\nThe facets for this dataset\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.eventv2.InputDataset(namespace, name, inputFacets=Nothing.NOTHING, *, facets=Nothing.NOTHING)\\\\nBases\\\\n\\\\nnamespace (str)\\\\nname (str)\\\\ninputFacets (dict[str, InputDatasetFacet] | None)\\\\nfacets (dict[str, DatasetFacet] | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ninputFacets Dataset\\\\nAn output dataset\\\\n\\\\nParameters dict[str, OutputDatasetFacet] | None\\\\nThe output facets for this dataset\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.event_v2.Run(runId, facets=_Nothing.NOTHING)\\\\nBases\\\\n\\\\nrunId (str)\\\\nfacets (dict[str, RunFacet] | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nrunId dict[str, RunFacet] | None\\\\nThe run facets.\\\\n\\\\n\\\\n\\\\nrunid_check(attribute, value)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.event_v2.Job(namespace, name, facets=_Nothing.NOTHING)\\\\nBases\\\\n\\\\nnamespace (str)\\\\nname (str)\\\\nfacets (dict[str, JobFacet] | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nnamespace str\\\\nThe unique name for that job within that namespace\\\\n\\\\n\\\\n\\\\nfacets\\\\nproducer (str)\\\\n\\\\nReturn type\\\\nproducer (str)\\\\n\\\\nReturn type RedactMixin\\\\n\\\\n\\\\n\\\\n\\\\nproperty skip_redact BaseFacet\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\nnominalEndTime BaseFacet\\\\n\\\\nParameters Dict[Any, Any]\\\\n\\\\n\\\\n\\\\njob\\\\n\\\\nrunId (str)\\\\nnamespace (str)\\\\nname (str)\\\\n\\\\n\\\\nReturn type BaseFacet\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.SourceCodeLocationJobFacet(type, url)\\\\nBases\\\\n\\\\ntype (str)\\\\nurl (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntype str\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.SqlJobFacet(query)\\\\nBases\\\\nquery (str)\\\\n\\\\n\\\\n\\\\n\\\\nquery BaseFacet\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.SchemaField(name, type, description=None)\\\\nBases\\\\n\\\\nname (str)\\\\ntype (str)\\\\ndescription (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nname str\\\\n\\\\n\\\\n\\\\ndescription BaseFacet\\\\n\\\\nParameters List[SchemaField]\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.DataSourceDatasetFacet(name, uri)\\\\nBases\\\\n\\\\nname (str)\\\\nuri (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nname str\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.OutputStatisticsOutputDatasetFacet(rowCount=None, size=None, fileCount=None)\\\\nBases\\\\n\\\\nrowCount (Optional[int])\\\\nsize (Optional[int])\\\\nfileCount (Optional[int])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nrowCount Optional[int]\\\\n\\\\n\\\\n\\\\nfileCount object\\\\n\\\\nParameters Optional[int]\\\\n\\\\n\\\\n\\\\ndistinctCount Optional[int]\\\\n\\\\n\\\\n\\\\ncount Optional[float]\\\\n\\\\n\\\\n\\\\nmax Optional[Dict[str, float]]\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.DataQualityMetricsInputDatasetFacet(rowCount=None, bytes=None, fileCount=None, columnMetrics=_Nothing.NOTHING)\\\\nBases\\\\n\\\\nrowCount (Optional[int])\\\\nbytes (Optional[int])\\\\nfileCount (Optional[int])\\\\ncolumnMetrics (Dict[str, ColumnMetric])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nrowCount Optional[int]\\\\n\\\\n\\\\n\\\\nfileCount Dict[str, ColumnMetric]\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.Assertion(assertion, success, column=None)\\\\nBases\\\\n\\\\nassertion (str)\\\\nsuccess (bool)\\\\ncolumn (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nassertion bool\\\\n\\\\n\\\\n\\\\ncolumn BaseFacet\\\\nThis facet represents asserted expectations on dataset or it\\\\u2019s column.\\\\n\\\\nParameters List[Assertion]\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.SourceCodeJobFacet(language, source)\\\\nBases\\\\n\\\\nlanguage (str)\\\\nsource (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nlanguage str\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.ExternalQueryRunFacet(externalQueryId, source)\\\\nBases\\\\n\\\\nexternalQueryId (str)\\\\nsource (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nexternalQueryId str\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.ErrorMessageRunFacet(message, programmingLanguage, stackTrace=None)\\\\nBases\\\\n\\\\nmessage (str)\\\\nprogrammingLanguage (str)\\\\nstackTrace (Optional[str])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nmessage str\\\\n\\\\n\\\\n\\\\nstackTrace object\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\nname str\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.SymlinksDatasetFacet(identifiers=_Nothing.NOTHING)\\\\nBases\\\\nidentifiers (List[SymlinksDatasetFacetIdentifiers])\\\\n\\\\n\\\\n\\\\n\\\\nidentifiers BaseFacet\\\\nThis facet represents dataset symlink names.\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\nfileFormat object\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\ntype BaseFacet\\\\nThis facet represents ownership of a job.\\\\n\\\\nParameters List[OwnershipJobFacetOwners]\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.JobTypeJobFacet(processingType, integration, jobType)\\\\nBases\\\\n\\\\nprocessingType (str)\\\\nintegration (str)\\\\njobType (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nprocessingType str\\\\n\\\\n\\\\n\\\\njobType BaseFacet\\\\nThis facet represents version of a dataset.\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.LifecycleStateChange(value)\\\\nBases object\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\nnamespace BaseFacet\\\\nThis facet represents information of lifecycle changes of a dataset.\\\\n\\\\nParameters LifecycleStateChange\\\\n\\\\n\\\\n\\\\npreviousIdentifier object\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\ntype BaseFacet\\\\nThis facet represents ownership of a dataset.\\\\n\\\\nParameters List[OwnershipDatasetFacetOwners]\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.ColumnLineageDatasetFacetFieldsAdditionalInputFields(namespace, name, field)\\\\nBases\\\\n\\\\nnamespace (str)\\\\nname (str)\\\\nfield (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nnamespace str\\\\n\\\\n\\\\n\\\\nfield object\\\\n\\\\nParameters ClassVar[List[ColumnLineageDatasetFacetFieldsAdditionalInputFields]]\\\\n\\\\n\\\\n\\\\ntransformationDescription str\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.ColumnLineageDatasetFacet(fields=_Nothing.NOTHING)\\\\nBases\\\\nfields (Dict[str, ColumnLineageDatasetFacetFieldsAdditional])\\\\n\\\\n\\\\n\\\\n\\\\nfields BaseFacet\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\nname str\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.ExtractionError(errorMessage, stackTrace, task, taskNumber)\\\\nBases\\\\n\\\\nerrorMessage (str)\\\\nstackTrace (Optional[str])\\\\ntask (Optional[str])\\\\ntaskNumber (Optional[int])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nerrorMessage Optional[str]\\\\n\\\\n\\\\n\\\\ntask Optional[int]\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet.ExtractionErrorRunFacet(totalTasks, failedTasks, errors)\\\\nBases\\\\n\\\\ntotalTasks (int)\\\\nfailedTasks (int)\\\\nerrors (List[ExtractionError])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntotalTasks int\\\\n\\\\n\\\\n\\\\nerrors RedactMixin\\\\nall fields of the base facet are prefixed with  to avoid name conflicts in facets\\\\n\\\\nParameters list[str]\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facetv2.DatasetFacet(*, producer=\'\', deleted=None)\\\\nBases\\\\n\\\\nproducer (str)\\\\ndeleted (bool | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facetv2.InputDatasetFacet(, producer=\'\')\\\\nBases\\\\nproducer (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facet_v2.JobFacet(, producer=\'\', deleted=None)\\\\nBases\\\\n\\\\nproducer (str)\\\\ndeleted (bool | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facetv2.OutputDatasetFacet(*, producer=\'\')\\\\nBases\\\\nproducer (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.facetv2.RunFacet(, producer=\'\')\\\\nBases\\\\nproducer (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.facet_v2.set_producer(producer)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.filter module\\\\n\\\\n\\\\nclass openlineage.client.filter.Filter\\\\nBases\\\\nevent (RunEventType)\\\\n\\\\nReturn type Filter\\\\n\\\\nParameters\\\\nevent (RunEventType)\\\\n\\\\nReturn type Filter\\\\n\\\\nParameters\\\\nevent (RunEventType)\\\\n\\\\nReturn type\\\\nconf (dict[str, str])\\\\n\\\\nReturn type Enum\\\\nAn enumeration.\\\\n\\\\n\\\\nSTART = \'START\'\\\\n\\\\n\\\\n\\\\nRUNNING = \'RUNNING\'\\\\n\\\\n\\\\n\\\\nCOMPLETE = \'COMPLETE\'\\\\n\\\\n\\\\n\\\\nABORT = \'ABORT\'\\\\n\\\\n\\\\n\\\\nFAIL = \'FAIL\'\\\\n\\\\n\\\\n\\\\nOTHER = \'OTHER\'\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.run.Dataset(namespace, name, facets=_Nothing.NOTHING)\\\\nBases\\\\n\\\\nnamespace (str)\\\\nname (str)\\\\nfacets (Dict[Any, Any])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nnamespace str\\\\n\\\\n\\\\n\\\\nfacets Dataset\\\\n\\\\nParameters Dict[Any, Any]\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.run.OutputDataset(namespace, name, facets=_Nothing.NOTHING, outputFacets=_Nothing.NOTHING)\\\\nBases\\\\n\\\\nnamespace (str)\\\\nname (str)\\\\nfacets (Dict[Any, Any])\\\\noutputFacets (Dict[Any, Any])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\noutputFacets RedactMixin\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\nproducer str\\\\n\\\\n\\\\n\\\\ndataset RedactMixin\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\nname Dict[Any, Any]\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.run.JobEvent(eventTime, producer, schemaURL, job, inputs=_Nothing.NOTHING, outputs=_Nothing.NOTHING)\\\\nBases\\\\n\\\\neventTime (str)\\\\nproducer (str)\\\\nschemaURL (str)\\\\njob (Job)\\\\ninputs (Optional[List[Dataset]])\\\\noutputs (Optional[List[Dataset]])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\neventTime str\\\\n\\\\n\\\\n\\\\nschemaURL Job\\\\n\\\\n\\\\n\\\\ninputs Optional[List[Dataset]]\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.run.Run(runId, facets=_Nothing.NOTHING)\\\\nBases\\\\n\\\\nrunId (str)\\\\nfacets (Dict[Any, Any])\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nrunId Dict[Any, Any]\\\\n\\\\n\\\\n\\\\ncheck(attribute, value)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.run.RunEvent(eventType, eventTime, run, job, producer, inputs=_Nothing.NOTHING, outputs=_Nothing.NOTHING, schemaURL=\'https RedactMixin\\\\n\\\\nParameters RunState\\\\n\\\\n\\\\n\\\\neventTime Run\\\\n\\\\n\\\\n\\\\njob str\\\\n\\\\n\\\\n\\\\ninputs Optional[List[Dataset]]\\\\n\\\\n\\\\n\\\\nschemaURL\\\\n\\\\nattribute (str)\\\\nvalue (str)\\\\n\\\\n\\\\nReturn type object\\\\n\\\\n\\\\nclassmethod remove_nulls_and_enums(obj)\\\\n\\\\nParameters\\\\nAny\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod to_dict(obj)\\\\n\\\\nParameters\\\\ndict[Any, Any]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclassmethod to_json(obj)\\\\n\\\\nParameters\\\\nstr\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.utils module\\\\n\\\\n\\\\nopenlineage.client.utils.import_from_string(path)\\\\n\\\\nParameters\\\\ntype[Any]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.utils.try_import_from_string(path)\\\\n\\\\nParameters\\\\ntype[Any] | None\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.utils.get_only_specified_fields(clazz, params)\\\\n\\\\nParameters\\\\ndict[str, Any]\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.utils.RedactMixin\\\\nBases list[str]\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.utils.load_config()\\\\n\\\\nReturn type\\\\nproducer (str)\\\\n\\\\nReturn type RedactMixin\\\\n\\\\nParameters str\\\\nthe time the event occurred at\\\\n\\\\n\\\\n\\\\nproducer str\\\\n\\\\n\\\\n\\\\nproperty skipredact\\\\n\\\\n\\\\n\\\\neventtimecheck(attribute, value)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nproducercheck(attribute, value)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nschemaurlcheck(attribute, value)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.base.BaseFacet(, producer=\'\')\\\\nBases\\\\nproducer (str)\\\\n\\\\n\\\\n\\\\n\\\\nproperty skip_redact\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.base.Dataset(namespace, name, , facets=Nothing.NOTHING)\\\\nBases\\\\n\\\\nnamespace (str)\\\\nname (str)\\\\nfacets (dict[str, DatasetFacet] | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nnamespace str\\\\nThe unique name for that dataset within that namespace\\\\n\\\\n\\\\n\\\\nfacets BaseEvent\\\\n\\\\nParameters StaticDataset\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.base.DatasetFacet(*, producer=\'\', deleted=None)\\\\nBases\\\\n\\\\nproducer (str)\\\\ndeleted (bool | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.base.EventType(value)\\\\nBases Dataset\\\\nAn input dataset\\\\n\\\\n\\\\ninputFacets BaseFacet\\\\nAn Input Dataset Facet\\\\n\\\\nParameters RedactMixin\\\\n\\\\nParameters str\\\\nThe namespace containing that job\\\\n\\\\n\\\\n\\\\nname dict[str, JobFacet] | None\\\\nThe job facets.\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.base.JobEvent(*, eventTime, producer=\'\', job, inputs=Nothing.NOTHING, outputs=Nothing.NOTHING)\\\\nBases Job\\\\n\\\\n\\\\n\\\\ninputs list[OutputDataset] | None\\\\nThe set of output datasets.\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.base.JobFacet(*, producer=\'\', deleted=None)\\\\nBases\\\\n\\\\nproducer (str)\\\\ndeleted (bool | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.base.OutputDataset(namespace, name, outputFacets=Nothing.NOTHING, , facets=_Nothing.NOTHING)\\\\nBases dict[str, OutputDatasetFacet] | None\\\\nThe output facets for this dataset\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.base.OutputDatasetFacet(, producer=\'\')\\\\nBases\\\\nproducer (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.base.Run(runId, facets=Nothing.NOTHING)\\\\nBases\\\\n\\\\nrunId (str)\\\\nfacets (dict[str, RunFacet] | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nrunId dict[str, RunFacet] | None\\\\nThe run facets.\\\\n\\\\n\\\\n\\\\nrunidcheck(attribute, value)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.base.RunEvent(, eventTime, producer=\'\', run, job, eventType=None, inputs=_Nothing.NOTHING, outputs=_Nothing.NOTHING)\\\\nBases\\\\n\\\\neventTime (str)\\\\nproducer (str)\\\\nrun (Run)\\\\njob (Job)\\\\neventType (EventType | None)\\\\ninputs (list[InputDataset] | None)\\\\noutputs (list[OutputDataset] | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nrun Job\\\\n\\\\n\\\\n\\\\neventType list[InputDataset] | None\\\\nThe set of input datasets.\\\\n\\\\n\\\\n\\\\noutputs BaseFacet\\\\nA Run Facet\\\\n\\\\nParameters Dataset\\\\nA Dataset sent within static metadata events\\\\n\\\\nParameters DatasetFacet\\\\n\\\\nParameters dict[str, Fields]\\\\nColumn level lineage that maps output fields into input fields used to evaluate them.\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.columnlineagedataset.Fields(inputFields, transformationDescription=None, transformationType=None)\\\\nBases\\\\n\\\\ninputFields (list[InputField])\\\\ntransformationDescription (str | None)\\\\ntransformationType (str | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ninputFields str | None\\\\na string representation of the transformation applied\\\\n\\\\n\\\\n\\\\ntransformationType\\\\nIDENTITY|MASKED reflects a clearly defined behavior. IDENTITY\\\\n\\\\nType RedactMixin\\\\n\\\\nParameters str\\\\nThe input dataset namespace\\\\n\\\\n\\\\n\\\\nname str\\\\nThe input field\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.dataqualityassertionsdataset module\\\\n\\\\n\\\\nclass openlineage.client.generated.dataqualityassertionsdataset.Assertion(assertion, success, column=None)\\\\nBases\\\\n\\\\nassertion (str)\\\\nsuccess (bool)\\\\ncolumn (str | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nassertion bool\\\\n\\\\n\\\\n\\\\ncolumn InputDatasetFacet\\\\nlist of tests performed on dataset or dataset columns, and their results\\\\n\\\\nParameters list[Assertion]\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.dataqualitymetricsinputdataset module\\\\n\\\\n\\\\nclass openlineage.client.generated.dataqualitymetricsinputdataset.ColumnMetrics(nullCount=None, distinctCount=None, sum=None, count=None, min=None, max=None, quantiles=Nothing.NOTHING)\\\\nBases\\\\n\\\\nnullCount (int | None)\\\\ndistinctCount (int | None)\\\\nsum (float | None)\\\\ncount (float | None)\\\\nmin (float | None)\\\\nmax (float | None)\\\\nquantiles (dict[str, float] | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nnullCount int | None\\\\nThe number of distinct values in this column for the rows evaluated\\\\n\\\\n\\\\n\\\\nsum float | None\\\\nThe number of values in this column\\\\n\\\\n\\\\n\\\\nmin float | None\\\\n\\\\n\\\\n\\\\nquantiles\\\\nThe property key is the quantile. Examples\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.dataqualitymetricsinputdataset.DataQualityMetricsInputDatasetFacet(columnMetrics, rowCount=None, bytes=None, fileCount=None, , producer=\'\')\\\\nBases\\\\n\\\\ncolumnMetrics (dict[str, ColumnMetrics])\\\\nrowCount (int | None)\\\\nbytes (int | None)\\\\nfileCount (int | None)\\\\nproducer (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ncolumnMetrics int | None\\\\nThe number of rows evaluated\\\\n\\\\n\\\\n\\\\nbytes int | None\\\\nThe number of files evaluated\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.dataset_version_dataset module\\\\n\\\\n\\\\nclass openlineage.client.generated.dataset_version_dataset.DatasetVersionDatasetFacet(datasetVersion, , producer=\'\', deleted=None)\\\\nBases\\\\n\\\\ndatasetVersion (str)\\\\nproducer (str)\\\\ndeleted (bool | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndatasetVersion DatasetFacet\\\\n\\\\nParameters str | None\\\\n\\\\n\\\\n\\\\nuri\\\\n\\\\nattribute (str)\\\\nvalue (str)\\\\n\\\\n\\\\nReturn type DatasetFacet\\\\n\\\\nParameters str\\\\nThe description of the dataset.\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.documentationjob module\\\\n\\\\n\\\\nclass openlineage.client.generated.documentationjob.DocumentationJobFacet(description, , producer=\'\', deleted=None)\\\\nBases\\\\n\\\\ndescription (str)\\\\nproducer (str)\\\\ndeleted (bool | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ndescription RunFacet\\\\n\\\\nParameters str\\\\nA human-readable string representing error message generated by observed system\\\\n\\\\n\\\\n\\\\nprogrammingLanguage str | None\\\\nA language-specific stack trace generated by observed system\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.externalqueryrun module\\\\n\\\\n\\\\nclass openlineage.client.generated.externalqueryrun.ExternalQueryRunFacet(externalQueryId, source, , producer=\'\')\\\\nBases\\\\n\\\\nexternalQueryId (str)\\\\nsource (str)\\\\nproducer (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nexternalQueryId str\\\\nsource of the external query\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.extraction_error_run module\\\\n\\\\n\\\\nclass openlineage.client.generated.extraction_error_run.Error(errorMessage, stackTrace=None, task=None, taskNumber=None)\\\\nBases\\\\n\\\\nerrorMessage (str)\\\\nstackTrace (str | None)\\\\ntask (str | None)\\\\ntaskNumber (int | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nerrorMessage str | None\\\\nStack trace of extraction error message\\\\n\\\\n\\\\n\\\\ntask int | None\\\\nOrder of task (counted from 0).\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.extraction_error_run.ExtractionErrorRunFacet(totalTasks, failedTasks, errors, , producer=\'\')\\\\nBases\\\\n\\\\ntotalTasks (int)\\\\nfailedTasks (int)\\\\nerrors (list[Error])\\\\nproducer (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ntotalTasks int\\\\nThe number of distinguishable tasks in a run that were processed not successfully by OpenLineage.\\\\nThose could be, for example, distinct SQL statements.\\\\n\\\\n\\\\n\\\\nerrors JobFacet\\\\n\\\\nParameters str\\\\nBATCH or STREAMING\\\\n\\\\nType str\\\\nSPARK|DBT|AIRFLOW|FLINK\\\\n\\\\nType str | None\\\\nQUERY|COMMAND|DAG|TASK|JOB|MODEL\\\\n\\\\nType Enum\\\\nThe lifecycle state change.\\\\n\\\\n\\\\nALTER = \'ALTER\'\\\\n\\\\n\\\\n\\\\nCREATE = \'CREATE\'\\\\n\\\\n\\\\n\\\\nDROP = \'DROP\'\\\\n\\\\n\\\\n\\\\nOVERWRITE = \'OVERWRITE\'\\\\n\\\\n\\\\n\\\\nRENAME = \'RENAME\'\\\\n\\\\n\\\\n\\\\nTRUNCATE = \'TRUNCATE\'\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.lifecycle_state_change_dataset.LifecycleStateChangeDatasetFacet(lifecycleStateChange, previousIdentifier=None, , producer=\'\', deleted=None)\\\\nBases\\\\n\\\\nlifecycleStateChange (LifecycleStateChange)\\\\npreviousIdentifier (PreviousIdentifier | None)\\\\nproducer (str)\\\\ndeleted (bool | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nlifecycleStateChange PreviousIdentifier | None\\\\nPrevious name of the dataset in case of renaming it.\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.lifecyclestatechangedataset.PreviousIdentifier(name, namespace)\\\\nBases\\\\n\\\\nname (str)\\\\nnamespace (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nname str\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.nominaltimerun module\\\\n\\\\n\\\\nclass openlineage.client.generated.nominaltimerun.NominalTimeRunFacet(nominalStartTime, nominalEndTime=None, *, producer=\'\')\\\\nBases\\\\n\\\\nnominalStartTime (str)\\\\nnominalEndTime (str | None)\\\\nproducer (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nnominalStartTime\\\\nAn [ISO-8601 timestamp representing the nominal end time\\\\n(excluded) of the run. (Should be the nominal start time of the next run)\\\\n\\\\nType\\\\n\\\\nattribute (str)\\\\nvalue (str)\\\\n\\\\n\\\\nReturn type\\\\n\\\\nattribute (str)\\\\nvalue (str)\\\\n\\\\n\\\\nReturn type OutputDatasetFacet\\\\n\\\\nParameters int | None\\\\nThe number of rows written to the dataset\\\\n\\\\n\\\\n\\\\nsize int | None\\\\nThe number of files written to the dataset\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.ownershipdataset module\\\\n\\\\n\\\\nclass openlineage.client.generated.ownershipdataset.Owner(name, type=None)\\\\nBases\\\\n\\\\nname (str)\\\\ntype (str | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nnamefoo, userdata\\\\n\\\\n\\\\n\\\\ntype DatasetFacet\\\\n\\\\nParameters list[Owner] | None\\\\nThe owners of the dataset.\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.ownershipjob module\\\\n\\\\n\\\\nclass openlineage.client.generated.ownershipjob.Owner(name, type=None)\\\\nBases\\\\n\\\\nname (str)\\\\ntype (str | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nnamefoo, userdata\\\\n\\\\n\\\\n\\\\ntype JobFacet\\\\n\\\\nParameters list[Owner] | None\\\\nThe owners of the job.\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.parentrun module\\\\n\\\\n\\\\nclass openlineage.client.generated.parentrun.Job(namespace, name)\\\\nBases\\\\n\\\\nnamespace (str)\\\\nname (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nnamespace str\\\\nThe unique name for that job within that namespace\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.parentrun.ParentRunFacet(run, job, , producer=\'\')\\\\nBases\\\\n\\\\nrun (Run)\\\\njob (Job)\\\\nproducer (str)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nrun Job\\\\n\\\\n\\\\n\\\\nclassmethod create(runId, namespace, name)\\\\n\\\\nParameters\\\\nParentRunFacet\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.parent_run.Run(runId)\\\\nBases\\\\nrunId (str)\\\\n\\\\n\\\\n\\\\n\\\\nrunId\\\\n\\\\nattribute (str)\\\\nvalue (str)\\\\n\\\\n\\\\nReturn type RunFacet\\\\n\\\\nParameters str\\\\nProcessing engine version. Might be Airflow or Spark version.\\\\n\\\\n\\\\n\\\\nname str | None\\\\nOpenLineage adapter package version. Might be e.g. OpenLineage Airflow integration package version\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.schemadataset module\\\\n\\\\n\\\\nclass openlineage.client.generated.schemadataset.SchemaDatasetFacet(fields=Nothing.NOTHING, *, producer=\'\', deleted=None)\\\\nBases\\\\n\\\\nfields (list[SchemaDatasetFacetFields] | None)\\\\nproducer (str)\\\\ndeleted (bool | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nfields RedactMixin\\\\n\\\\nParameters str\\\\nThe name of the field.\\\\n\\\\n\\\\n\\\\ntype str | None\\\\nThe description of the field.\\\\n\\\\n\\\\n\\\\nfields JobFacet\\\\n\\\\nParameters str\\\\nLanguage in which source code of this job was written.\\\\n\\\\n\\\\n\\\\nsourceCode JobFacet\\\\n\\\\nParameters str\\\\nthe source control system\\\\n\\\\n\\\\n\\\\nurl str | None\\\\nthe URL to the repository\\\\n\\\\n\\\\n\\\\npath str | None\\\\nthe current version deployed (not a branch name, the actual unique version)\\\\n\\\\n\\\\n\\\\ntag str | None\\\\noptional branch name\\\\n\\\\n\\\\n\\\\nurlcheck(attribute, value)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.generated.sqljob module\\\\n\\\\n\\\\nclass openlineage.client.generated.sqljob.SQLJobFacet(query, , producer=\'\', deleted=None)\\\\nBases\\\\n\\\\nquery (str)\\\\nproducer (str)\\\\ndeleted (bool | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nquery DatasetFacet\\\\n\\\\nParameters str\\\\niceberg, delta.\\\\n\\\\nType str | None\\\\nparquet, orc, avro, json, csv, text, xml.\\\\n\\\\nType RedactMixin\\\\n\\\\nParameters str\\\\nThe dataset namespace\\\\n\\\\n\\\\n\\\\nname str\\\\nIdentifier type\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.generated.symlinksdataset.SymlinksDatasetFacet(identifiers=Nothing.NOTHING, *, producer=\'\', deleted=None)\\\\nBases\\\\n\\\\nidentifiers (list[Identifier] | None)\\\\nproducer (str)\\\\ndeleted (bool | None)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nidentifiers Config\\\\n\\\\n\\\\n\\\\nclass openlineage.client.transport.console.ConsoleTransport(config)\\\\nBases\\\\nconfig (ConsoleConfig)\\\\n\\\\n\\\\n\\\\n\\\\nkind\\\\nevent (Union[RunEvent, DatasetEvent, JobEvent, RunEvent, DatasetEvent, JobEvent])\\\\n\\\\nReturn type TransportFactory\\\\n\\\\n\\\\n\\\\n\\\\nregistertransport(oftype, clazz)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\ncreate(config=None)\\\\n\\\\nParameters\\\\nTransport\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.transport.file module\\\\n\\\\n\\\\nclass openlineage.client.transport.file.FileConfig(logfilepath, append=False)\\\\nBases\\\\n\\\\nlogfilepath (str)\\\\nappend (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nlogfilepath bool = False\\\\n\\\\n\\\\n\\\\nclassmethod fromdict(params)\\\\n\\\\nParameters\\\\nFileConfig\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.transport.file.FileTransport(config)\\\\nBases\\\\nconfig (FileConfig)\\\\n\\\\n\\\\n\\\\n\\\\nkind\\\\nevent (Union[RunEvent, DatasetEvent, JobEvent, RunEvent, DatasetEvent, JobEvent])\\\\n\\\\nReturn type object\\\\n\\\\nParameters\\\\nstr | None\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.transport.http.HttpCompression(value)\\\\nBases TokenProvider\\\\n\\\\nParameters\\\\nstr | None\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.transport.http.createtokenprovider(auth)\\\\n\\\\nParameters\\\\nTokenProvider\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.transport.http.getsession()\\\\n\\\\nReturn type Config\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\nendpoint float\\\\n\\\\n\\\\n\\\\nverify TokenProvider\\\\n\\\\n\\\\n\\\\ncompression Session | None\\\\n\\\\n\\\\n\\\\nadapter\\\\nparams (dict[str, Any])\\\\n\\\\nReturn type\\\\n\\\\nurl (str)\\\\noptions (OpenLineageClientOptions)\\\\nsession (Session | None)\\\\n\\\\n\\\\nReturn type Transport\\\\n\\\\nParameters str | None = \'http\'\\\\n\\\\n\\\\n\\\\nconfigclass\\\\nalias of HttpConfig\\\\n\\\\n\\\\n\\\\nsetadapter(adapter)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nemit(event)\\\\n\\\\nParameters\\\\nResponse\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.transport.kafka module\\\\n\\\\n\\\\nclass openlineage.client.transport.kafka.KafkaConfig(config, topic, messageKey=None, flush=True)\\\\nBases\\\\n\\\\nconfig (dict[str, str])\\\\ntopic (str)\\\\nmessageKey (str | None)\\\\nflush (bool)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nconfig str\\\\n\\\\n\\\\n\\\\nmessageKey bool\\\\n\\\\n\\\\n\\\\nclassmethod fromdict(params)\\\\n\\\\nParameters\\\\nT\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.transport.kafka.ondelivery(err, msg)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nclass openlineage.client.transport.kafka.KafkaTransport(config)\\\\nBases\\\\nconfig (KafkaConfig)\\\\n\\\\n\\\\n\\\\n\\\\nkind\\\\nevent (Event)\\\\n\\\\nReturn type KafkaConfig\\\\n\\\\nParameters str\\\\n\\\\n\\\\n\\\\nawsprofile None | str\\\\n\\\\n\\\\n\\\\nawsdebugcreds KafkaTransport\\\\n\\\\nParameters str | None = \'msk-iam\'\\\\n\\\\n\\\\n\\\\nconfigclass\\\\nalias of MSKIAMConfig\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.transport.noop module\\\\n\\\\n\\\\nclass openlineage.client.transport.noop.NoopConfig\\\\nBases Transport\\\\n\\\\nParameters str | None = \'noop\'\\\\n\\\\n\\\\n\\\\nconfigclass\\\\nalias of NoopConfig\\\\n\\\\n\\\\n\\\\nemit(event)\\\\n\\\\nParameters\\\\nNone\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nopenlineage.client.transport.transport module\\\\nTo implement custom Transport implement Config and Transport classes.\\\\n\\\\nTransport needs to\\\\nspecify class variable config that will point to Config class that Transport requires\\\\ninit that will accept specified Config class instance\\\\nimplement emit method that will accept RunEvent\\\\n\\\\n\\\\n\\\\nConfig file is read and parameters there are passed to fromdict classmethod.\\\\nThe config class can have more complex attributes, but needs to be able to\\\\ninstantiate them in fromdict method.\\\\nDefaultTransportFactory instantiates custom transports by looking at type field in\\\\nclass config.\\\\n\\\\n\\\\nclass openlineage.client.transport.transport.Config\\\\nBases\\\\nparams (dict[str, Any])\\\\n\\\\nReturn type object\\\\n\\\\n\\\\nkind\\\\nevent (Union[RunEvent, DatasetEvent, JobEvent, RunEvent, DatasetEvent, JobEvent])\\\\n\\\\nReturn type object\\\\n\\\\n\\\\ncreate(config=None)\\\\n\\\\nParameters\\\\nTransport\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\"}}>","sidebar":"tutorialSidebar"},"development/developing/python/setup":{"id":"development/developing/python/setup","title":"Setup a development environment","description":"There are four Python OpenLineage packages that you can install locally when setting up a development environment.","sidebar":"tutorialSidebar"},"development/developing/python/tests/airflow":{"id":"development/developing/python/tests/airflow","title":"Airflow","description":"OpenLineage provides an integration with Apache Airflow. As Airflow is actively developed and major changes happen quite often it is advised to test OpenLineage integration against multiple Airflow versions. In the current CI process OpenLineage is tested against following versions:","sidebar":"tutorialSidebar"},"development/developing/python/tests/client":{"id":"development/developing/python/tests/client","title":"Client","description":"This page needs your contribution! Please contribute new examples using the edit link at the bottom.","sidebar":"tutorialSidebar"},"development/developing/python/tests/common":{"id":"development/developing/python/tests/common","title":"Common","description":"This page needs your contribution! Please contribute new examples using the edit link at the bottom.","sidebar":"tutorialSidebar"},"development/developing/python/tests/dagster":{"id":"development/developing/python/tests/dagster","title":"Dagster","description":"This page needs your contribution! Please contribute new examples using the edit link at the bottom.","sidebar":"tutorialSidebar"},"development/developing/python/troubleshooting/logging":{"id":"development/developing/python/troubleshooting/logging","title":"Logging","description":"OpenLineage uses python\'s logging facility when generating logs. Being able to emit logs for various purposes is very helpful when troubleshooting OpenLineage.","sidebar":"tutorialSidebar"},"development/developing/spark/built_in_lineage":{"id":"development/developing/spark/built_in_lineage","title":"Integrating with Spark extensions","description":"Feature available since 1.11.","sidebar":"tutorialSidebar"},"development/developing/spark/setup":{"id":"development/developing/spark/setup","title":"Build","description":"Java 8","sidebar":"tutorialSidebar"},"development/examples":{"id":"development/examples","title":"Example Lineage Events","description":"Simple Examples","sidebar":"tutorialSidebar"},"development/ol-proxy":{"id":"development/ol-proxy","title":"OpenLineage Proxy","description":"OpenLineage Proxy is a simple Java server that can be used to monitor the JSON events that OpenLineage client emits, as well as tunnel the transmission to the OpenLineage backend such as Marquez.","sidebar":"tutorialSidebar"},"faq":{"id":"faq","title":"Frequently Asked Questions","description":"This page needs your contribution! Please contribute new questions (or answers) using the edit link at the bottom.","sidebar":"tutorialSidebar"},"guides/about":{"id":"guides/about","title":"About These Guides","description":"The following tutorials take you through the process of exploiting the lineage metadata provided by Marquez and OpenLineage to solve common data engineering problems and make new analytical and historical insights into your pipelines.","sidebar":"tutorialSidebar"},"guides/airflow_proxy":{"id":"guides/airflow_proxy","title":"Using the OpenLineage Proxy with Airflow","description":"This tutorial introduces you to using the OpenLineage Proxy with Airflow. OpenLineage has various integrations that will enable Airflow to emit OpenLineage events when using Airflow Integrations. In this tutorial, you will be running a local instance of Airflow using Docker Compose and learning how to enable and setup OpenLineage to emit data lineage events. The tutorial will use two backends to check the data lineage, 1) the Proxy, and 2) Marquez.","sidebar":"tutorialSidebar"},"guides/airflow-backfill-dags":{"id":"guides/airflow-backfill-dags","title":"Backfilling Airflow DAGs Using Marquez","description":"Adapted from a blog post by Willy Lulciuc","sidebar":"tutorialSidebar"},"guides/airflow-quickstart":{"id":"guides/airflow-quickstart","title":"Getting Started with Airflow and OpenLineage+Marquez","description":"In this example, we\'ll walk you through how to enable Airflow DAGs to send lineage metadata to Marquez using OpenLineage.","sidebar":"tutorialSidebar"},"guides/dbt":{"id":"guides/dbt","title":"Using Marquez with dbt","description":"Adapted from a blog post by Ross Turk","sidebar":"tutorialSidebar"},"guides/facets":{"id":"guides/facets","title":"Understanding and Using Facets","description":"Adapted from the OpenLineage spec.","sidebar":"tutorialSidebar"},"guides/spark":{"id":"guides/spark","title":"Using OpenLineage with Spark","description":"Adapted from a blog post by Michael Collado","sidebar":"tutorialSidebar"},"index":{"id":"index","title":"About OpenLineage","description":"OpenLineage is an open framework for data lineage collection and analysis. At its core is an extensible specification that systems can use to interoperate with lineage metadata.","sidebar":"tutorialSidebar"},"integrations/about":{"id":"integrations/about","title":"OpenLineage Integrations","description":"Capability Matrix","sidebar":"tutorialSidebar"},"integrations/airflow/airflow":{"id":"integrations/airflow/airflow","title":"Apache Airflow","description":"This page is about Airflow\'s external integration that works mainly for Airflow versions <2.7.","sidebar":"tutorialSidebar"},"integrations/airflow/default-extractors":{"id":"integrations/airflow/default-extractors","title":"Exposing Lineage in Airflow Operators","description":"This page is about Airflow\'s external integration that works mainly for Airflow versions <2.7.","sidebar":"tutorialSidebar"},"integrations/airflow/extractors/custom-extractors":{"id":"integrations/airflow/extractors/custom-extractors","title":"Custom Extractors","description":"This page is about Airflow\'s external integration that works mainly for Airflow versions <2.7.","sidebar":"tutorialSidebar"},"integrations/airflow/extractors/extractor-testing":{"id":"integrations/airflow/extractors/extractor-testing","title":"Testing Custom Extractors","description":"This page is about Airflow\'s external integration that works mainly for Airflow versions <2.7.","sidebar":"tutorialSidebar"},"integrations/airflow/job-hierarchy":{"id":"integrations/airflow/job-hierarchy","title":"Job Hierarchy","description":"This page is about Airflow\'s external integration that works mainly for Airflow versions <2.7.","sidebar":"tutorialSidebar"},"integrations/airflow/manual":{"id":"integrations/airflow/manual","title":"Manually Annotated Lineage","description":"This page is about Airflow\'s external integration that works mainly for Airflow versions <2.7.","sidebar":"tutorialSidebar"},"integrations/airflow/older":{"id":"integrations/airflow/older","title":"Supported Airflow versions","description":"This page is about Airflow\'s external integration that works mainly for Airflow versions <2.7.","sidebar":"tutorialSidebar"},"integrations/airflow/preflight-check-dag":{"id":"integrations/airflow/preflight-check-dag","title":"Preflight check DAG","description":"Purpose","sidebar":"tutorialSidebar"},"integrations/airflow/usage":{"id":"integrations/airflow/usage","title":"Using the Airflow Integration","description":"This page is about Airflow\'s external integration that works mainly for Airflow versions <2.7.","sidebar":"tutorialSidebar"},"integrations/dbt":{"id":"integrations/dbt","title":"dbt","description":"dbt (data build tool) is a powerful transformation engine. It operates on data already within a warehouse, making it easy for data engineers to build complex pipelines from the comfort of their laptops. While it doesn\u2019t perform extraction and loading of data, it\u2019s extremely powerful at transformations.","sidebar":"tutorialSidebar"},"integrations/flink":{"id":"integrations/flink","title":"Apache Flink","description":"Apache Flink is one of the most popular stream processing frameworks. Apache Flink jobs run on clusters,","sidebar":"tutorialSidebar"},"integrations/great-expectations":{"id":"integrations/great-expectations","title":"Great Expectations","description":"Great Expectations is a robust data quality tool. It runs suites of checks, called expectations, over a defined dataset. This dataset can be a table in a database, or a Spark or Pandas dataframe. Expectations are run by checkpoints, which are configuration files that describe not just the expectations to use, but also any batching, runtime configurations, and, importantly, the action list of actions run after the expectation suite completes.","sidebar":"tutorialSidebar"},"integrations/spark/configuration/airflow":{"id":"integrations/spark/configuration/airflow","title":"Scheduling from Airflow","description":"The same parameters passed to spark-submit can be supplied from Airflow and other schedulers. If","sidebar":"tutorialSidebar"},"integrations/spark/configuration/circuit_breaker":{"id":"integrations/spark/configuration/circuit_breaker","title":"Circuit Breaker","description":"","sidebar":"tutorialSidebar"},"integrations/spark/configuration/spark_conf":{"id":"integrations/spark/configuration/spark_conf","title":"Spark Config Parameters","description":"The following parameters can be specified:","sidebar":"tutorialSidebar"},"integrations/spark/configuration/transport":{"id":"integrations/spark/configuration/transport","title":"Transport","description":"","sidebar":"tutorialSidebar"},"integrations/spark/configuration/usage":{"id":"integrations/spark/configuration/usage","title":"Usage","description":"Configuring the OpenLineage Spark integration is straightforward. It uses built-in Spark configuration mechanisms.","sidebar":"tutorialSidebar"},"integrations/spark/extending":{"id":"integrations/spark/extending","title":"Extending","description":"The Spark library is intended to support extension via custom implementations of a handful","sidebar":"tutorialSidebar"},"integrations/spark/installation":{"id":"integrations/spark/installation","title":"Installation","description":"* Version 1.8.0 and earlier only supported Scala 2.12 variants of Apache Spark.","sidebar":"tutorialSidebar"},"integrations/spark/job-hierarchy":{"id":"integrations/spark/job-hierarchy","title":"Job Hierarchy","description":"Please get familiar with OpenLineage Job Hierarchy concept before reading this.","sidebar":"tutorialSidebar"},"integrations/spark/main_concept":{"id":"integrations/spark/main_concept","title":"Main Concepts","description":"Spark jobs typically run on clusters of machines. A single machine hosts the \\"driver\\" application,","sidebar":"tutorialSidebar"},"integrations/spark/metrics":{"id":"integrations/spark/metrics","title":"Spark Integration Metrics","description":"The OpenLineage integration with Spark not only utilizes the Java client\'s metrics but also introduces its own set of metrics specific to Spark operations. Below is a list of these metrics.","sidebar":"tutorialSidebar"},"integrations/spark/quickstart/quickstart_databricks":{"id":"integrations/spark/quickstart/quickstart_databricks","title":"Quickstart with Databricks","description":"OpenLineage\'s Spark Integration can be installed on Databricks leveraging init scripts. Please note, Databricks on Google Cloud does not currently support the DBFS CLI, so the proposed solution will not work on Google Cloud until that feature is enabled.","sidebar":"tutorialSidebar"},"integrations/spark/quickstart/quickstart_local":{"id":"integrations/spark/quickstart/quickstart_local","title":"Quickstart with Jupyter","description":"Trying out the Spark integration is super easy if you already have Docker Desktop and git installed.","sidebar":"tutorialSidebar"},"integrations/spark/spark":{"id":"integrations/spark/spark","title":"Apache Spark","description":"This integration is known to work with latest Spark versions as well as Apache Spark 2.4.","sidebar":"tutorialSidebar"},"integrations/spark/spark_column_lineage":{"id":"integrations/spark/spark_column_lineage","title":"Column-Level Lineage","description":"Column-level lineage works only with Spark 3.","sidebar":"tutorialSidebar"},"releases/0_1_0":{"id":"releases/0_1_0","title":"0.1.0","description":"OpenLineage is an Open Standard for lineage metadata collection designed to record metadata for a job in execution. The initial public release includes:","sidebar":"tutorialSidebar"},"releases/0_10_0":{"id":"releases/0_10_0","title":"0.10.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_11_0":{"id":"releases/0_11_0","title":"0.11.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_12_0":{"id":"releases/0_12_0","title":"0.12.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_13_0":{"id":"releases/0_13_0","title":"0.13.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_13_1":{"id":"releases/0_13_1","title":"0.13.1","description":"Fixed","sidebar":"tutorialSidebar"},"releases/0_14_0":{"id":"releases/0_14_0","title":"0.14.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_14_1":{"id":"releases/0_14_1","title":"0.14.1","description":"Fixed","sidebar":"tutorialSidebar"},"releases/0_15_1":{"id":"releases/0_15_1","title":"0.15.1","description":"Added","sidebar":"tutorialSidebar"},"releases/0_16_1":{"id":"releases/0_16_1","title":"0.16.1","description":"Added","sidebar":"tutorialSidebar"},"releases/0_17_0":{"id":"releases/0_17_0","title":"0.17.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_18_0":{"id":"releases/0_18_0","title":"0.18.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_19_2":{"id":"releases/0_19_2","title":"0.19.2","description":"Added","sidebar":"tutorialSidebar"},"releases/0_2_0":{"id":"releases/0_2_0","title":"0.2.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_2_1":{"id":"releases/0_2_1","title":"0.2.1","description":"Fixed","sidebar":"tutorialSidebar"},"releases/0_2_2":{"id":"releases/0_2_2","title":"0.2.2","description":"Added","sidebar":"tutorialSidebar"},"releases/0_2_3":{"id":"releases/0_2_3","title":"0.2.3","description":"Fixed","sidebar":"tutorialSidebar"},"releases/0_20_4":{"id":"releases/0_20_4","title":"0.20.4","description":"Added","sidebar":"tutorialSidebar"},"releases/0_20_6":{"id":"releases/0_20_6","title":"0.20.6","description":"Added","sidebar":"tutorialSidebar"},"releases/0_21_1":{"id":"releases/0_21_1","title":"0.21.1","description":"Added","sidebar":"tutorialSidebar"},"releases/0_22_0":{"id":"releases/0_22_0","title":"0.22.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_23_0":{"id":"releases/0_23_0","title":"0.23.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_24_0":{"id":"releases/0_24_0","title":"0.24.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_25_0":{"id":"releases/0_25_0","title":"0.25.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_26_0":{"id":"releases/0_26_0","title":"0.26.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_27_1":{"id":"releases/0_27_1","title":"0.27.1","description":"Added","sidebar":"tutorialSidebar"},"releases/0_27_2":{"id":"releases/0_27_2","title":"0.27.2","description":"Fixed","sidebar":"tutorialSidebar"},"releases/0_28_0":{"id":"releases/0_28_0","title":"0.28.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_29_2":{"id":"releases/0_29_2","title":"0.29.2","description":"Added","sidebar":"tutorialSidebar"},"releases/0_3_0":{"id":"releases/0_3_0","title":"0.3.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_3_1":{"id":"releases/0_3_1","title":"0.3.1","description":"Fixed","sidebar":"tutorialSidebar"},"releases/0_30_1":{"id":"releases/0_30_1","title":"0.30.1","description":"Added","sidebar":"tutorialSidebar"},"releases/0_4_0":{"id":"releases/0_4_0","title":"0.4.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_5_1":{"id":"releases/0_5_1","title":"0.5.1","description":"Added","sidebar":"tutorialSidebar"},"releases/0_5_2":{"id":"releases/0_5_2","title":"0.5.2","description":"Added","sidebar":"tutorialSidebar"},"releases/0_6_0":{"id":"releases/0_6_0","title":"0.6.0","description":"Added","sidebar":"tutorialSidebar"},"releases/0_6_1":{"id":"releases/0_6_1","title":"0.6.1","description":"Fixed","sidebar":"tutorialSidebar"},"releases/0_6_2":{"id":"releases/0_6_2","title":"0.6.2","description":"Added","sidebar":"tutorialSidebar"},"releases/0_7_1":{"id":"releases/0_7_1","title":"0.7.1","description":"Added","sidebar":"tutorialSidebar"},"releases/0_8_1":{"id":"releases/0_8_1","title":"0.8.1","description":"Added","sidebar":"tutorialSidebar"},"releases/0_8_2":{"id":"releases/0_8_2","title":"0.8.2","description":"Added","sidebar":"tutorialSidebar"},"releases/0_9_0":{"id":"releases/0_9_0","title":"0.9.0","description":"Added","sidebar":"tutorialSidebar"},"releases/1_0_0":{"id":"releases/1_0_0","title":"1.0.0","description":"Added","sidebar":"tutorialSidebar"},"releases/1_1_0":{"id":"releases/1_1_0","title":"1.1.0","description":"Added","sidebar":"tutorialSidebar"},"releases/1_10_2":{"id":"releases/1_10_2","title":"1.10.2","description":"Added","sidebar":"tutorialSidebar"},"releases/1_11_3":{"id":"releases/1_11_3","title":"1.11.3","description":"Added","sidebar":"tutorialSidebar"},"releases/1_12_0":{"id":"releases/1_12_0","title":"1.12.0","description":"Added","sidebar":"tutorialSidebar"},"releases/1_2_2":{"id":"releases/1_2_2","title":"1.2.2","description":"Added","sidebar":"tutorialSidebar"},"releases/1_3_1":{"id":"releases/1_3_1","title":"1.3.1","description":"Added","sidebar":"tutorialSidebar"},"releases/1_4_1":{"id":"releases/1_4_1","title":"1.4.1","description":"Added","sidebar":"tutorialSidebar"},"releases/1_5_0":{"id":"releases/1_5_0","title":"1.5.0","description":"Added","sidebar":"tutorialSidebar"},"releases/1_6_2":{"id":"releases/1_6_2","title":"1.6.2","description":"Added","sidebar":"tutorialSidebar"},"releases/1_7_0":{"id":"releases/1_7_0","title":"1.7.0","description":"COMPATIBILITY NOTICE","sidebar":"tutorialSidebar"},"releases/1_8_0":{"id":"releases/1_8_0","title":"1.8.0","description":"Added","sidebar":"tutorialSidebar"},"releases/1_9_1":{"id":"releases/1_9_1","title":"1.9.1","description":"This version adds the capability to publish Scala 2.12 and 2.13 variants of Apache Spark,","sidebar":"tutorialSidebar"},"spec/facets/custom-facets":{"id":"spec/facets/custom-facets","title":"Custom Facets","description":"In addition to the existing facets mentioned in this documentation, users can extend the base facets and provide their own facet definition as part of the payload in OpenLineage event. For example, when OpenLineage event is emitted from the Apache Airflow using OpenLineage\'s Airflow integration, the following facets can be observed:","sidebar":"tutorialSidebar"},"spec/facets/dataset-facets/column_lineage_facet":{"id":"spec/facets/dataset-facets/column_lineage_facet","title":"Column Level Lineage Dataset Facet","description":"Column level lineage provides fine grained information on datasets\' dependencies. Not only we know the dependency exist, but we are also able to understand which input columns are used to produce output columns. This allows answering questions like Which root input columns are used to construct column x?","sidebar":"tutorialSidebar"},"spec/facets/dataset-facets/data_quality_assertions":{"id":"spec/facets/dataset-facets/data_quality_assertions","title":"Data Quality Assertions Facet","description":"Example:","sidebar":"tutorialSidebar"},"spec/facets/dataset-facets/data_source":{"id":"spec/facets/dataset-facets/data_source","title":"Datasource Facet","description":"Example:","sidebar":"tutorialSidebar"},"spec/facets/dataset-facets/dataset-facets":{"id":"spec/facets/dataset-facets/dataset-facets","title":"Dataset Facets","description":"Dataset Facets are generally consisted of common facet that is used both in inputs and outputs of the OpenLineage event. There are facets that exist specifically for input or output datasets.","sidebar":"tutorialSidebar"},"spec/facets/dataset-facets/input-dataset-facets/data_quality_metrics":{"id":"spec/facets/dataset-facets/input-dataset-facets/data_quality_metrics","title":"Data Quality Metrics Facet","description":"Example:","sidebar":"tutorialSidebar"},"spec/facets/dataset-facets/lifecycle_state_change":{"id":"spec/facets/dataset-facets/lifecycle_state_change","title":"Lifecycle State Change Facet","description":"Example:","sidebar":"tutorialSidebar"},"spec/facets/dataset-facets/output-dataset-facets/output_statistics":{"id":"spec/facets/dataset-facets/output-dataset-facets/output_statistics","title":"Output Statistics Facet","description":"Example:","sidebar":"tutorialSidebar"},"spec/facets/dataset-facets/ownership":{"id":"spec/facets/dataset-facets/ownership","title":"Ownership Dataset Facet","description":"Example:","sidebar":"tutorialSidebar"},"spec/facets/dataset-facets/schema":{"id":"spec/facets/dataset-facets/schema","title":"Schema Dataset Facet","description":"The schema dataset facet contains the schema of a particular dataset.","sidebar":"tutorialSidebar"},"spec/facets/dataset-facets/storage":{"id":"spec/facets/dataset-facets/storage","title":"Storage Facet","description":"Example:","sidebar":"tutorialSidebar"},"spec/facets/dataset-facets/symlinks":{"id":"spec/facets/dataset-facets/symlinks","title":"Symlinks Facet","description":"Example:","sidebar":"tutorialSidebar"},"spec/facets/dataset-facets/version_facet":{"id":"spec/facets/dataset-facets/version_facet","title":"Version Facet","description":"Example:","sidebar":"tutorialSidebar"},"spec/facets/facets":{"id":"spec/facets/facets","title":"Facets & Extensibility","description":"Facets provide context to the OpenLineage events. Generally, an OpenLineage event contains the type of the event, who created it, and when the event happened. In addition to the basic information related to the event, it provides facets for more details in four general categories:","sidebar":"tutorialSidebar"},"spec/facets/job-facets/documentation":{"id":"spec/facets/job-facets/documentation","title":"Documentation Facet","description":"Contains the documentation or description of the job.","sidebar":"tutorialSidebar"},"spec/facets/job-facets/job-facets":{"id":"spec/facets/job-facets/job-facets","title":"Job Facets","description":"Job Facets apply to a distinct instance of a job: an abstract process that consumes, executes, and produces datasets (defined as its inputs and outputs). It is identified by a unique name within a namespace. The Job evolves over time and this change is captured during the job runs.","sidebar":"tutorialSidebar"},"spec/facets/job-facets/job-type":{"id":"spec/facets/job-facets/job-type","title":"Job type Job Facet","description":"Facet to contain job properties like:","sidebar":"tutorialSidebar"},"spec/facets/job-facets/ownership":{"id":"spec/facets/job-facets/ownership","title":"Ownership Job Facet","description":"The facet that contains the information regarding users or group who owns this particular job.","sidebar":"tutorialSidebar"},"spec/facets/job-facets/source-code":{"id":"spec/facets/job-facets/source-code","title":"Source Code Facet","description":"The source code of a particular job (e.g. Python script)","sidebar":"tutorialSidebar"},"spec/facets/job-facets/source-code-location":{"id":"spec/facets/job-facets/source-code-location","title":"Source Code Location Facet","description":"The facet that indicates where the source code is located.","sidebar":"tutorialSidebar"},"spec/facets/job-facets/sql":{"id":"spec/facets/job-facets/sql","title":"SQL Job Facet","description":"The SQL Job Facet contains a SQL query that was used in a particular job.","sidebar":"tutorialSidebar"},"spec/facets/run-facets/error_message":{"id":"spec/facets/run-facets/error_message","title":"Error Message Facet","description":"The facet to contain information about the failures during the run of the job. A typical payload would be the message, stack trace, etc.","sidebar":"tutorialSidebar"},"spec/facets/run-facets/external_query":{"id":"spec/facets/run-facets/external_query","title":"External Query Facet","description":"The facet that describes the identification of the query that the run is related to which was executed by external systems. Even though the query itself is not contained, using this facet, the user should be able to access the query and its details.","sidebar":"tutorialSidebar"},"spec/facets/run-facets/nominal_time":{"id":"spec/facets/run-facets/nominal_time","title":"Nominal Time Facet","description":"The facet to describe the nominal start and end time of the run. The nominal usually means the time the job run was expected to run (like a scheduled time), and the actual time can be different.","sidebar":"tutorialSidebar"},"spec/facets/run-facets/parent_run":{"id":"spec/facets/run-facets/parent_run","title":"Parent Run Facet","description":"Commonly, scheduler systems like Apache Airflow will trigger processes on remote systems, such as on Apache Spark or Apache Beam jobs.","sidebar":"tutorialSidebar"},"spec/facets/run-facets/run-facets":{"id":"spec/facets/run-facets/run-facets","title":"Run Facets","description":"Run Facets apply to a specific instance of a particular running job. Every run will have a uniquely identifiable run ID that is usually in UUID format, that can later be tracked.","sidebar":"tutorialSidebar"},"spec/job-hierarchy":{"id":"spec/job-hierarchy","title":"Job Hierarchy","description":"This feature is available in OpenLineage versions >= 1.9.0.","sidebar":"tutorialSidebar"},"spec/naming":{"id":"spec/naming","title":"Naming Conventions","description":"Employing a unique naming strategy per resource ensures that the spec is followed uniformly regardless of metadata producer.","sidebar":"tutorialSidebar"},"spec/object-model":{"id":"spec/object-model","title":"Object Model","description":"OpenLineage was designed to enable large-scale observation of datasets as they move through a complex pipeline.","sidebar":"tutorialSidebar"},"spec/producers":{"id":"spec/producers","title":"Producers","description":"This page could use some extra detail! You\'re welcome to contribute using the Edit link at the bottom.","sidebar":"tutorialSidebar"},"spec/run-cycle":{"id":"spec/run-cycle","title":"The Run Cycle","description":"The OpenLineage object model is event-based and updates provide an OpenLineage backend with details about the activities of a Job.","sidebar":"tutorialSidebar"},"spec/schemas":{"id":"spec/schemas","title":"Working with Schemas","description":"OpenLineage is a rapidly growing open source project, and therefore, will face many new changes in its SPEC. The spec file is based on JSON schema specification and defines how the OpenLineage\'s event message would be structured. More details on what are defined in its object model can be found here.","sidebar":"tutorialSidebar"}}}')}}]);