"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1924],{3905:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>f});var a=t(67294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var p=a.createContext({}),l=function(e){var n=a.useContext(p),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},c=function(e){var n=l(e.components);return a.createElement(p.Provider,{value:n},e.children)},u={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},d=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,o=e.originalType,p=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),d=l(t),f=r,m=d["".concat(p,".").concat(f)]||d[f]||u[f]||o;return t?a.createElement(m,i(i({ref:n},c),{},{components:t})):a.createElement(m,i({ref:n},c))}));function f(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=t.length,i=new Array(o);i[0]=d;var s={};for(var p in n)hasOwnProperty.call(n,p)&&(s[p]=n[p]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var l=2;l<o;l++)i[l]=t[l];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}d.displayName="MDXCreateElement"},85162:(e,n,t)=>{t.d(n,{Z:()=>i});var a=t(67294),r=t(86010);const o="tabItem_Ymn6";function i(e){let{children:n,hidden:t,className:i}=e;return a.createElement("div",{role:"tabpanel",className:(0,r.Z)(o,i),hidden:t},n)}},74866:(e,n,t)=>{t.d(n,{Z:()=>N});var a=t(87462),r=t(67294),o=t(86010),i=t(76775),s=t(91980),p=t(67392),l=t(50012);function c(e){return function(e){return r.Children.map(e,(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:n,label:t,attributes:a,default:r}}=e;return{value:n,label:t,attributes:a,default:r}}))}function u(e){const{values:n,children:t}=e;return(0,r.useMemo)((()=>{const e=n??c(t);return function(e){const n=(0,p.l)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function d(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function f(e){let{queryString:n=!1,groupId:t}=e;const a=(0,i.k6)(),o=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,s._X)(o),(0,r.useCallback)((e=>{if(!o)return;const n=new URLSearchParams(a.location.search);n.set(o,e),a.replace({...a.location,search:n.toString()})}),[o,a])]}function m(e){const{defaultValue:n,queryString:t=!1,groupId:a}=e,o=u(e),[i,s]=(0,r.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!d({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const a=t.find((e=>e.default))??t[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:n,tabValues:o}))),[p,c]=f({queryString:t,groupId:a}),[m,g]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[a,o]=(0,l.Nk)(t);return[a,(0,r.useCallback)((e=>{t&&o.set(e)}),[t,o])]}({groupId:a}),k=(()=>{const e=p??m;return d({value:e,tabValues:o})?e:null})();(0,r.useLayoutEffect)((()=>{k&&s(k)}),[k]);return{selectedValue:i,selectValue:(0,r.useCallback)((e=>{if(!d({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);s(e),c(e),g(e)}),[c,g,o]),tabValues:o}}var g=t(12466),k=t(72389);const h="tabList__CuJ",b="tabItem_LNqP";function y(e){let{className:n,block:t,selectedValue:i,selectValue:s,tabValues:p}=e;const l=[],{blockElementScrollPositionUntilNextRender:c}=(0,g.o5)(),u=e=>{const n=e.currentTarget,t=l.indexOf(n),a=p[t].value;a!==i&&(c(n),s(a))},d=e=>{let n=null;switch(e.key){case"Enter":u(e);break;case"ArrowRight":{const t=l.indexOf(e.currentTarget)+1;n=l[t]??l[0];break}case"ArrowLeft":{const t=l.indexOf(e.currentTarget)-1;n=l[t]??l[l.length-1];break}}n?.focus()};return r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.Z)("tabs",{"tabs--block":t},n)},p.map((e=>{let{value:n,label:t,attributes:s}=e;return r.createElement("li",(0,a.Z)({role:"tab",tabIndex:i===n?0:-1,"aria-selected":i===n,key:n,ref:e=>l.push(e),onKeyDown:d,onClick:u},s,{className:(0,o.Z)("tabs__item",b,s?.className,{"tabs__item--active":i===n})}),t??n)})))}function v(e){let{lazy:n,children:t,selectedValue:a}=e;const o=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=o.find((e=>e.props.value===a));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return r.createElement("div",{className:"margin-top--md"},o.map(((e,n)=>(0,r.cloneElement)(e,{key:n,hidden:e.props.value!==a}))))}function x(e){const n=m(e);return r.createElement("div",{className:(0,o.Z)("tabs-container",h)},r.createElement(y,(0,a.Z)({},e,n)),r.createElement(v,(0,a.Z)({},e,n)))}function N(e){const n=(0,k.Z)();return r.createElement(x,(0,a.Z)({key:String(n)},e))}},39816:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>p,default:()=>f,frontMatter:()=>s,metadata:()=>l,toc:()=>u});var a=t(87462),r=(t(67294),t(3905)),o=t(74866),i=t(85162);const s={sidebar_position:1,title:"Usage"},p=void 0,l={unversionedId:"integrations/spark/configuration/usage",id:"integrations/spark/configuration/usage",title:"Usage",description:"Configuring the OpenLineage Spark integration is straightforward. It uses built-in Spark configuration mechanisms.",source:"@site/docs/integrations/spark/configuration/usage.md",sourceDirName:"integrations/spark/configuration",slug:"/integrations/spark/configuration/usage",permalink:"/docs/integrations/spark/configuration/usage",draft:!1,editUrl:"https://github.com/OpenLineage/docs/tree/main/docs/integrations/spark/configuration/usage.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1,title:"Usage"},sidebar:"tutorialSidebar",previous:{title:"Main Concepts",permalink:"/docs/integrations/spark/main_concept"},next:{title:"Spark Config Parameters",permalink:"/docs/integrations/spark/configuration/spark_conf"}},c={},u=[{value:"Setting the properties directly in your application",id:"setting-the-properties-directly-in-your-application",level:4},{value:"Using <code>--conf</code> options with the CLI",id:"using---conf-options-with-the-cli",level:4},{value:"Adding properties to the <code>spark-defaults.conf</code> file in the <code>${SPARK_HOME}/conf</code> directory",id:"adding-properties-to-the-spark-defaultsconf-file-in-the-spark_homeconf-directory",level:4}],d={toc:u};function f(e){let{components:n,...t}=e;return(0,r.kt)("wrapper",(0,a.Z)({},d,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"Configuring the OpenLineage Spark integration is straightforward. It uses built-in Spark configuration mechanisms."),(0,r.kt)("p",null,"Your options are:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"#setting-the-properties-directly-in-your-application"},"Setting the properties directly in your application"),"."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"#using---conf-options-with-the-cli"},"Using ",(0,r.kt)("inlineCode",{parentName:"a"},"--conf")," options with the CLI"),"."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"#adding-properties-to-the-spark-defaultsconf-file-in-the-spark_homeconf-directory"},"Adding properties to the ",(0,r.kt)("inlineCode",{parentName:"a"},"spark-defaults.conf")," file in the ",(0,r.kt)("inlineCode",{parentName:"a"},"${SPARK_HOME}/conf")," directory"),".")),(0,r.kt)("h4",{id:"setting-the-properties-directly-in-your-application"},"Setting the properties directly in your application"),(0,r.kt)("p",null,"The below example demonstrates how to set the properties directly in your application when\nconstructing\na ",(0,r.kt)("inlineCode",{parentName:"p"},"SparkSession"),"."),(0,r.kt)("admonition",{type:"warning"},(0,r.kt)("p",{parentName:"admonition"},"The setting ",(0,r.kt)("inlineCode",{parentName:"p"},'config("spark.extraListeners", "io.openlineage.spark.agent.OpenLineageSparkListener")')," is\n",(0,r.kt)("strong",{parentName:"p"},"extremely important"),". Without it, the OpenLineage Spark integration will not be invoked, rendering\nthe integration ineffective.")),(0,r.kt)(o.Z,{groupId:"spark-app-conf",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import org.apache.spark.sql.SparkSession\n\nobject OpenLineageExample extends App {\n  val spark = SparkSession.builder()\n    .appName("OpenLineageExample")\n    // This line is EXTREMELY important\n    .config("spark.extraListeners", "io.openlineage.spark.agent.OpenLineageSparkListener")\n    .config("spark.openlineage.transport.type", "http")\n    .config("spark.openlineage.transport.url", "http://localhost:5000")\n    .config("spark.openlineage.namespace", "spark_namespace")\n    .config("spark.openlineage.parentJobNamespace", "airflow_namespace")\n    .config("spark.openlineage.parentJobName", "airflow_dag.airflow_task")\n    .config("spark.openlineage.parentRunId", "xxxx-xxxx-xxxx-xxxx")\n    .getOrCreate()\n\n  // ... your code\n\n  spark.stop()\n}\n'))),(0,r.kt)(i.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from pyspark.sql import SparkSession\n\nspark = SparkSession.builder\n    .appName("OpenLineageExample")\n    .config("spark.extraListeners", "io.openlineage.spark.agent.OpenLineageSparkListener")\n    .config("spark.openlineage.transport.type", "http")\n    .config("spark.openlineage.transport.url", "http://localhost:5000")\n    .config("spark.openlineage.namespace", "spark_namespace")\n    .config("spark.openlineage.parentJobNamespace", "airflow_namespace")\n    .config("spark.openlineage.parentJobName", "airflow_dag.airflow_task")\n    .config("spark.openlineage.parentRunId", "xxxx-xxxx-xxxx-xxxx")\n    .getOrCreate()\n\n# ... your code\n\nspark.stop()\n')))),(0,r.kt)("h4",{id:"using---conf-options-with-the-cli"},"Using ",(0,r.kt)("inlineCode",{parentName:"h4"},"--conf")," options with the CLI"),(0,r.kt)("p",null,"The below example demonstrates how to use the ",(0,r.kt)("inlineCode",{parentName:"p"},"--conf")," option with ",(0,r.kt)("inlineCode",{parentName:"p"},"spark-submit"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'spark-submit \\\n  --conf "spark.extraListeners=io.openlineage.spark.agent.OpenLineageSparkListener" \\\n  --conf "spark.openlineage.transport.type=http" \\\n  --conf "spark.openlineage.transport.url=http://localhost:5000" \\\n  --conf "spark.openlineage.namespace=spark_namespace" \\\n  --conf "spark.openlineage.parentJobNamespace=airflow_namespace" \\\n  --conf "spark.openlineage.parentJobName=airflow_dag.airflow_task" \\\n  --conf "spark.openlineage.parentRunId=xxxx-xxxx-xxxx-xxxx" \\\n  # ... other options\n')),(0,r.kt)("h4",{id:"adding-properties-to-the-spark-defaultsconf-file-in-the-spark_homeconf-directory"},"Adding properties to the ",(0,r.kt)("inlineCode",{parentName:"h4"},"spark-defaults.conf")," file in the ",(0,r.kt)("inlineCode",{parentName:"h4"},"${SPARK_HOME}/conf")," directory"),(0,r.kt)("admonition",{type:"warning"},(0,r.kt)("p",{parentName:"admonition"},"You may need to create this file if it does not exist. If it does exist, ",(0,r.kt)("strong",{parentName:"p"},"we strongly suggest that\nyou back it up before making any changes"),", particularly if you are not the only user of the Spark\ninstallation. A misconfiguration here can have devastating effects on the operation of your Spark\ninstallation, particularly in a shared environment.")),(0,r.kt)("p",null,"The below example demonstrates how to add properties to the ",(0,r.kt)("inlineCode",{parentName:"p"},"spark-defaults.conf")," file."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-properties"},"spark.extraListeners=io.openlineage.spark.agent.OpenLineageSparkListener\nspark.openlineage.transport.type=http\nspark.openlineage.transport.url=http://localhost:5000\nspark.openlineage.namespace=MyNamespace\n")),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"The ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.extraListeners")," configuration parameter is ",(0,r.kt)("strong",{parentName:"p"},"non-additive"),". This means that if you set\n",(0,r.kt)("inlineCode",{parentName:"p"},"spark.extraListeners")," via the CLI or via ",(0,r.kt)("inlineCode",{parentName:"p"},"SparkSession#config"),", it will ",(0,r.kt)("strong",{parentName:"p"},"replace")," the value\nin ",(0,r.kt)("inlineCode",{parentName:"p"},"spark-defaults.conf"),". This is important to remember if you are using ",(0,r.kt)("inlineCode",{parentName:"p"},"spark-defaults.conf")," to\nset a default value for ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.extraListeners")," and then want to override it for a specific job.")),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"When it comes to configuration parameters like ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.openlineage.namespace"),", a default value can\nbe supplied in the ",(0,r.kt)("inlineCode",{parentName:"p"},"spark-defaults.conf")," file. This default value can be overridden by the\napplication at runtime, via the previously detailed methods. However, it is ",(0,r.kt)("strong",{parentName:"p"},"strongly")," recommended\nthat more dynamic or quickly changing parameters like ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.openlineage.parentRunId")," or\n",(0,r.kt)("inlineCode",{parentName:"p"},"spark.openlineage.parentJobName")," be set at runtime via the CLI or ",(0,r.kt)("inlineCode",{parentName:"p"},"SparkSession#config")," methods.")))}f.isMDXComponent=!0}}]);