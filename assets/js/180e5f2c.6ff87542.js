"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5265],{3905:(e,n,r)=>{r.d(n,{Zo:()=>l,kt:()=>d});var t=r(67294);function a(e,n,r){return n in e?Object.defineProperty(e,n,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[n]=r,e}function o(e,n){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),r.push.apply(r,t)}return r}function i(e){for(var n=1;n<arguments.length;n++){var r=null!=arguments[n]?arguments[n]:{};n%2?o(Object(r),!0).forEach((function(n){a(e,n,r[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(r,n))}))}return e}function p(e,n){if(null==e)return{};var r,t,a=function(e,n){if(null==e)return{};var r,t,a={},o=Object.keys(e);for(t=0;t<o.length;t++)r=o[t],n.indexOf(r)>=0||(a[r]=e[r]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(t=0;t<o.length;t++)r=o[t],n.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var s=t.createContext({}),c=function(e){var n=t.useContext(s),r=n;return e&&(r="function"==typeof e?e(n):i(i({},n),e)),r},l=function(e){var n=c(e.components);return t.createElement(s.Provider,{value:n},e.children)},u={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},f=t.forwardRef((function(e,n){var r=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,l=p(e,["components","mdxType","originalType","parentName"]),f=c(r),d=a,g=f["".concat(s,".").concat(d)]||f[d]||u[d]||o;return r?t.createElement(g,i(i({ref:n},l),{},{components:r})):t.createElement(g,i({ref:n},l))}));function d(e,n){var r=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=r.length,i=new Array(o);i[0]=f;var p={};for(var s in n)hasOwnProperty.call(n,s)&&(p[s]=n[s]);p.originalType=e,p.mdxType="string"==typeof e?e:a,i[1]=p;for(var c=2;c<o;c++)i[c]=r[c];return t.createElement.apply(null,i)}return t.createElement.apply(null,r)}f.displayName="MDXCreateElement"},60118:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>p,toc:()=>c});var t=r(87462),a=(r(67294),r(3905));const o={sidebar_position:4,title:"Scheduling from Airflow"},i=void 0,p={unversionedId:"integrations/spark/configuration/airflow",id:"integrations/spark/configuration/airflow",title:"Scheduling from Airflow",description:"The same parameters passed to spark-submit can be supplied from Airflow and other schedulers. If",source:"@site/docs/integrations/spark/configuration/airflow.md",sourceDirName:"integrations/spark/configuration",slug:"/integrations/spark/configuration/airflow",permalink:"/docs/integrations/spark/configuration/airflow",draft:!1,editUrl:"https://github.com/OpenLineage/docs/tree/main/docs/integrations/spark/configuration/airflow.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4,title:"Scheduling from Airflow"},sidebar:"tutorialSidebar",previous:{title:"Circuit Breaker",permalink:"/docs/integrations/spark/configuration/circuit_breaker"},next:{title:"Installation",permalink:"/docs/integrations/spark/installation"}},s={},c=[],l={toc:c};function u(e){let{components:n,...r}=e;return(0,a.kt)("wrapper",(0,t.Z)({},l,r,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The same parameters passed to ",(0,a.kt)("inlineCode",{parentName:"p"},"spark-submit")," can be supplied from Airflow and other schedulers. If\nusing the ",(0,a.kt)("a",{parentName:"p",href:"/docs/integrations/airflow/"},"openlineage-airflow")," integration, each task in the DAG has its own Run id\nwhich can be connected to the Spark job run via the ",(0,a.kt)("inlineCode",{parentName:"p"},"spark.openlineage.parentRunId")," parameter. For example,\nhere is an example of a ",(0,a.kt)("inlineCode",{parentName:"p"},"DataProcPySparkOperator")," that submits a Pyspark application on Dataproc:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'t1 = DataProcPySparkOperator(\n    task_id=job_name,\n    gcp_conn_id=\'google_cloud_default\',\n    project_id=\'project_id\',\n    cluster_name=\'cluster-name\',\n    region=\'us-west1\',\n    main=\'gs://bucket/your-prog.py\',\n    job_name=job_name,\n    dataproc_pyspark_properties={\n      "spark.extraListeners": "io.openlineage.spark.agent.OpenLineageSparkListener",\n      "spark.jars.packages": "io.openlineage:openlineage-spark:1.0.0+",\n      "spark.openlineage.transport.url": f"{openlineage_url}/api/v1/namespaces/{openlineage_namespace}/jobs/dump_orders_to_gcs/runs/{{{{lineage_run_id(run_id, task)}}}}?api_key={api_key}",\n      "spark.openlineage.namespace": openlineage_namespace,\n      "spark.openlineage.parentJobName": job_name,\n      "spark.openlineage.parentRunId": f"{{{{lineage_run_id(run_id, task)}}}}\n    },\n    dag=dag)\n')))}u.isMDXComponent=!0}}]);