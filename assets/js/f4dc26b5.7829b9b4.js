"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5190],{3905:(e,t,a)=>{a.d(t,{Zo:()=>s,kt:()=>c});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function p(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var o=n.createContext({}),m=function(e){var t=n.useContext(o),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},s=function(e){var t=m(e.components);return n.createElement(o.Provider,{value:t},e.children)},k={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,o=e.parentName,s=p(e,["components","mdxType","originalType","parentName"]),d=m(a),c=r,u=d["".concat(o,".").concat(c)]||d[c]||k[c]||i;return a?n.createElement(u,l(l({ref:t},s),{},{components:a})):n.createElement(u,l({ref:t},s))}));function c(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,l=new Array(i);l[0]=d;var p={};for(var o in t)hasOwnProperty.call(t,o)&&(p[o]=t[o]);p.originalType=e,p.mdxType="string"==typeof e?e:r,l[1]=p;for(var m=2;m<i;m++)l[m]=a[m];return n.createElement.apply(null,l)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},39706:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>l,default:()=>k,frontMatter:()=>i,metadata:()=>p,toc:()=>m});var n=a(87462),r=(a(67294),a(3905));const i={title:"1.18.0",sidebar_position:9939},l="1.18.0 - 2024-07-11",p={unversionedId:"releases/1_18_0",id:"releases/1_18_0",title:"1.18.0",description:"Added",source:"@site/docs/releases/1_18_0.md",sourceDirName:"releases",slug:"/releases/1_18_0",permalink:"/docs/releases/1_18_0",draft:!1,editUrl:"https://github.com/OpenLineage/docs/tree/main/docs/releases/1_18_0.md",tags:[],version:"current",sidebarPosition:9939,frontMatter:{title:"1.18.0",sidebar_position:9939},sidebar:"tutorialSidebar",previous:{title:"OpenLineage Proxy",permalink:"/docs/development/ol-proxy"},next:{title:"1.17.1",permalink:"/docs/releases/1_17_1"}},o={},m=[{value:"Added",id:"added",level:3},{value:"Changed",id:"changed",level:3},{value:"Fixed",id:"fixed",level:3}],s={toc:m};function k(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},s,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"1180---2024-07-11"},"1.18.0 - 2024-07-11"),(0,r.kt)("h3",{id:"added"},"Added"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: configurable integration test")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2755"},(0,r.kt)("inlineCode",{parentName:"a"},"#2755"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/pawel-big-lebowski"},"@pawel-big-lebowski"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Provides command line tool capable of running Spark integration tests that can be created without Java.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: OpenLineage Spark extension interfaces without runtime dependency hell")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2809"},(0,r.kt)("inlineCode",{parentName:"a"},"#2809"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2837"},(0,r.kt)("inlineCode",{parentName:"a"},"#2837"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/ddebowczyk92"},"@ddebowczyk92"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"New Spark extension interfaces without runtime dependency hell. Includes a test to verify the integration is working properly.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: support latest versions 3.4.3 and 3.5.1.")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2743"},(0,r.kt)("inlineCode",{parentName:"a"},"#2743"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/pawel-big-lebowski"},"@pawel-big-lebowski"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Upgrades CI workflows to run tests against latest Spark versions: 3.4.2 -> 3.4.3 and 3.5.0 -> 3.5.1.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: add extraction of the masking property in column-level lineage")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2789"},(0,r.kt)("inlineCode",{parentName:"a"},"#2789"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/tnazarew"},"@tnazarew"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Adds extraction of the masking property during collection of dependencies for ",(0,r.kt)("inlineCode",{parentName:"em"},"ColumnLineageDatasetFacet")," creation.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: collect table name from ",(0,r.kt)("inlineCode",{parentName:"strong"},"InsertIntoHadoopFsRelationCommand"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2794"},(0,r.kt)("inlineCode",{parentName:"a"},"#2794"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/dolfinus"},"@dolfinus"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Collects a table name for ",(0,r.kt)("inlineCode",{parentName:"em"},"INSERT INTO")," command for tables created with ",(0,r.kt)("inlineCode",{parentName:"em"},"USING $fileFormat")," syntax, like ",(0,r.kt)("inlineCode",{parentName:"em"},"USING orc"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark, Flink: add ",(0,r.kt)("inlineCode",{parentName:"strong"},"PostgresJdbcExtractor"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2806"},(0,r.kt)("inlineCode",{parentName:"a"},"#2806"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/dolfinus"},"@dolfinus"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Adds the default ",(0,r.kt)("inlineCode",{parentName:"em"},"5432")," port to Postgres namespaces.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark, Flink: add ",(0,r.kt)("inlineCode",{parentName:"strong"},"TeradataJdbcExtractor"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2826"},(0,r.kt)("inlineCode",{parentName:"a"},"#2826"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/dolfinus"},"@dolfinus"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Converts JDBC URLs like ",(0,r.kt)("inlineCode",{parentName:"em"},"jdbc:teradata/host/DBS_PORT=1024,DATABASE=somedb")," to datasets with namespace ",(0,r.kt)("inlineCode",{parentName:"em"},"teradata://host:1024")," and name ",(0,r.kt)("inlineCode",{parentName:"em"},"somedb.table"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark, Flink: add ",(0,r.kt)("inlineCode",{parentName:"strong"},"MySqlJdbcExtractor"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2825"},(0,r.kt)("inlineCode",{parentName:"a"},"#2825"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/dolfinus"},"@dolfinus"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Handles different formats of MySQL JDBC URL, and produces datasets with consistent namespaces, like ",(0,r.kt)("inlineCode",{parentName:"em"},"mysql://host:port"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark, Flink: add ",(0,r.kt)("inlineCode",{parentName:"strong"},"OracleJdbcExtractor"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2824"},(0,r.kt)("inlineCode",{parentName:"a"},"#2824"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/dolfinus"},"@dolfinus"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Handles simple Oracle JDBC URLs, like ",(0,r.kt)("inlineCode",{parentName:"em"},"oracle:thin:@//host:port/serviceName")," and ",(0,r.kt)("inlineCode",{parentName:"em"},"oracle:thin@host:port:sid"),", and converts each to a dataset with namespace ",(0,r.kt)("inlineCode",{parentName:"em"},"oracle://host:port")," and name ",(0,r.kt)("inlineCode",{parentName:"em"},"sid.schema.table")," or ",(0,r.kt)("inlineCode",{parentName:"em"},"serviceName.schema.table"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: configurable test with Docker image provided")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2822"},(0,r.kt)("inlineCode",{parentName:"a"},"#2822"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/pawel-big-lebowski"},"@pawel-big-lebowski"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Extends the configurable integration test feature to enable getting the Docker image name as a name.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: Support Iceberg 1.4 on Spark 3.5.1.")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2838"},(0,r.kt)("inlineCode",{parentName:"a"},"#2838"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/pawel-big-lebowski"},"@pawel-big-lebowski"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Include Iceberg support for Spark 3.5. Fix column level lineage facet for ",(0,r.kt)("inlineCode",{parentName:"em"},"UNION")," queries.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spec: add example for change in ",(0,r.kt)("inlineCode",{parentName:"strong"},"#2756"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2801"},(0,r.kt)("inlineCode",{parentName:"a"},"#2801"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/Sheeri"},"@Sheeri"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Updates the ",(0,r.kt)("inlineCode",{parentName:"em"},"customLineage")," facet test for the new syntax created in ",(0,r.kt)("inlineCode",{parentName:"em"},"#2756"),"."))),(0,r.kt)("h3",{id:"changed"},"Changed"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: fallback to ",(0,r.kt)("inlineCode",{parentName:"strong"},"spark.sql.warehouse.dir")," as table namespace")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2767"},(0,r.kt)("inlineCode",{parentName:"a"},"#2767"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/dolfinus"},"@dolfinus"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"In cases when a metastore is not used, falls back to ",(0,r.kt)("inlineCode",{parentName:"em"},"spark.sql.warehouse.dir")," or ",(0,r.kt)("inlineCode",{parentName:"em"},"hive.metastore.warehouse.dir")," as table namespace, instead of duplicating the table's location."))),(0,r.kt)("h3",{id:"fixed"},"Fixed"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Java: handle dashes in hostname for ",(0,r.kt)("inlineCode",{parentName:"strong"},"JdbcExtractors"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2830"},(0,r.kt)("inlineCode",{parentName:"a"},"#2830"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/dolfinus"},"@dolfinus"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Proper handling of dashes in JDBC URL hosts.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: fix Glue symlinks formatting bug")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2807"},(0,r.kt)("inlineCode",{parentName:"a"},"#2807"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/Akash2351"},"@Akash2351"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Fixes Glue symlinks with config parsing for Glue ",(0,r.kt)("inlineCode",{parentName:"em"},"catalogid"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark, Flink: fix DBFS namespace format")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2800"},(0,r.kt)("inlineCode",{parentName:"a"},"#2800"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/dolfinus"},"@dolfinus"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Fixes the DBFS namespace format.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: fix Glue naming format")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2766"},(0,r.kt)("inlineCode",{parentName:"a"},"#2766"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/dolfinus"},"@dolfinus"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Changes the AWS Glue namespace to match Glue ARN documentation.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: fix Iceberg dataset location")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2797"},(0,r.kt)("inlineCode",{parentName:"a"},"#2797"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/dolfinus"},"@dolfinus"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Fixes Iceberg dataset namespace: instead of ",(0,r.kt)("inlineCode",{parentName:"em"},"file:/some/path/database.table")," uses ",(0,r.kt)("inlineCode",{parentName:"em"},"file:/some/path/database/table"),". For dataset TABLE symlink, uses warehouse location instead of database location.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: fix NPE and incorrect comment")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2827"},(0,r.kt)("inlineCode",{parentName:"a"},"#2827"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/pawel-big-lebowski"},"@pawel-big-lebowski"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Fixes an error caused by a recent upgrade of Spark versions that did not break existing tests.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Spark: convert scheme and authority to lowercase in ",(0,r.kt)("inlineCode",{parentName:"strong"},"JdbcLocation"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/OpenLineage/OpenLineage/pull/2831"},(0,r.kt)("inlineCode",{parentName:"a"},"#2831"))," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/dolfinus"},"@dolfinus"),(0,r.kt)("br",{parentName:"li"}),"",(0,r.kt)("em",{parentName:"li"},"Converts valid JDBC URL scheme and authority to lowercase, leaving intact instance/database name, as different databases have different default case and case-sensitivity rules."))))}k.isMDXComponent=!0}}]);