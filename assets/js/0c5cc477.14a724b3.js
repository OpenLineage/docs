"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[214],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>m});var r=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},s=Object.keys(e);for(r=0;r<s.length;r++)a=s[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(r=0;r<s.length;r++)a=s[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var o=r.createContext({}),p=function(e){var t=r.useContext(o),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},c=function(e){var t=p(e.components);return r.createElement(o.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,s=e.originalType,o=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),d=p(a),m=n,f=d["".concat(o,".").concat(m)]||d[m]||u[m]||s;return a?r.createElement(f,i(i({ref:t},c),{},{components:a})):r.createElement(f,i({ref:t},c))}));function m(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var s=a.length,i=new Array(s);i[0]=d;var l={};for(var o in t)hasOwnProperty.call(t,o)&&(l[o]=t[o]);l.originalType=e,l.mdxType="string"==typeof e?e:n,i[1]=l;for(var p=2;p<s;p++)i[p]=a[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,a)}d.displayName="MDXCreateElement"},750:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>i,default:()=>u,frontMatter:()=>s,metadata:()=>l,toc:()=>p});var r=a(7462),n=(a(7294),a(3905));const s={sidebar_position:3},i="SQL parser",l={unversionedId:"development/sql",id:"development/sql",title:"SQL parser",description:"SQL is the most widely used data processing language and for a lot of use cases, getting lineage from SQL-based tasks is solving majority of the problem.",source:"@site/docs/development/sql.md",sourceDirName:"development",slug:"/development/sql",permalink:"/docs/development/sql",draft:!1,editUrl:"https://github.com/OpenLineage/docs/tree/main/docs/development/sql.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"OpenLineage Proxy",permalink:"/docs/development/ol-proxy"},next:{title:"1.5.0",permalink:"/docs/releases/1_5_0"}},o={},p=[{value:"Interface",id:"interface",level:3},{value:"SQL dialects",id:"sql-dialects",level:3},{value:"Default databases and schemas",id:"default-databases-and-schemas",level:3},{value:"Usage",id:"usage",level:3}],c={toc:p};function u(e){let{components:t,...a}=e;return(0,n.kt)("wrapper",(0,r.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"sql-parser"},"SQL parser"),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"SQL")," is the most widely used data processing language and for a lot of use cases, getting lineage from SQL-based tasks is solving majority of the problem.\nFor this reason, we've created SQL parser that allows you to get lineage directly by processing SQL query."),(0,n.kt)("p",null,"Our SQL parser is based on excellent ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/sqlparser-rs/sqlparser-rs"},"sqlparser-rs")," library."),(0,n.kt)("h3",{id:"interface"},"Interface"),(0,n.kt)("p",null,"SQL parser interface expressed in pseudo-python."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'class DbTableMeta:\n    database: Optional[str]\n    schema: Optional[str]\n    name: str\n\n\nclass SqlMeta:\n    in_tables: List[DbTableMeta]\n    out_tables: List[DbTableMeta]\n\ndef parse(\n    sql: Union[List[str], str],\n    # Setting dialect allows you to enable some dialect-specific processing \n    # like using backticks "`" as delimiters in BigQuery tables.\n    dialect: Optional[str] = None,   \n    # Setting this will make parser use this schema for every table that\n    # does not specify schema. \n    default_schema: Optional[str] = None\n) -> Optional[SqlMeta] \n')),(0,n.kt)("h3",{id:"sql-dialects"},"SQL dialects"),(0,n.kt)("p",null,"Optional ",(0,n.kt)("inlineCode",{parentName:"p"},"dialect")," can be specified when using the parser to specify a specific flavor of SQL statement that is required to be parsed. The following dialects are currently available:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"ansi"),(0,n.kt)("li",{parentName:"ul"},"bigquery"),(0,n.kt)("li",{parentName:"ul"},"hive"),(0,n.kt)("li",{parentName:"ul"},"mssql"),(0,n.kt)("li",{parentName:"ul"},"mysql"),(0,n.kt)("li",{parentName:"ul"},"postgres"),(0,n.kt)("li",{parentName:"ul"},"postgresql"),(0,n.kt)("li",{parentName:"ul"},"redshift"),(0,n.kt)("li",{parentName:"ul"},"snowflake"),(0,n.kt)("li",{parentName:"ul"},"sqlite")),(0,n.kt)("p",null,"If no dialect is specified, the dialect defaults to ",(0,n.kt)("inlineCode",{parentName:"p"},"generic")," which parses generic SQL statements."),(0,n.kt)("h3",{id:"default-databases-and-schemas"},"Default databases and schemas"),(0,n.kt)("p",null,"SQL processing engines and databases sometimes rely on some ",(0,n.kt)("em",{parentName:"p"},"implicit")," information. For example, they often allow you to set current database or schema, instead of forcing\nyou to specify fully-qualified table name every time you're refering to it."),(0,n.kt)("p",null,"For this reason, bare SQL parser might be insufficient to fully understand which tables the query refers to.\nWe recommend to process the data that you acquired from SQL parser to take that into account."),(0,n.kt)("h3",{id:"usage"},"Usage"),(0,n.kt)("p",null,"OpenLineage SQL parser is available as part of the integrations that contains extractors that need to parse SQL statements. An example would be Apache Airflow integrations which houses multiple operators that executes SQL statements."),(0,n.kt)("p",null,"SQL parser is included as part of the library for such integrations (e.g. ",(0,n.kt)("inlineCode",{parentName:"p"},"integration-airflow"),"). However, you can explicitly install and use the SQL parser via pip:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-text"},"pip install openlineage-sql \n")),(0,n.kt)("p",null,"For details about using the SQL parser, please refer to its git ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/OpenLineage/OpenLineage/tree/main/integration/sql"},"README")),(0,n.kt)("p",null,"There is also a python tester script ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/OpenLineage/OpenLineage/blob/main/integration/sql/tests/python/sql_tester.py"},"here")," which you can use to run parsing tests against any arbitrary SQL statements to verify whether the SQL parser can properly parse them."))}u.isMDXComponent=!0}}]);